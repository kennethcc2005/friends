{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import psycopg2\n",
    "import json\n",
    "import simplejson\n",
    "import urllib\n",
    "import config\n",
    "import ast\n",
    "\n",
    "from operator import itemgetter\n",
    "from sklearn.cluster import KMeans\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Users/Gon/anaconda3/envs/python2/lib/python2.7/site-packages\n",
      "Requirement already satisfied: sqlalchemy in /Users/Gon/anaconda3/envs/python2/lib/python2.7/site-packages\n",
      "Requirement already satisfied: psycopg2 in /Users/Gon/anaconda3/envs/python2/lib/python2.7/site-packages\n",
      "Requirement already satisfied: simplejson in /Users/Gon/anaconda3/envs/python2/lib/python2.7/site-packages\n",
      "Requirement already satisfied: config in /Users/Gon/anaconda3/envs/python2/lib/python2.7/site-packages\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install sqlalchemy\n",
    "!pip install psycopg2\n",
    "!pip install simplejson\n",
    "!pip install config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_str = \"dbname='travel_with_friends' user='zoesh' host='localhost'\"\n",
    "# conn_str = \"dbname='travel_with_friends' user='Zoesh' host='localhost'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "def distL2((x1,y1), (x2,y2)):\n",
    "    \"\"\"Compute the L2-norm (Euclidean) distance between two points.\n",
    "\n",
    "    The distance is rounded to the closest integer, for compatibility\n",
    "    with the TSPLIB convention.\n",
    "\n",
    "    The two points are located on coordinates (x1,y1) and (x2,y2),\n",
    "    sent as parameters\"\"\"\n",
    "    xdiff = x2 - x1\n",
    "    ydiff = y2 - y1\n",
    "    return math.sqrt(xdiff*xdiff + ydiff*ydiff) + .5\n",
    "\n",
    "\n",
    "def distL1((x1,y1), (x2,y2)):\n",
    "    \"\"\"Compute the L1-norm (Manhattan) distance between two points.\n",
    "\n",
    "    The distance is rounded to the closest integer, for compatibility\n",
    "    with the TSPLIB convention.\n",
    "\n",
    "    The two points are located on coordinates (x1,y1) and (x2,y2),\n",
    "    sent as parameters\"\"\"\n",
    "    return abs(x2-x1) + abs(y2-y1)+.5\n",
    "\n",
    "\n",
    "def mk_matrix(coord, dist):\n",
    "    \"\"\"Compute a distance matrix for a set of points.\n",
    "\n",
    "    Uses function 'dist' to calculate distance between\n",
    "    any two points.  Parameters:\n",
    "    -coord -- list of tuples with coordinates of all points, [(x1,y1),...,(xn,yn)]\n",
    "    -dist -- distance function\n",
    "    \"\"\"\n",
    "    n = len(coord)\n",
    "    D = {}      # dictionary to hold n times n matrix\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1,n):\n",
    "            [x1,y1] = coord[i]\n",
    "            [x2,y2] = coord[j]\n",
    "            D[i,j] = dist((x1,y1), (x2,y2))\n",
    "            D[j,i] = D[i,j]\n",
    "    return n,D\n",
    "\n",
    "def read_tsplib(filename):\n",
    "    \"basic function for reading a TSP problem on the TSPLIB format\"\n",
    "    \"NOTE: only works for 2D euclidean or manhattan distances\"\n",
    "    f = open(filename, 'r');\n",
    "\n",
    "    line = f.readline()\n",
    "    while line.find(\"EDGE_WEIGHT_TYPE\") == -1:\n",
    "        line = f.readline()\n",
    "\n",
    "    if line.find(\"EUC_2D\") != -1:\n",
    "        dist = distL2\n",
    "    elif line.find(\"MAN_2D\") != -1:\n",
    "        dist = distL1\n",
    "    else:\n",
    "        print \"cannot deal with non-euclidean or non-manhattan distances\"\n",
    "        raise Exception\n",
    "\n",
    "    while line.find(\"NODE_COORD_SECTION\") == -1:\n",
    "        line = f.readline()\n",
    "\n",
    "    xy_positions = []\n",
    "    while 1:\n",
    "        line = f.readline()\n",
    "        if line.find(\"EOF\") != -1: break\n",
    "        (i,x,y) = line.split()\n",
    "        x = float(x)\n",
    "        y = float(y)\n",
    "        xy_positions.append((x,y))\n",
    "\n",
    "    n,D = mk_matrix(xy_positions, dist)\n",
    "    return n, xy_positions, D\n",
    "\n",
    "\n",
    "def mk_closest(D, n):\n",
    "    \"\"\"Compute a sorted list of the distances for each of the nodes.\n",
    "\n",
    "    For each node, the entry is in the form [(d1,i1), (d2,i2), ...]\n",
    "    where each tuple is a pair (distance,node).\n",
    "    \"\"\"\n",
    "    C = []\n",
    "    for i in range(n):\n",
    "        dlist = [(D[i,j], j) for j in range(n) if j != i]\n",
    "        dlist.sort()\n",
    "        C.append(dlist)\n",
    "    return C\n",
    "\n",
    "\n",
    "def length(tour, D):\n",
    "    \"\"\"Calculate the length of a tour according to distance matrix 'D'.\"\"\"\n",
    "    z = D[tour[-1], tour[0]]    # edge from last to first city of the tour\n",
    "    for i in range(1,len(tour)):\n",
    "        z += D[tour[i], tour[i-1]]      # add length of edge from city i-1 to i\n",
    "    return z\n",
    "\n",
    "\n",
    "def randtour(n):\n",
    "    \"\"\"Construct a random tour of size 'n'.\"\"\"\n",
    "    sol = range(n)      # set solution equal to [0,1,...,n-1]\n",
    "    random.shuffle(sol) # place it in a random order\n",
    "    return sol\n",
    "\n",
    "\n",
    "def nearest(last, unvisited, D):\n",
    "    \"\"\"Return the index of the node which is closest to 'last'.\"\"\"\n",
    "    near = unvisited[0]\n",
    "    min_dist = D[last, near]\n",
    "    for i in unvisited[1:]:\n",
    "        if D[last,i] < min_dist:\n",
    "            near = i\n",
    "            min_dist = D[last, near]\n",
    "    return near\n",
    "\n",
    "\n",
    "def nearest_neighbor(n, i, D):\n",
    "    \"\"\"Return tour starting from city 'i', using the Nearest Neighbor.\n",
    "\n",
    "    Uses the Nearest Neighbor heuristic to construct a solution:\n",
    "    - start visiting city i\n",
    "    - while there are unvisited cities, follow to the closest one\n",
    "    - return to city i\n",
    "    \"\"\"\n",
    "    unvisited = range(n)\n",
    "    unvisited.remove(i)\n",
    "    last = i\n",
    "    tour = [i]\n",
    "    while unvisited != []:\n",
    "        next = nearest(last, unvisited, D)\n",
    "        tour.append(next)\n",
    "        unvisited.remove(next)\n",
    "        last = next\n",
    "    return tour\n",
    "\n",
    "\n",
    "\n",
    "def exchange_cost(tour, i, j, D):\n",
    "    \"\"\"Calculate the cost of exchanging two arcs in a tour.\n",
    "\n",
    "    Determine the variation in the tour length if\n",
    "    arcs (i,i+1) and (j,j+1) are removed,\n",
    "    and replaced by (i,j) and (i+1,j+1)\n",
    "    (note the exception for the last arc).\n",
    "\n",
    "    Parameters:\n",
    "    -t -- a tour\n",
    "    -i -- position of the first arc\n",
    "    -j>i -- position of the second arc\n",
    "    \"\"\"\n",
    "    n = len(tour)\n",
    "    a,b = tour[i],tour[(i+1)%n]\n",
    "    c,d = tour[j],tour[(j+1)%n]\n",
    "    return (D[a,c] + D[b,d]) - (D[a,b] + D[c,d])\n",
    "\n",
    "\n",
    "def exchange(tour, tinv, i, j):\n",
    "    \"\"\"Exchange arcs (i,i+1) and (j,j+1) with (i,j) and (i+1,j+1).\n",
    "\n",
    "    For the given tour 't', remove the arcs (i,i+1) and (j,j+1) and\n",
    "    insert (i,j) and (i+1,j+1).\n",
    "\n",
    "    This is done by inverting the sublist of cities between i and j.\n",
    "    \"\"\"\n",
    "    n = len(tour)\n",
    "    if i>j:\n",
    "        i,j = j,i\n",
    "    assert i>=0 and i<j-1 and j<n\n",
    "    path = tour[i+1:j+1]\n",
    "    path.reverse()\n",
    "    tour[i+1:j+1] = path\n",
    "    for k in range(i+1,j+1):\n",
    "        tinv[tour[k]] = k\n",
    "\n",
    "\n",
    "def improve(tour, z, D, C):\n",
    "    \"\"\"Try to improve tour 't' by exchanging arcs; return improved tour length.\n",
    "\n",
    "    If possible, make a series of local improvements on the solution 'tour',\n",
    "    using a breadth first strategy, until reaching a local optimum.\n",
    "    \"\"\"\n",
    "    n = len(tour)\n",
    "    tinv = [0 for i in tour]\n",
    "    for k in range(n):\n",
    "        tinv[tour[k]] = k  # position of each city in 't'\n",
    "    for i in range(n):\n",
    "        a,b = tour[i],tour[(i+1)%n]\n",
    "        dist_ab = D[a,b]\n",
    "        improved = False\n",
    "        for dist_ac,c in C[a]:\n",
    "            if dist_ac >= dist_ab:\n",
    "                break\n",
    "            j = tinv[c]\n",
    "            d = tour[(j+1)%n]\n",
    "            dist_cd = D[c,d]\n",
    "            dist_bd = D[b,d]\n",
    "            delta = (dist_ac + dist_bd) - (dist_ab + dist_cd)\n",
    "            if delta < 0:       # exchange decreases length\n",
    "                exchange(tour, tinv, i, j);\n",
    "                z += delta\n",
    "                improved = True\n",
    "                break\n",
    "        if improved:\n",
    "            continue\n",
    "        for dist_bd,d in C[b]:\n",
    "            if dist_bd >= dist_ab:\n",
    "                break\n",
    "            j = tinv[d]-1\n",
    "            if j==-1:\n",
    "                j=n-1\n",
    "            c = tour[j]\n",
    "            dist_cd = D[c,d]\n",
    "            dist_ac = D[a,c]\n",
    "            delta = (dist_ac + dist_bd) - (dist_ab + dist_cd)\n",
    "            if delta < 0:       # exchange decreases length\n",
    "                exchange(tour, tinv, i, j);\n",
    "                z += delta\n",
    "                break\n",
    "    return z\n",
    "\n",
    "\n",
    "def localsearch(tour, z, D, C=None):\n",
    "    \"\"\"Obtain a local optimum starting from solution t; return solution length.\n",
    "\n",
    "    Parameters:\n",
    "      tour -- initial tour\n",
    "      z -- length of the initial tour\n",
    "      D -- distance matrix\n",
    "    \"\"\"\n",
    "    n = len(tour)\n",
    "    if C == None:\n",
    "        C = mk_closest(D, n)     # create a sorted list of distances to each node\n",
    "    while 1:\n",
    "        newz = improve(tour, z, D, C)\n",
    "        if newz < z:\n",
    "            z = newz\n",
    "        else:\n",
    "            break\n",
    "    return z\n",
    "\n",
    "\n",
    "def multistart_localsearch(k, n, D, report=None):\n",
    "    \"\"\"Do k iterations of local search, starting from random solutions.\n",
    "\n",
    "    Parameters:\n",
    "    -k -- number of iterations\n",
    "    -D -- distance matrix\n",
    "    -report -- if not None, call it to print verbose output\n",
    "\n",
    "    Returns best solution and its cost.\n",
    "    \"\"\"\n",
    "    C = mk_closest(D, n) # create a sorted list of distances to each node\n",
    "    bestt=None\n",
    "    bestz=None\n",
    "    for i in range(0,k):\n",
    "        tour = randtour(n)\n",
    "        z = length(tour, D)\n",
    "        z = localsearch(tour, z, D, C)\n",
    "        if z < bestz or bestz == None:\n",
    "            bestz = z\n",
    "            bestt = list(tour)\n",
    "            if report:\n",
    "                report(z, tour)\n",
    "\n",
    "    return bestt, bestz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# db_name = \"travel_with_friends\"\n",
    "# TABLES ={}\n",
    "# TABLES['full_trip_table'] = (\n",
    "#     \"CREATE TABLE `full_trip_table` (\"\n",
    "#     \"  `user_id` int(11) NOT NULL AUTO_INCREMENT,\"\n",
    "#     \"  `full_trip_id` date NOT NULL,\"\n",
    "#     \"  `trip_location_ids` varchar(14) NOT NULL,\"\n",
    "#     \"  `default` varchar(16) NOT NULL,\"\n",
    "#     \"  `county` enum('M','F') NOT NULL,\"\n",
    "#     \"  `state` date NOT NULL,\"\n",
    "#     \"  `details` ,\"\n",
    "#     \"  `n_days`,\"\n",
    "#     \"  PRIMARY KEY (`full_trip_id`)\"\n",
    "#     \") ENGINE=InnoDB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_tables():\n",
    "#     \"\"\" create tables in the PostgreSQL database\"\"\"\n",
    "#     commands = (\n",
    "#         \"\"\"\n",
    "#         CREATE TABLE full_trip_table (\n",
    "#             index INTEGER PRIMARY KEY,\n",
    "#             user_id VARCHAR(225) NOT NULL,\n",
    "#             full_trip_id VARCHAR(225) NOT NULL,\n",
    "#             trip_location_ids VARCHAR(225),\n",
    "#             default BOOLEAN NOT NULL,\n",
    "#             county VARCHAR(225) NOT NULL,\n",
    "#             state VARCHAR(225) NOT NULL,\n",
    "#             details VARCHAR(MAX),\n",
    "#             n_days VARCHAR(225) NOT NULL\n",
    "#         )\n",
    "#         \"\"\",\n",
    "#         \"\"\" CREATE TABLE day_trip_table (\n",
    "#                 trip_locations_id \n",
    "#                 full_day\n",
    "#                 default \n",
    "#                 county \n",
    "#                 state\n",
    "#                 details\n",
    "#                 )\n",
    "#         \"\"\",\n",
    "#         \"\"\"\n",
    "#         CREATE TABLE poi_detail_table (\n",
    "#                 part_id INTEGER PRIMARY KEY,\n",
    "#                 file_extension VARCHAR(5) NOT NULL,\n",
    "#                 drawing_data BYTEA NOT NULL,\n",
    "#                 FOREIGN KEY (part_id)\n",
    "#                 REFERENCES parts (part_id)\n",
    "#                 ON UPDATE CASCADE ON DELETE CASCADE\n",
    "#         )\n",
    "#         \"\"\",\n",
    "#         \"\"\"\n",
    "#         CREATE TABLE google_travel_time_table (\n",
    "#                 index INTEGER PRIMARY KEY,\n",
    "#                 id_ VARCHAR NOT NULL,\n",
    "#                 orig_name VARCHAR,\n",
    "#                 orig_idx VARCHAR,\n",
    "#                 dest_name VARCHAR,\n",
    "#                 dest_idx VARCHAR,\n",
    "#                 orig_coord0 INTEGER,\n",
    "#                 orig_coord1 INTEGER,\n",
    "#                 dest_coord0 INTEGER,\n",
    "#                 dest_coord1 INTEGER,\n",
    "#                 orig_coords VARCHAR,\n",
    "#                 dest_coords VARCHAR,\n",
    "#                 google_driving_url VARCHAR,\n",
    "#                 google_walking_url VARCHAR,\n",
    "#                 driving_result VARCHAR,\n",
    "#                 walking_result VARCHAR,\n",
    "#                 google_driving_time INTEGER,\n",
    "#                 google_walking_time INTEGER\n",
    "                \n",
    "\n",
    "#         )\n",
    "#         \"\"\")\n",
    "#     conn = None\n",
    "#     try:\n",
    "#         # read the connection parameters\n",
    "#         params = config()\n",
    "#         # connect to the PostgreSQL server\n",
    "#         conn = psycopg2.connect(**params)\n",
    "#         cur = conn.cursor()\n",
    "#         # create table one by one\n",
    "#         for command in commands:\n",
    "#             cur.execute(command)\n",
    "#         # close communication with the PostgreSQL database server\n",
    "#         cur.close()\n",
    "#         # commit the changes\n",
    "#         conn.commit()\n",
    "#     except (Exception, psycopg2.DatabaseError) as error:\n",
    "#         print(error)\n",
    "#     finally:\n",
    "#         if conn is not None:\n",
    "#             conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# full_trip_table = pd.DataFrame(columns =['user_id', 'full_trip_id', 'trip_location_ids', 'default', 'county', 'state', 'details', 'n_days'])\n",
    "\n",
    "# day_trip_locations_table = pd.DataFrame(columns =['trip_locations_id','full_day', 'default', 'county', 'state','details'])\n",
    "\n",
    "# google_travel_time_table = pd.DataFrame(columns =['id_','orig_name','orig_idx','dest_name','dest_idx','orig_coord0','orig_coord1',\\\n",
    "#                                        'dest_coord0','dest_coord1','orig_coords','dest_coords','google_driving_url',\\\n",
    "#                                        'google_walking_url','driving_result','walking_result','google_driving_time',\\\n",
    "#                                        'google_walking_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read poi details csv file \n",
    "poi_detail = pd.read_csv(\"./step9_poi.csv\", index_col=0)\n",
    "poi_detail['address'] = None\n",
    "poi_detail['rating']=poi_detail['rating'].fillna(0)\n",
    "#read US city state and county csv file\n",
    "# df_counties = pd.read_csv('./us_cities_states_counties.csv',sep='|')\n",
    "#find counties without duplicate\n",
    "# df_counties_u = df_counties.drop('City alias',axis = 1).drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_db_tables():\n",
    "    full_trip_table = pd.DataFrame(columns =['user_id', 'full_trip_id', 'trip_location_ids', 'default', 'county', 'state', 'details', 'n_days'])\n",
    "\n",
    "    day_trip_locations_table = pd.DataFrame(columns =['trip_locations_id','full_day', 'default', 'county', 'state','details','event_type','event_ids'])\n",
    "\n",
    "    google_travel_time_table = pd.DataFrame(columns =['id_','orig_name','orig_idx','dest_name','dest_idx','orig_coord0','orig_coord1',\\\n",
    "                                           'dest_coord0','dest_coord1','orig_coords','dest_coords','google_driving_url',\\\n",
    "                                           'google_walking_url','driving_result','walking_result','google_driving_time',\\\n",
    "                                           'google_walking_time'])\n",
    "    day_trip_locations_table.loc[0] = ['CALIFORNIA-SAN-DIEGO-1-3-0', True, True, 'SAN DIEGO', 'California',\n",
    "       [\"{'address': '15500 San Pasqual Valley Rd, Escondido, CA 92027, USA', 'id': 2259, 'day': 0, 'name': u'San Diego Zoo Safari Park'}\", \"{'address': 'Safari Walk, Escondido, CA 92027, USA', 'id': 2260, 'day': 0, 'name': u'Meerkat'}\", \"{'address': '1999 Citracado Parkway, Escondido, CA 92029, USA', 'id': 3486, 'day': 0, 'name': u'Stone'}\", \"{'address': '1999 Citracado Parkway, Escondido, CA 92029, USA', 'id': 3487, 'day': 0, 'name': u'Stone Brewery'}\", \"{'address': 'Mount Woodson Trail, Poway, CA 92064, USA', 'id': 4951, 'day': 0, 'name': u'Lake Poway'}\", \"{'address': '17130 Mt Woodson Rd, Ramona, CA 92065, USA', 'id': 4953, 'day': 0, 'name': u'Potato Chip Rock'}\", \"{'address': '17130 Mt Woodson Rd, Ramona, CA 92065, USA', 'id': 4952, 'day': 0, 'name': u'Mt. Woodson'}\"],\n",
    "       'big','[2259, 2260,3486,3487,4951,4953,4952]']\n",
    "    google_travel_time_table.loc[0] = ['439300002871', u'Moonlight Beach', 4393.0,\n",
    "       u'Carlsbad Flower Fields', 2871.0, -117.29692141333341,\n",
    "       33.047769600024424, -117.3177652511278, 33.124079753475236,\n",
    "       '33.0477696,-117.296921413', '33.1240797535,-117.317765251',\n",
    "       'https://maps.googleapis.com/maps/api/distancematrix/json?origins=33.0477696,-117.296921413&destinations=33.1240797535,-117.317765251&mode=driving&language=en-EN&sensor=false&key=AIzaSyDJh9EWCA_v0_B3SvjzjUA3OSVYufPJeGE',\n",
    "       'https://maps.googleapis.com/maps/api/distancematrix/json?origins=33.0477696,-117.296921413&destinations=33.1240797535,-117.317765251&mode=walking&language=en-EN&sensor=false&key=AIzaSyDJh9EWCA_v0_B3SvjzjUA3OSVYufPJeGE',\n",
    "       \"{'status': 'OK', 'rows': [{'elements': [{'duration': {'text': '14 mins', 'value': 822}, 'distance': {'text': '10.6 km', 'value': 10637}, 'status': 'OK'}]}], 'origin_addresses': ['233 C St, Encinitas, CA 92024, USA'], 'destination_addresses': ['5754-5780 Paseo Del Norte, Carlsbad, CA 92008, USA']}\",\n",
    "       \"{'status': 'OK', 'rows': [{'elements': [{'duration': {'text': '2 hours 4 mins', 'value': 7457}, 'distance': {'text': '10.0 km', 'value': 10028}, 'status': 'OK'}]}], 'origin_addresses': ['498 B St, Encinitas, CA 92024, USA'], 'destination_addresses': ['5754-5780 Paseo Del Norte, Carlsbad, CA 92008, USA']}\",\n",
    "       13.0, 124.0]\n",
    "    full_trip_table.loc[0] = ['gordon_lee01', 'CALIFORNIA-SAN-DIEGO-1-3',\n",
    "       \"['CALIFORNIA-SAN-DIEGO-1-3-0', 'CALIFORNIA-SAN-DIEGO-1-3-1', 'CALIFORNIA-SAN-DIEGO-1-3-2']\",\n",
    "       True, 'SAN DIEGO', 'California',\n",
    "       '[\"{\\'address\\': \\'15500 San Pasqual Valley Rd, Escondido, CA 92027, USA\\', \\'id\\': 2259, \\'day\\': 0, \\'name\\': u\\'San Diego Zoo Safari Park\\'}\", \"{\\'address\\': \\'Safari Walk, Escondido, CA 92027, USA\\', \\'id\\': 2260, \\'day\\': 0, \\'name\\': u\\'Meerkat\\'}\", \"{\\'address\\': \\'1999 Citracado Parkway, Escondido, CA 92029, USA\\', \\'id\\': 3486, \\'day\\': 0, \\'name\\': u\\'Stone\\'}\", \"{\\'address\\': \\'1999 Citracado Parkway, Escondido, CA 92029, USA\\', \\'id\\': 3487, \\'day\\': 0, \\'name\\': u\\'Stone Brewery\\'}\", \"{\\'address\\': \\'Mount Woodson Trail, Poway, CA 92064, USA\\', \\'id\\': 4951, \\'day\\': 0, \\'name\\': u\\'Lake Poway\\'}\", \"{\\'address\\': \\'17130 Mt Woodson Rd, Ramona, CA 92065, USA\\', \\'id\\': 4953, \\'day\\': 0, \\'name\\': u\\'Potato Chip Rock\\'}\", \"{\\'address\\': \\'17130 Mt Woodson Rd, Ramona, CA 92065, USA\\', \\'id\\': 4952, \\'day\\': 0, \\'name\\': u\\'Mt. Woodson\\'}\", \"{\\'address\\': \\'1 Legoland Dr, Carlsbad, CA 92008, USA\\', \\'id\\': 2870, \\'day\\': 1, \\'name\\': u\\'Legoland\\'}\", \"{\\'address\\': \\'5754-5780 Paseo Del Norte, Carlsbad, CA 92008, USA\\', \\'id\\': 2871, \\'day\\': 1, \\'name\\': u\\'Carlsbad Flower Fields\\'}\", \"{\\'address\\': \\'211-359 The Strand N, Oceanside, CA 92054, USA\\', \\'id\\': 2089, \\'day\\': 1, \\'name\\': u\\'Oceanside Pier\\'}\", \"{\\'address\\': \\'211-359 The Strand N, Oceanside, CA 92054, USA\\', \\'id\\': 2090, \\'day\\': 1, \\'name\\': u\\'Pier\\'}\", \"{\\'address\\': \\'1016-1024 Neptune Ave, Encinitas, CA 92024, USA\\', \\'id\\': 2872, \\'day\\': 1, \\'name\\': u\\'Encinitas\\'}\", \"{\\'address\\': \\'625 Pan American Rd E, San Diego, CA 92101, USA\\', \\'id\\': 147, \\'day\\': 2, \\'name\\': u\\'Balboa Park\\'}\", \"{\\'address\\': \\'1849-1863 Zoo Pl, San Diego, CA 92101, USA\\', \\'id\\': 152, \\'day\\': 2, \\'name\\': u\\'San Diego Zoo\\'}\", \"{\\'address\\': \\'701-817 Coast Blvd, La Jolla, CA 92037, USA\\', \\'id\\': 148, \\'day\\': 2, \\'name\\': u\\'La Jolla\\'}\", \"{\\'address\\': \\'10051-10057 Pebble Beach Dr, Santee, CA 92071, USA\\', \\'id\\': 4630, \\'day\\': 2, \\'name\\': u\\'Santee Lakes\\'}\", \"{\\'address\\': \\'Lake Murray Bike Path, La Mesa, CA 91942, USA\\', \\'id\\': 4545, \\'day\\': 2, \\'name\\': u\\'Lake Murray\\'}\", \"{\\'address\\': \\'4905 Mt Helix Dr, La Mesa, CA 91941, USA\\', \\'id\\': 4544, \\'day\\': 2, \\'name\\': u\\'Mt. Helix\\'}\", \"{\\'address\\': \\'1720 Melrose Ave, Chula Vista, CA 91911, USA\\', \\'id\\': 1325, \\'day\\': 2, \\'name\\': u\\'Thick-billed Kingbird\\'}\", \"{\\'address\\': \\'711 Basswood Ave, Imperial Beach, CA 91932, USA\\', \\'id\\': 1326, \\'day\\': 2, \\'name\\': u\\'Lesser Sand-Plover\\'}\"]',\n",
    "       3.0]\n",
    "    engine = create_engine('postgresql://zoesh@localhost:5432/travel_with_friends')\n",
    "    # full_trip_table = pd.read_csv('./full_trip_table.csv', index_col= 0)\n",
    "    # full_trip_table.to_sql('full_trip_table', engine,if_exists='append')\n",
    "\n",
    "    full_trip_table.to_sql('full_trip_table',engine, if_exists = \"replace\")\n",
    "    day_trip_locations_table.to_sql('day_trip_table',engine, if_exists = \"replace\")\n",
    "    google_travel_time_table.to_sql('google_travel_time_table',engine, if_exists = \"replace\")\n",
    "    poi_detail.to_sql('poi_detail_table',engine, if_exists = \"replace\")\n",
    "    \n",
    "    \n",
    "    df_counties = pd.read_csv('/Users/zoesh/Desktop/travel_with_friends/travel_with_friends/us_cities_states_counties.csv',sep='|')\n",
    "    df_counties_u = df_counties.drop('City alias',axis = 1).drop_duplicates()\n",
    "    df_counties_u.columns = [\"city\",\"state_abb\",\"state\",\"county\"]\n",
    "    df_counties_u.to_sql('county_table',engine, if_exists = \"replace\")\n",
    "init_db_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cold_start_places(df, county, state, city, number_days, first_day_full = True, last_day_full = True):\n",
    "    \n",
    "    if len(county.values) != 0:\n",
    "        county = county.values[0]\n",
    "        temp_df = df[(df['county'] == county) & (df['state'] == state)]\n",
    "    else:\n",
    "        temp_df = df[(df['city'] == city) & (df['state'] == state)]\n",
    "\n",
    "    return county, temp_df\n",
    "def find_county(state, city):\n",
    "    \n",
    "    conn = psycopg2.connect(conn_str)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"select county from county_table where city = '%s' and state = '%s';\" %(city.title(), state.title()))\n",
    "\n",
    "    county = cur.fetchone()\n",
    "    conn.close()\n",
    "    if county:\n",
    "        return county[0]\n",
    "    else:\n",
    "        return None\n",
    "def db_start_location(county, state, city):\n",
    "    conn = psycopg2.connect(conn_str)\n",
    "    cur = conn.cursor()\n",
    "    if county:\n",
    "        cur.execute(\"select index, coord0, coord1, adjusted_normal_time_spent, poi_rank, rating from poi_detail_table where county = '%s' and state = '%s'; \"%(county.upper(), state))\n",
    "\n",
    "    else:\n",
    "#         print \"else\"\n",
    "        cur.execute(\"select index, coord0, coord1, adjusted_normal_time_spent, poi_rank, rating from poi_detail_table where city = '%s' and state = '%s'; \"%(city, state))\n",
    "    a = cur.fetchall()\n",
    "    conn.close()\n",
    "    return np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [2, 10, 14] [0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20]\n",
      "[2, 10, 14] wat\n",
      "293.0 wat [[ 275.         -122.42271178   37.82661824  180.            3.            4.5       ]\n",
      " [ 283.         -122.39371165   37.79535812  120.           11.            4.5       ]\n",
      " [ 287.         -122.38973205   37.77838412  120.           15.            4.5       ]]\n",
      "[2, 10, 14]\n"
     ]
    }
   ],
   "source": [
    "a1= db_start_location('San Francisco',\"California\",\"San Francisco\")\n",
    "poi_coords =  a1[:,1:3]\n",
    "n_days = 1\n",
    "current_events =[]\n",
    "big_ix, med_ix, small_ix =[],[],[]\n",
    "kmeans = KMeans(n_clusters=n_days).fit(poi_coords)\n",
    "i = 0\n",
    "for ix, label in enumerate(kmeans.labels_):\n",
    "#     print ix, label\n",
    "    if label == i:\n",
    "        time = a1[ix,3]\n",
    "        event_ix = a1[ix,0]\n",
    "        \n",
    "        current_events.append(event_ix)\n",
    "        if time > 180 :\n",
    "            big_ix.append(ix)\n",
    "\n",
    "        elif time >= 120 :\n",
    "            med_ix.append(ix)\n",
    "        else:\n",
    "            small_ix.append(ix)\n",
    "print big_ix, med_ix, small_ix\n",
    "# big_ = a1[[big_ix],4:]\n",
    "print med_ix, ('wat')\n",
    "print a1[ix,0], 'wat', a1[med_ix]\n",
    "print med_ix\n",
    "big_ = a1[big_ix][:,[0,4,5]]\n",
    "med_ = a1[med_ix][:,[0,4,5]]\n",
    "small_ = a1[small_ix][:,[0,4,5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 2, 5], [4, 2, 2], [1, 3, 3], [3, 4, 4]]\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "med_s= sorted(med_, key=itemgetter(1,2))\n",
    "a = [[1,3,3],[2,2,5],[3,4,4],[4,2,2]]\n",
    "# [sorted(a, key=itemgetter(1,2)) for i in range(100)]\n",
    "b = sorted(a, key=itemgetter(1,2))\n",
    "a.sort(key=lambda k: (k[1], -k[2]), reverse=False)\n",
    "# print med_s\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_cold_start_places(df,df_counties_u, day_trip_locations,full_trip_table,df_poi_travel_info,number_days = [1,2,3,4,5]):\n",
    "    \n",
    "    df_c = df_counties_u.groupby(['State full','County']).count().reset_index()\n",
    "    for state, county,_,_ in df_c.values[105:150]:\n",
    "        temp_df = df[(df['county'] == county) & (df['state'] == state)]\n",
    "        if temp_df.shape[0]!=0:\n",
    "            if sum(temp_df.adjusted_normal_time_spent) < 360:\n",
    "                number_days = [1]\n",
    "            elif sum(temp_df.adjusted_normal_time_spent) < 720:\n",
    "                number_days = [1,2]\n",
    "            big_events = temp_df[temp_df.adjusted_normal_time_spent > 180]\n",
    "            med_events = temp_df[(temp_df.adjusted_normal_time_spent>= 120)&(temp_df.adjusted_normal_time_spent<=180)]\n",
    "            small_events = temp_df[temp_df.adjusted_normal_time_spent < 120]\n",
    "            for i in number_days:\n",
    "                n_days = i\n",
    "                full_trip_table, day_trip_locations, new_trip_df1, df_poi_travel_info = \\\n",
    "                        default_search_cluster_events(df, df_counties_u, county, state, big_events,med_events, \\\n",
    "                                                      small_events, temp_df, n_days,day_trip_locations, full_trip_table,\\\n",
    "                                                      df_poi_travel_info)\n",
    "                print county, state\n",
    "                print full_trip_table.shape, len(day_trip_locations), new_trip_df1.shape, df_poi_travel_info.shape\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# full_trip_table = pd.DataFrame(columns =['user_id', 'full_trip_id', 'trip_location_ids', 'default', 'county', 'state', 'details', 'n_days'])\n",
    "\n",
    "# day_trip_locations_table = pd.DataFrame(columns =['trip_locations_id','full_day', 'default', 'county', 'state','details'])\n",
    "\n",
    "# google_travel_time_table = pd.DataFrame(columns =['id_','orig_name','orig_idx','dest_name','dest_idx','orig_coord0','orig_coord1',\\\n",
    "#                                        'dest_coord0','dest_coord1','orig_coords','dest_coords','google_driving_url',\\\n",
    "#                                        'google_walking_url','driving_result','walking_result','google_driving_time',\\\n",
    "#                                        'google_walking_time'])\n",
    "# google_travel_time_table.loc[0] = ['000000000001', \"home\", '0000', 'space', '0001', 999 ,999, 999.1,999.1, \"999,999\",\"999.1,999.1\",\"http://google.com\",\"http://google.com\", \"\", \"\", 0, 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# google_travel_time_table.index=google_travel_time_table.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# engine = create_engine('postgresql://Gon@localhost:5432/travel_with_friends')\n",
    "# # full_trip_table = pd.read_csv('./full_trip_table.csv', index_col= 0)\n",
    "# # full_trip_table.to_sql('full_trip_table', engine,if_exists='append')\n",
    "\n",
    "# full_trip_table.to_sql('full_trip_table',engine, if_exists = \"append\")\n",
    "# day_trip_locations_table.to_sql('day_trip_table',engine, if_exists = \"append\")\n",
    "# google_travel_time_table.to_sql('google_travel_time_table',engine, if_exists = \"append\")\n",
    "# # df.to_sql('poi_detail_table',engine, if_exists = \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trip_df_cloest_distance(trip_df, event_type):\n",
    "    points = trip_df[['coord0','coord1']].values.tolist()\n",
    "    n, D = mk_matrix(points, distL2) # create the distance matrix\n",
    "    if len(points) >= 3:\n",
    "        if event_type == 'big':\n",
    "            tour = nearest_neighbor(n, trip_df.shape[0]-1, D)     # create a greedy tour, visiting city 'i' first\n",
    "            z = length(tour, D)\n",
    "            z = localsearch(tour, z, D)\n",
    "        elif event_type == 'med':\n",
    "            tour = nearest_neighbor(n, trip_df.shape[0]-2, D)     # create a greedy tour, visiting city 'i' first\n",
    "            z = length(tour, D)\n",
    "            z = localsearch(tour, z, D)\n",
    "        else:\n",
    "            tour = nearest_neighbor(n, 0, D)     # create a greedy tour, visiting city 'i' first\n",
    "            z = length(tour, D)\n",
    "            z = localsearch(tour, z, D)\n",
    "        return tour\n",
    "    else:\n",
    "        return range(len(points))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_event_ids_list(trip_locations_id):\n",
    "    conn = psycopg2.connect(conn_str)  \n",
    "    cur = conn.cursor()  \n",
    "    cur.execute(\"select event_ids,event_type from day_trip_table where trip_locations_id = '%s' \" %(trip_locations_id))\n",
    "    event_ids,event_type = cur.fetchone()\n",
    "    event_ids = ast.literal_eval(event_ids)\n",
    "    conn.close()\n",
    "    return event_ids,event_type\n",
    "\n",
    "def db_event_cloest_distance(trip_locations_id=None,event_ids=None, event_type = 'add',new_event_id = None):\n",
    "    if new_event_id or not event_ids:\n",
    "        event_ids, event_type = get_event_ids_list(trip_locations_id)\n",
    "        if new_event_id:\n",
    "            event_ids.append(new_event_id)\n",
    "            \n",
    "    conn = psycopg2.connect(conn_str)  \n",
    "    cur = conn.cursor()\n",
    "    points = np.zeros((len(event_ids), 3))\n",
    "    for i,v in enumerate(event_ids):\n",
    "        cur.execute(\"select index, coord0, coord1 from poi_detail_table where index = %i;\"%(float(v)))\n",
    "        points[i] = cur.fetchone()\n",
    "    conn.close()\n",
    "    n,D = mk_matrix(points[:,1:], distL2)\n",
    "    if len(points) >= 3:\n",
    "        if event_type == 'add':\n",
    "            tour = nearest_neighbor(n, 0, D)\n",
    "            # create a greedy tour, visiting city 'i' first\n",
    "            z = length(tour, D)\n",
    "            z = localsearch(tour, z, D)\n",
    "            return np.array(event_ids)[tour], event_type\n",
    "        #need to figure out other cases\n",
    "        else:\n",
    "            tour = nearest_neighbor(n, 0, D)\n",
    "            # create a greedy tour, visiting city 'i' first\n",
    "            z = length(tour, D)\n",
    "            z = localsearch(tour, z, D)\n",
    "            return np.array(event_ids)[tour], event_type\n",
    "    else:\n",
    "        return np.array(event_ids), event_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_full_trip_id(full_trip_id, debug):\n",
    "    conn = psycopg2.connect(conn_str)  \n",
    "    cur = conn.cursor()  \n",
    "    cur.execute(\"select details from full_trip_table where full_trip_id = '%s'\" %(full_trip_id)) \n",
    "    a = cur.fetchone()\n",
    "    conn.close()\n",
    "    if bool(a):\n",
    "        if not debug: \n",
    "            return a[0]\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_day_trip_id(day_trip_id, debug):\n",
    "    conn = psycopg2.connect(conn_str)  \n",
    "    cur = conn.cursor()  \n",
    "    cur.execute(\"select details from day_trip_table where trip_locations_id = '%s'\" %(day_trip_id)) \n",
    "    a = cur.fetchone()\n",
    "    conn.close()\n",
    "    if bool(a):\n",
    "        if not debug: \n",
    "            return a[0]\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_travel_time_id(new_id):\n",
    "    conn = psycopg2.connect(conn_str)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"select google_driving_time from google_travel_time_table where id_ = '%s'\" %(new_id))\n",
    "    a = cur.fetchone()\n",
    "    conn.close()\n",
    "    if bool(a):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#need to check about the code!\n",
    "def sorted_events(info,ix):\n",
    "    '''\n",
    "    find the event_id, ranking and rating columns\n",
    "    sorted base on ranking then rating\n",
    "    \n",
    "    return sorted list \n",
    "    '''\n",
    "    event_ = info[ix][:,[0,4,5]]\n",
    "    return np.array(sorted(event_, key=lambda x: (x[1], -x[2])))\n",
    "\n",
    "def sorted_outside_events(info, ix):\n",
    "    '''\n",
    "    find the event_id, ranking and rating columns\n",
    "    sorted base on ranking then rating\n",
    "    \n",
    "    return sorted list \n",
    "    '''\n",
    "    event_ = info[:,[0,4,5]]\n",
    "    return np.array(sorted(event_, key=lambda x: (x[1], -x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 273.     1.     4.5]\n",
      " [ 274.     2.     4.5]\n",
      " [ 276.     4.     0. ]\n",
      " [ 277.     5.     0. ]\n",
      " [ 278.     6.     0. ]\n",
      " [ 279.     7.     4. ]\n",
      " [ 280.     8.     0. ]\n",
      " [ 281.     9.     0. ]\n",
      " [ 282.    10.     0. ]\n",
      " [ 284.    12.     4.5]\n",
      " [ 275.     3.     4.5]\n",
      " [ 283.    11.     4.5]]\n",
      "[273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 287.0]\n"
     ]
    }
   ],
   "source": [
    "med_[0,1] ,small_[0,1] , med_[0,0]\n",
    "# small_[0:8,0].concatenate(medium_[0:2,0])\n",
    "c = small_[0:10,]\n",
    "d = med_[0:2,]\n",
    "print np.vstack((c,d))\n",
    "# print list(np.array(sorted(np.vstack((c,d)), key=lambda x: (x[1],-x[2])))[:,0])\n",
    "print list(np.array(sorted(np.vstack((small_[0:10,:],med_)), key=lambda x: (x[1],-x[2])))[:,0])\n",
    "# np.vstack((small_[0:10,],med_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[273.0, 274.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 275.0, 283.0]\n",
      "[ 273.  281.  278.  277.  280.  283.  276.  274.  279.  275.] med\n"
     ]
    }
   ],
   "source": [
    "a_ids, a_type=create_event_id_list(big_,med_,small_)\n",
    "# conn = psycopg2.connect(conn_str)\n",
    "# cur = conn.cursor()\n",
    "# for i,v in enumerate(a_ids):\n",
    "# #     print i, v, type(v)\n",
    "#     cur.execute(\"select index, coord0, coord1 from poi_detail_table where index = %i;\"%(float(v)))\n",
    "#     aaa = cur.fetchone()\n",
    "# #     print aaa\n",
    "# conn.close()\n",
    "\n",
    "# new_a_ids, new_a_type=db_event_cloest_distance(event_ids = a_ids, event_type = a_type)\n",
    "# print new_a_ids, new_a_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_event_id_list(big_,medium_,small_):\n",
    "    event_type = ''\n",
    "    if big_.shape[0] >= 1:\n",
    "        if (medium_.shape[0] < 2) or (big_[0,1] <= medium_[0,1]):\n",
    "            if small_.shape[0] >= 6:\n",
    "                event_ids = list(np.concatenate((small_[0:6,0],big_[0,0]),axis=0))  \n",
    "            else:\n",
    "                event_ids = list(np.concatenate((small_[:,0],big_[0,0]),axis=0)) \n",
    "            event_type = 'big'\n",
    "        else:\n",
    "            if small_.shape[0] >= 8:\n",
    "                event_ids = list(np.concatenate((small_[0:8,0],medium_[0:2,0]),axis=0))\n",
    "            else:\n",
    "                event_ids = list(np.concatenate((small_[:,0],medium_[0:2,0]),axis=0))\n",
    "            event_type = 'med'\n",
    "    elif medium_.shape[0] >= 2:\n",
    "        if small_.shape[0] >= 8:\n",
    "            event_ids = list(np.concatenate((small_[0:8,0],medium_[0:2,0]),axis=0))\n",
    "        else:\n",
    "            event_ids = list(np.concatenate((small_[:,0],medium_[0:2,0]),axis=0))\n",
    "        event_type = 'med'\n",
    "    else:\n",
    "        if small_.shape[0] >= 10:\n",
    "            if not medium_.shape[0]:\n",
    "                event_ids = list(np.array(sorted(small_[0:10,:], key=lambda x: (x[1],-x[2])))[:,0])\n",
    "            else:\n",
    "                event_ids = list(np.array(sorted(np.vstack((small_[0:10,:],medium_)), key=lambda x: (x[1],-x[2])))[:,0])\n",
    "        else:\n",
    "            if not medium_.shape[0]:\n",
    "                event_ids = list(np.array(sorted(small_[0:10,:], key=lambda x: (x[1],-x[2])))[:,0])\n",
    "            else:\n",
    "                event_ids = list(np.array(sorted(np.vstack((small_,medium_)), key=lambda x: (x[1],-x[2])))[:,0])\n",
    "        event_type = 'small'\n",
    "    return event_ids, event_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'float'>\n"
     ]
    }
   ],
   "source": [
    "from geopy.distance import vincenty\n",
    "newport_ri = (41.49008, -70.312796)\n",
    "cleveland_oh = (41.499498, -81.695391)\n",
    "print(vincenty(newport_ri, cleveland_oh).miles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_trip_df(big_,medium_,small_):\n",
    "    event_type = ''\n",
    "    if big_.shape[0] >= 1:\n",
    "        if (medium_.shape[0] < 2) or (big_.iloc[0].poi_rank <= medium_.iloc[0].poi_rank):\n",
    "            if small_.shape[0] >= 6:\n",
    "                trip_df = small_.iloc[0:6].append(big_.iloc[0])\n",
    "            else:\n",
    "                trip_df = small_.append(big_.iloc[0])\n",
    "            event_type = 'big'\n",
    "        else:\n",
    "            if small_.shape[0] >= 8:\n",
    "                trip_df = small_.iloc[0:8].append(medium_.iloc[0:2])\n",
    "            else:\n",
    "                trip_df = small_.append(medium_.iloc[0:2])\n",
    "            event_type = 'med'\n",
    "    elif medium_.shape[0] >= 2:\n",
    "        if small_.shape[0] >= 8:\n",
    "            trip_df = small_.iloc[0:8].append(medium_.iloc[0:2])\n",
    "        else:\n",
    "            trip_df = small_.append(medium_.iloc[0:2])\n",
    "        event_type = 'med'\n",
    "    else:\n",
    "        if small_.shape[0] >= 10:\n",
    "            trip_df = small_.iloc[0:10].append(medium_).sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "        else:\n",
    "            trip_df = small_.append(medium_).sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "        event_type = 'small'\n",
    "    return trip_df, event_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_key = 'AIzaSyDJh9EWCA_v0_B3SvjzjUA3OSVYufPJeGE'\n",
    "# my_key = 'AIzaSyAwx3xg6oJ0yiPV3MIunBa1kx6N7v5Tcw8'\n",
    "def google_driving_walking_time(tour,trip_df,event_type):\n",
    "    poi_travel_time_df = pd.DataFrame(columns =['id_','orig_name','orig_idx','dest_name','dest_idx','orig_coord0','orig_coord1',\\\n",
    "                                   'dest_coord0','dest_coord1','orig_coords','dest_coords','google_driving_url',\\\n",
    "                                   'google_walking_url','driving_result','walking_result','google_driving_time',\\\n",
    "                                   'google_walking_time'])\n",
    "    ids_, orig_names,orid_idxs,dest_names,dest_idxs,orig_coord0s,orig_coord1s,dest_coord0s,dest_coord1s = [],[],[],[],[],[],[],[],[]\n",
    "    orig_coordss,dest_coordss,driving_urls,walking_urls,driving_results,walking_results,driving_times,walking_times = [],[],[],[],[],[],[],[]\n",
    "    trip_id_list=[]\n",
    "    for i in range(len(tour)-1):\n",
    "        id_ = str(trip_df.loc[trip_df.index[tour[i]]].name) + '0000'+str(trip_df.loc[trip_df.index[tour[i+1]]].name)\n",
    "        \n",
    "        result_check_travel_time_id = check_travel_time_id(id_)\n",
    "        if not result_check_travel_time_id:\n",
    "    \n",
    "            orig_name = trip_df.loc[trip_df.index[tour[i]]]['name']\n",
    "            orig_idx = trip_df.loc[trip_df.index[tour[i]]].name\n",
    "            dest_name = trip_df.loc[trip_df.index[tour[i+1]]]['name']\n",
    "            dest_idx = trip_df.loc[trip_df.index[tour[i+1]]].name\n",
    "            orig_coord0 = trip_df.loc[trip_df.index[tour[i]]]['coord0']\n",
    "            orig_coord1 = trip_df.loc[trip_df.index[tour[i]]]['coord1']\n",
    "            dest_coord0 = trip_df.loc[trip_df.index[tour[i+1]]]['coord0']\n",
    "            dest_coord1 = trip_df.loc[trip_df.index[tour[i+1]]]['coord1']\n",
    "            orig_coords = str(orig_coord1)+','+str(orig_coord0)\n",
    "            dest_coords = str(dest_coord1)+','+str(dest_coord0)\n",
    "            \n",
    "            google_driving_url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins={0}&destinations={1}&mode=driving&language=en-EN&sensor=false&key={2}\".\\\n",
    "                                    format(orig_coords.replace(' ',''),dest_coords.replace(' ',''),my_key)\n",
    "            google_walking_url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins={0}&destinations={1}&mode=walking&language=en-EN&sensor=false&key={2}\".\\\n",
    "                                    format(orig_coords.replace(' ',''),dest_coords.replace(' ',''),my_key)\n",
    "            driving_result= simplejson.load(urllib.urlopen(google_driving_url))\n",
    "            walking_result= simplejson.load(urllib.urlopen(google_walking_url))\n",
    "            \n",
    "            if driving_result['rows'][0]['elements'][0]['status'] == 'ZERO_RESULTS':\n",
    "                google_driving_url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins={0}&destinations={1}&mode=driving&language=en-EN&sensor=false&key={2}\".\\\n",
    "                                    format(orig_name.replace(' ','+').replace('-','+'),dest_name.replace(' ','+').replace('-','+'),my_key)\n",
    "                driving_result= simplejson.load(urllib.urlopen(google_driving_url))\n",
    "                \n",
    "            if walking_result['rows'][0]['elements'][0]['status'] == 'ZERO_RESULTS':\n",
    "                google_walking_url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins={0}&destinations={1}&mode=walking&language=en-EN&sensor=false&key={2}\".\\\n",
    "                                        format(orig_name.replace(' ','+').replace('-','+'),dest_name.replace(' ','+').replace('-','+'),my_key)\n",
    "                walking_result= simplejson.load(urllib.urlopen(google_walking_url))\n",
    "                \n",
    "            if (driving_result['rows'][0]['elements'][0]['status'] == 'NOT_FOUND') and (walking_result['rows'][0]['elements'][0]['status'] == 'NOT_FOUND'):\n",
    "                new_df = trip_df.drop(trip_df.iloc[tour[i+1]].name)\n",
    "                new_tour = trip_df_cloest_distance(new_df,event_type)\n",
    "                return google_driving_walking_time(new_tour,new_df, event_type)\n",
    "            try:\n",
    "                google_driving_time = driving_result['rows'][0]['elements'][0]['duration']['value']/60\n",
    "            except:            \n",
    "                print driving_result\n",
    "\n",
    "            try:\n",
    "                google_walking_time = walking_result['rows'][0]['elements'][0]['duration']['value']/60\n",
    "            except:\n",
    "                google_walking_time = 9999\n",
    "                \n",
    "            \n",
    "            poi_travel_time_df.loc[len(df_poi_travel_time)]=[id_,orig_name,orig_idx,dest_name,dest_idx,orig_coord0,orig_coord1,dest_coord0,\\\n",
    "                                   dest_coord1,orig_coords,dest_coords,google_driving_url,google_walking_url,\\\n",
    "                                   str(driving_result),str(walking_result),google_driving_time,google_walking_time]\n",
    "            driving_result = str(driving_result).replace(\"'\", '\"')\n",
    "            walking_result = str(walking_result).replace(\"'\", '\"')\n",
    "\n",
    "            conn = psycopg2.connect(conn_str)  \n",
    "            cur = conn.cursor()  \n",
    "            cur.execute(\"select max(index) from  google_travel_time_table\")\n",
    "            index = cur.fetchone()[0]+1\n",
    "#             print \"startindex:\",  index , type(index)\n",
    "#             index += 1\n",
    "#             print \"end index: \" ,index\n",
    "            cur.execute(\"INSERT INTO google_travel_time_table VALUES (%i, '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s','%s', '%s', '%s', '%s', '%s', '%s', %s, %s);\"%(index, id_, orig_name, orig_idx, dest_name, dest_idx, orig_coord0, orig_coord1, dest_coord0,\\\n",
    "                                   dest_coord1, orig_coords, dest_coords, google_driving_url, google_walking_url,\\\n",
    "                                   str(driving_result), str(walking_result), google_driving_time, google_walking_time))\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "        else:\n",
    "            trip_id_list.append(id_)\n",
    "    \n",
    "    return tour, trip_df, poi_travel_time_df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def db_google_driving_walking_time(event_ids, event_type):\n",
    "    conn = psycopg2.connect(conn_str)  \n",
    "    cur = conn.cursor()  \n",
    "    google_ids = []\n",
    "    driving_time_list = []\n",
    "    walking_time_list = []\n",
    "    name_list = []\n",
    "    for i,v in enumerate(event_ids[:-1]):\n",
    "        id_ = str(v) + '0000'+str(event_ids[i+1])\n",
    "        result_check_travel_time_id = check_travel_time_id(id_)\n",
    "        if not result_check_travel_time_id:\n",
    "            cur.execute(\"select name, coord0, coord1 from poi_detail_table where index = %s\"%(v))\n",
    "            orig_name, orig_coord0, orig_coord1 = cur.fetchone()\n",
    "            orig_idx = v\n",
    "            cur.execute(\"select name, coord0, coord1 from poi_detail_table where index = %s \"%(event_ids[i+1]))\n",
    "            dest_name, dest_coord0, dest_coord1 = cur.fetchone()\n",
    "            dest_idx = event_ids[i+1]\n",
    "            orig_coords = str(orig_coord1)+','+str(orig_coord0)\n",
    "            dest_coords = str(dest_coord1)+','+str(dest_coord0)\n",
    "            google_driving_url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins={0}&destinations={1}&mode=driving&language=en-EN&sensor=false&key={2}\".\\\n",
    "                                    format(orig_coords.replace(' ',''),dest_coords.replace(' ',''),my_key)\n",
    "            google_walking_url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins={0}&destinations={1}&mode=walking&language=en-EN&sensor=false&key={2}\".\\\n",
    "                                    format(orig_coords.replace(' ',''),dest_coords.replace(' ',''),my_key)\n",
    "            driving_result= simplejson.load(urllib.urlopen(google_driving_url))\n",
    "            walking_result= simplejson.load(urllib.urlopen(google_walking_url))\n",
    "            if driving_result['rows'][0]['elements'][0]['status'] == 'ZERO_RESULTS':\n",
    "                google_driving_url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins={0}&destinations={1}&mode=driving&language=en-EN&sensor=false&key={2}\".\\\n",
    "                                    format(orig_name.replace(' ','+').replace('-','+'),dest_name.replace(' ','+').replace('-','+'),my_key)\n",
    "                driving_result= simplejson.load(urllib.urlopen(google_driving_url))\n",
    "                \n",
    "            if walking_result['rows'][0]['elements'][0]['status'] == 'ZERO_RESULTS':\n",
    "                google_walking_url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins={0}&destinations={1}&mode=walking&language=en-EN&sensor=false&key={2}\".\\\n",
    "                                        format(orig_name.replace(' ','+').replace('-','+'),dest_name.replace(' ','+').replace('-','+'),my_key)\n",
    "                walking_result= simplejson.load(urllib.urlopen(google_walking_url))\n",
    "            if (driving_result['rows'][0]['elements'][0]['status'] == 'NOT_FOUND') and (walking_result['rows'][0]['elements'][0]['status'] == 'NOT_FOUND'):\n",
    "                new_event_ids = list(event_ids)\n",
    "                new_event_ids.pop(i+1)\n",
    "                new_event_ids = db_event_cloest_distance(event_ids=new_event_ids, event_type = event_type)\n",
    "                return db_google_driving_walking_time(new_event_ids, event_type)\n",
    "            try:\n",
    "                google_driving_time = driving_result['rows'][0]['elements'][0]['duration']['value']/60\n",
    "            except:            \n",
    "                print v, id_, driving_result #need to debug for this\n",
    "            try:\n",
    "                google_walking_time = walking_result['rows'][0]['elements'][0]['duration']['value']/60\n",
    "            except:\n",
    "                google_walking_time = 9999\n",
    "        \n",
    "            cur.execute(\"select max(index) from  google_travel_time_table\")\n",
    "            index = cur.fetchone()[0]+1\n",
    "            driving_result = str(driving_result).replace(\"'\",'\"')\n",
    "            walking_result = str(walking_result).replace(\"'\",'\"')\n",
    "            orig_name = orig_name.replace(\"'\",\"''\")\n",
    "            dest_name = dest_name.replace(\"'\",\"''\")\n",
    "            cur.execute(\"INSERT INTO google_travel_time_table VALUES (%i, '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s','%s', '%s', '%s', '%s', '%s', '%s', %s, %s);\"%(index, id_, orig_name, orig_idx, dest_name, dest_idx, orig_coord0, orig_coord1, dest_coord0,\\\n",
    "                                   dest_coord1, orig_coords, dest_coords, google_driving_url, google_walking_url,\\\n",
    "                                   str(driving_result), str(walking_result), google_driving_time, google_walking_time))\n",
    "            conn.commit()\n",
    "            name_list.append(orig_name+\" to \"+ dest_name)\n",
    "            google_ids.append(id_)\n",
    "            driving_time_list.append(google_driving_time)\n",
    "            walking_time_list.append(google_walking_time)\n",
    "        else:\n",
    "            \n",
    "            cur.execute(\"select orig_name, dest_name, google_driving_time, google_walking_time from google_travel_time_table \\\n",
    "                         where id_ = '%s'\" %(id_))\n",
    "            orig_name, dest_name, google_driving_time, google_walking_time = cur.fetchone()\n",
    "            name_list.append(orig_name+\" to \"+ dest_name)\n",
    "            google_ids.append(id_)\n",
    "            driving_time_list.append(google_driving_time)\n",
    "            walking_time_list.append(google_walking_time)\n",
    "            \n",
    "    \n",
    "    conn.close()\n",
    "    return event_ids, google_ids, name_list, driving_time_list, walking_time_list\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2259L, 'San Diego Zoo Safari Park', '15500 San Pasqual Valley Rd, Escondido, CA 92027, USA')\n"
     ]
    }
   ],
   "source": [
    "trip_locations_id = 'CALIFORNIA-SAN-DIEGO-1-3-0'\n",
    "default = 1\n",
    "n_days =3\n",
    "full_day = 1\n",
    "poi_coords = df_events[['coord0','coord1']]\n",
    "trip_location_ids, full_trip_details =[],[]\n",
    "kmeans = KMeans(n_clusters=n_days).fit(poi_coords)\n",
    "# print kmeans.labels_\n",
    "i=0\n",
    "current_events = []\n",
    "big_ix = []\n",
    "small_ix = []\n",
    "med_ix = []\n",
    "for ix, label in enumerate(kmeans.labels_):\n",
    "    if label == i:\n",
    "        time = df_events.iloc[ix].adjusted_normal_time_spent\n",
    "        event_ix = df_events.iloc[ix].name\n",
    "        current_events.append(event_ix)\n",
    "        if time > 180 :\n",
    "            big_ix.append(event_ix)\n",
    "        elif time >= 120 :\n",
    "            med_ix.append(event_ix)\n",
    "        else:\n",
    "            small_ix.append(event_ix)\n",
    "\n",
    "#         all_big = big.sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "big_ = df_events.loc[big_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "small_ = df_events.loc[small_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "medium_ = df_events.loc[med_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "\n",
    "# trip_df, event_type = create_trip_df(big_,medium_,small_)\n",
    "# tour = trip_df_cloest_distance(trip_df, event_type)\n",
    "# new_tour, new_trip_df, df_poi_travel_time = google_driving_walking_time(tour,trip_df,event_type)\n",
    "# new_trip_df = new_trip_df.iloc[new_tour]\n",
    "# new_trip_df1,new_df_poi_travel_time,total_time = remove_extra_events(new_trip_df, df_poi_travel_time)\n",
    "# new_trip_df1['address'] = df_addresses(new_trip_df1, new_df_poi_travel_time)\n",
    "\n",
    "event_ids, event_type=db_event_cloest_distance(trip_locations_id)\n",
    "event_ids, google_ids, name_list, driving_time_list, walking_time_list =db_google_driving_walking_time(event_ids, event_type)\n",
    "event_ids, driving_time_list, walking_time_list, total_time_spent = db_remove_extra_events(event_ids, driving_time_list, walking_time_list)\n",
    "db_address(event_ids)\n",
    "values = day_trip(event_ids, county, state, default, full_day,n_days,i)\n",
    "day_trip_locations.loc[len(day_trip_locations)] = values\n",
    "trip_location_ids.append(values[0])\n",
    "full_trip_details.extend(values[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_small_med_big_ix(county_list_info, day_labels):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fulltrip_data_default(state, city, n_days, day_trip_locations = True, full_trip_table = True, default = True, debug = True):\n",
    "    county = find_county(state, city)\n",
    "    trip_location_ids, full_trip_details =[],[]\n",
    "    full_trip_id = '-'.join([str(state.upper()), str(county.upper().replace(' ','-')),str(int(default)), str(n_days)])\n",
    "    \n",
    "    if not check_full_trip_id(full_trip_id, debug):\n",
    "        county_list_info = db_start_location(county, state, city)\n",
    "        poi_coords = county_list_info[:,1:3]\n",
    "        kmeans = KMeans(n_clusters=n_days).fit(poi_coords)\n",
    "        day_labels = kmeans.labels_\n",
    "        for i in range(n_days):\n",
    "            \n",
    "            if not check_day_trip_id(day_trip, debug):\n",
    "                trip_locations_id = '-'.join([str(state), str(county.replace(' ','-')),str(int(default)), str(n_days),str(i)])\n",
    "                current_events, big_ix, small_ix, med_ix = [],[],[],[]\n",
    "\n",
    "                for ix, label in enumerate(day_labels):\n",
    "                    if label == i:\n",
    "                        time = county_list_info[ix,3]\n",
    "                        event_ix = county_list_info[ix,0]\n",
    "                        current_events.append(event_ix)\n",
    "                        if time > 180 :\n",
    "                            big_ix.append(ix)\n",
    "                        elif time >= 120 :\n",
    "                            med_ix.append(ix)\n",
    "                        else:\n",
    "                            small_ix.append(ix)\n",
    "                            \n",
    "                #need to double check this funct!\n",
    "                big_ = sorted_events(county_list_info, big_ix)\n",
    "                med_ = sorted_events(county_list_info, med_ix)\n",
    "                small_ = sorted_events(county_list_info, small_ix)\n",
    "                \n",
    "                event_ids, event_type = create_event_id_list(big_, med_, small_)\n",
    "                event_ids, event_type = db_event_cloest_distance(event_ids = event_ids, event_type = event_type)\n",
    "                event_ids, google_ids, name_list, driving_time_list, walking_time_list =db_google_driving_walking_time(event_ids, event_type)\n",
    "                event_ids, driving_time_list, walking_time_list, total_time_spent = db_remove_extra_events(event_ids, driving_time_list, walking_time_list)\n",
    "                db_address(event_ids)\n",
    "                details = db_day_trip(event_ids, i)\n",
    "#                 insert to day_trip ....\n",
    "                conn = psycopg2.connect(conn_str)\n",
    "                cur = conn.cursor()\n",
    "                cur.execute(\"insert into day_trip_table (trip_locations_id,full_day, default, county, state, details, event_type, event_ids) VALUES ( '%s', %s, %s, '%s', '%s', '%s', '%s', '%s')\" %( trip_location_id, full_day, default, county, state, details, event_type, event_ids))\n",
    "                conn.commit()\n",
    "                conn.close()\n",
    "                trip_location_ids.append(trip_locations_id)\n",
    "                full_trip_details.extend(details)\n",
    "\n",
    "            else:\n",
    "                print \"error: already have this day, please check the next day\"\n",
    "                trip_location_ids.append(trip_locations_id)\n",
    "#                 call db find day trip detail \n",
    "                conn = psycopg2.connect(conn_str)\n",
    "                cur = conn.cursor()\n",
    "                cur.execute(\"select details from day_trip_table where trip_locations_id = '%s';\"%(trip_locations_id) )\n",
    "                day_trip_detail = fetchall()\n",
    "                conn.close()\n",
    "                full_trip_details.extend(day_trip_detail)\n",
    "\n",
    "        full_trip_id = '-'.join([str(state.upper()), str(county.upper().replace(' ','-')),str(int(default)), str(n_days)])\n",
    "        details = full_trip_details\n",
    "        user_id = \"Admin\"\n",
    "        conn = psycopg2.connect(conn_str)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"insert into full_trip_table(user_id, full_trip_id,trip_location_ids, default, county, state, details, n_days) VALUES ('%s', '%s', '%s', %s, '%s', '%s', '%s', %s)\" %(user_id, full_trip_id, str(trip_location_ids), default, county, state, details, n_days))\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "        return \"finish update %s, %s into database\" %(state, county)\n",
    "    else:\n",
    "        return \"%s, %s already in database\" %(state, county) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def db_day_trip(event_ids, county, state, default, full_day,n_days,i):\n",
    "    conn=psycopg2.connect(conn_str)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "#     cur.execute(\"select state, county, count(*) AS count from poi_detail_table where index in %s GROUP BY state, county order by count desc;\" %(tuple(test_event_ids_list),))\n",
    "#     a = cur.fetchall()\n",
    "#     state = a[0][0].upper()\n",
    "#     county = a[0][1].upper()\n",
    "\n",
    "    trip_locations_id = '-'.join([str(state), str(county.replace(' ','-')),str(int(default)), str(n_days),str(i)])\n",
    "\n",
    "    #details dict includes: id, name,address, day\n",
    "\n",
    "    cur.execute(\"select index, name, address from poi_detail_table where index in %s;\" %(tuple(event_ids),))\n",
    "    a = cur.fetchall()\n",
    "    details = [str({'id': a[x][0],'name': a[x][1],'address': a[x][2], 'day': i}) for x in range(len(a))]\n",
    "    conn.close()\n",
    "    return [trip_locations_id, full_day, default, county, state, details]\n",
    "\n",
    "\n",
    "def db_day_trip(event_ids, i):\n",
    "    conn=psycopg2.connect(conn_str)\n",
    "    cur = conn.cursor()\n",
    "    details = []\n",
    "    #details dict includes: id, name,address, day\n",
    "    for event_id in event_ids:\n",
    "        cur.execute(\"select index, name, address from poi_detail_table where index = %s;\" %(event_id))\n",
    "        a = cur.fetchone()\n",
    "        details.append(str({'id': a[0],'name': a[1],'address': a[2], 'day': i}))\n",
    "    conn.close()\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn=psycopg2.connect(conn_str)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select state, county, count(*) AS count from poi_detail_table where index in %s GROUP BY state, county order by count desc;\" %(tuple(test_event_ids_list),))\n",
    "a = cur.fetchall()\n",
    "print a[0][0].upper()\n",
    "# details = [str({'id': a[x][0],'name': a[x][1],'address': a[x][2], 'day': i}) for x in range(a)]\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extend_full_trip_details(full_trip_details):\n",
    "    details = {}\n",
    "    addresses = []\n",
    "    ids = []\n",
    "    days = []\n",
    "    names = []\n",
    "    for item in full_trip_details:\n",
    "        addresses.append(eval(item)['address'])\n",
    "        ids.append(eval(item)['id'])\n",
    "        days.append(eval(item)['day'])\n",
    "        names.append(eval(item)['name'])\n",
    "    details['addresses'] = addresses\n",
    "    details['ids'] = ids\n",
    "    details['days'] = days\n",
    "    details['names'] = names\n",
    "    return str(full_trip_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2259, 2260, 3486, 3487, 4951, 4953, 4952])"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2259 2260 3486 3487 4951 4953 4952] ['225900002260', '226000003486', '348600003487', '348700004951', '495100004953', '495300004952'] ['San Diego Zoo Safari Park to Meerkat', 'Meerkat to Stone', 'Stone to Stone Brewery', 'Stone Brewery to Lake Poway', 'Lake Poway to Potato Chip Rock', 'Potato Chip Rock to Mt. Woodson'] [3.0, 25.0, 0.0, 25.0, 25.0, 0.0] [7.0, 193.0, 0.0, 268.0, 99.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print event_ids, google_ids, name_list, driving_time_list, walking_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_db_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_extra_events(trip_df, df_poi_travel_time):\n",
    "    if sum(trip_df.adjusted_normal_time_spent)+sum(df_poi_travel_time.google_driving_time) > 480:\n",
    "        new_trip_df = trip_df[:-1]\n",
    "        new_df_poi_travel_time = df_poi_travel_time[:-1]\n",
    "        return remove_extra_events(new_trip_df,new_df_poi_travel_time)\n",
    "    else:\n",
    "        return trip_df, df_poi_travel_time, sum(trip_df.adjusted_normal_time_spent)+sum(df_poi_travel_time.google_driving_time)\n",
    "def db_remove_extra_events(event_ids, driving_time_list,walking_time_list, max_time_spent=480):\n",
    "    conn = psycopg2.connect(conn_str)\n",
    "    cur = conn.cursor()   \n",
    "    cur.execute(\"select sum (adjusted_normal_time_spent) from poi_detail_table where index in %s;\" %(tuple(event_ids),))\n",
    "    time_spent = cur.fetchone()[0]\n",
    "    conn.close()\n",
    "    time_spent += sum(np.minimum(np.array(driving_time_list),np.array(walking_time_list)))\n",
    "    if time_spent > max_time_spent:\n",
    "        update_event_ids = event_ids[:-1]\n",
    "        update_driving_time_list = driving_time_list[:-1]\n",
    "        update_walking_time_list = walking_time_list[:-1]\n",
    "        return db_remove_extra_events(update_event_ids, update_driving_time_list, update_walking_time_list)\n",
    "    else:\n",
    "        return event_ids, driving_time_list, walking_time_list, time_spent\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def df_addresses(new_trip_df1, new_df_poi_travel_time):\n",
    "    my_lst = []\n",
    "    print new_trip_df1.index.values\n",
    "    for i in new_trip_df1.index.values:\n",
    "        temp_df = new_df_poi_travel_time[i == new_df_poi_travel_time.orig_idx.values]\n",
    "        if temp_df.shape[0]>0:\n",
    "            address = eval(temp_df.driving_result.values[0])['origin_addresses'][0]\n",
    "            my_lst.append(address)\n",
    "        else:\n",
    "            try:\n",
    "                temp_df = new_df_poi_travel_time[i == new_df_poi_travel_time.dest_idx.values]\n",
    "                address = eval(temp_df.driving_result.values[0])['destination_addresses'][0]\n",
    "                my_lst.append(address)\n",
    "            except:\n",
    "                print new_trip_df1, new_df_poi_travel_time\n",
    "    return my_lst\n",
    "\n",
    "def check_address(index):\n",
    "    conn = psycopg2.connect(conn_str)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"select address from poi_detail_table where index = %s;\"%(index))\n",
    "    a = cur.fetchone()[0]\n",
    "    conn.close()\n",
    "    if a:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def db_address(event_ids):\n",
    "    conn = psycopg2.connect(conn_str)\n",
    "    cur = conn.cursor()\n",
    "    for i in event_ids[:-1]:\n",
    "        if not check_address(i):\n",
    "            cur.execute(\"select driving_result from google_travel_time_table where orig_idx = %s;\" %(i))\n",
    "            a= cur.fetchone()[0]\n",
    "            add = ast.literal_eval(a)['origin_addresses'][0]\n",
    "            cur.execute(\"update poi_detail_table set address = '%s' where index = %s;\" %(add, i))\n",
    "            conn.commit()\n",
    "    last = event_ids[-1]\n",
    "    if not check_address(last):\n",
    "        cur.execute(\"select driving_result from google_travel_time_table where dest_idx = %s;\" %(last))\n",
    "        a= cur.fetchone()[0]\n",
    "        add = ast.literal_eval(a)['destination_addresses'][0]\n",
    "        cur.execute(\"update poi_detail_table set address = '%s' where index = %s;\" %(add, last))\n",
    "        conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 273 2259 2260 3486 3487 4951 4953 4952]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "\n",
    "test_event_ids_list =  append(273, event_ids)\n",
    "# event_ids\n",
    "print test_event_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALIFORNIA\n"
     ]
    }
   ],
   "source": [
    "conn=psycopg2.connect(conn_str)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select state, county, count(*) AS count from poi_detail_table where index in %s GROUP BY state, county order by count desc;\" %(tuple(test_event_ids_list),))\n",
    "a = cur.fetchall()\n",
    "print a[0][0].upper()\n",
    "# details = [str({'id': a[x][0],'name': a[x][1],'address': a[x][2], 'day': i}) for x in range(a)]\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_trip_locations = 'San Diego, California'\n",
    "\n",
    "f, d, n, d= search_cluster_events(df, county, state, city, 3, day_trip_locations, full_trip_table, default = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 2, 6], [1, 2, 3], [4, 3, 10], [3, 3, 3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0008938312530517578"
      ]
     },
     "execution_count": 1095,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "t1=time.time()\n",
    "# [index, ranking,score]\n",
    "a = [[1,2,3],[2,2,6],[3,3,3],[4,3,10]]\n",
    "from operator import itemgetter\n",
    "print sorted(a, key=lambda x: (x[1], -x[2]))\n",
    "\n",
    "time.time()-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Most important event that will call all the functions and return the day details for the trip\n",
    "'''\n",
    "\n",
    "\n",
    "def search_cluster_events(df, county, state, city, n_days, day_trip_locations = True, full_trip_table = True, default = True, debug = True):\n",
    "    \n",
    "    county, df_events =cold_start_places(df, county, state, city, n_days) \n",
    "    \n",
    "    poi_coords = df_events[['coord0','coord1']]\n",
    "    kmeans = KMeans(n_clusters=n_days).fit(poi_coords)\n",
    "\n",
    "    new_trip_id = '-'.join([str(state.upper()), str(county.upper().replace(' ','-')),str(int(default)), str(n_days)])\n",
    "    if not check_full_trip_id(new_trip_id, debug):\n",
    "        \n",
    "        trip_location_ids = []\n",
    "        full_trip_details = []\n",
    "        for i in range(n_days):\n",
    "            current_events = []\n",
    "            big_ix = []\n",
    "            small_ix = []\n",
    "            med_ix = []\n",
    "            for ix, label in enumerate(kmeans.labels_):\n",
    "                if label == i:\n",
    "                    event_ix = poi_coords.index[ix]\n",
    "                    current_events.append(event_ix)\n",
    "                    if event_ix in big.index:\n",
    "                        big_ix.append(event_ix)\n",
    "                    elif event_ix in med.index:\n",
    "                        med_ix.append(event_ix)\n",
    "                    else:\n",
    "                        small_ix.append(event_ix)\n",
    "#             all_big = big.sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "            big_ = big.loc[big_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "            small_ = small.loc[small_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "            medium_ = med.loc[med_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "    #         print 'big:', big_, 'small:', small_, 'msize:', medium_\n",
    "            trip_df, event_type = create_trip_df(big_,medium_,small_)\n",
    "    #         print event_type\n",
    "            tour = trip_df_cloest_distance(trip_df, event_type)\n",
    "    #         print tour\n",
    "            new_tour, new_trip_df, df_poi_travel_time = google_driving_walking_time(tour,trip_df,event_type)\n",
    "    #         print new_tour, new_trip_df\n",
    "    #         return new_trip_df, df_poi_travel_time\n",
    "            new_trip_df = new_trip_df.iloc[new_tour]\n",
    "            new_trip_df1,new_df_poi_travel_time,total_time = remove_extra_events(new_trip_df, df_poi_travel_time)\n",
    "    #         print new_trip_df1\n",
    "            new_trip_df1['address'] = df_addresses(new_trip_df1, new_df_poi_travel_time)\n",
    "    #         print 'total time:', total_ti\n",
    "            values = day_trip(new_trip_df1, county, state, default, full_day,n_days,i)\n",
    "            day_trip_locations.loc[len(day_trip_locations)] = values\n",
    "            trip_location_ids.append(values[0])\n",
    "            full_trip_details.extend(values[-1])\n",
    "            df_poi_travel_info = df_poi_travel_info.append(new_df_poi_travel_time)\n",
    "            \n",
    "    full_trip_id = '-'.join([str(state.upper()), str(county.upper().replace(' ','-')),str(int(default)), str(n_days)])\n",
    "    details = extend_full_trip_details(full_trip_details)\n",
    "    full_trip_table.loc[len(full_trip_table)] = [\"adam\", full_trip_id, str(trip_location_ids), default, county, state, details, n_days]\n",
    "    \n",
    "    \n",
    "    return full_trip_table, day_trip_locations, new_trip_df1, df_poi_travel_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_search_cluster_events(df, df_counties_u, county, state, big,med, small, \\\n",
    "                                  temp, n_days,day_trip_locations, full_trip_table,df_poi_travel_info):\n",
    "#     df_poi_travel_info = pd.DataFrame(columns =['id_','orig_name','orig_idx','dest_name','dest_idx','orig_coord0','orig_coord1',\\\n",
    "#                                        'dest_coord0','dest_coord1','orig_coords','dest_coords','google_driving_url',\\\n",
    "#                                        'google_walking_url','driving_result','walking_result','google_driving_time',\\\n",
    "#                                        'google_walking_time'])\n",
    "    poi_coords = temp[['coord0','coord1']]\n",
    "    kmeans = KMeans(n_clusters=n_days, random_state=0).fit(poi_coords)\n",
    "#     print kmeans.labels_\n",
    "    full_trip_id = '-'.join([str(state.upper()), str(county.upper().replace(' ','-')),str(int(default)), str(n_days)])\n",
    "    trip_location_ids = []\n",
    "    full_trip_details = []\n",
    "    for i in range(n_days):\n",
    "        current_events = []\n",
    "        big_ix = []\n",
    "        small_ix = []\n",
    "        med_ix = []\n",
    "        for ix, label in enumerate(kmeans.labels_):\n",
    "            if label == i:\n",
    "                event_ix = poi_coords.index[ix]\n",
    "                current_events.append(event_ix)\n",
    "                if event_ix in big.index:\n",
    "                    big_ix.append(event_ix)\n",
    "                elif event_ix in med.index:\n",
    "                    med_ix.append(event_ix)\n",
    "                else:\n",
    "                    small_ix.append(event_ix)\n",
    "        all_big = big.sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "        big_ = big.loc[big_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "        small_ = small.loc[small_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "        medium_ = med.loc[med_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "        trip_df, event_type = create_trip_df(big_,medium_,small_)\n",
    "        tour = trip_df_cloest_distance(trip_df, event_type)\n",
    "        new_tour, new_trip_df, df_poi_travel_time = google_driving_walking_time(tour,trip_df,event_type)\n",
    "        new_trip_df = new_trip_df.iloc[new_tour]\n",
    "        new_trip_df1,new_df_poi_travel_time,total_time = remove_extra_events(new_trip_df, df_poi_travel_time)\n",
    "        new_trip_df1['address'] = df_addresses(new_trip_df1, new_df_poi_travel_time)\n",
    "        values = day_trip(new_trip_df1, county, state, default, full_day,n_days,i)\n",
    "        day_trip_locations.loc[len(day_trip_locations)] = values\n",
    "        trip_location_ids.append(values[0])\n",
    "        full_trip_details.extend(values[-1])\n",
    "#         print 'trave time df \\n',new_df_poi_travel_time\n",
    "        df_poi_travel_info = df_poi_travel_info.append(new_df_poi_travel_time)\n",
    "    full_trip_id = '-'.join([str(state.upper()), str(county.upper().replace(' ','-')),str(int(default)), str(n_days)])\n",
    "    details = extend_full_trip_details(full_trip_details)\n",
    "    full_trip_table.loc[len(full_trip_table)] = [user_id, full_trip_id, \\\n",
    "                                                 str(trip_location_ids), default, county, state, details, n_days]\n",
    "    return full_trip_table, day_trip_locations, new_trip_df1, df_poi_travel_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Next Steps: Add control from the users. funt1: allow to add events,(specific name or auto add)\n",
    "### auto route to the most appropirate order\n",
    "###funt2: allow to reorder the events. funt3: allow to delete the events. \n",
    "###funt4: allow to switch a new event-next to the switch and x mark icon,check mark to confirm the new place and auto order\n",
    "\n",
    "###New table for the trip info...features including trip id, event place, days, specific date, trip details. (trip tour, trip)\n",
    "\n",
    "def ajax_available_events(county, state):\n",
    "    county=county.upper()\n",
    "    state = state.title()\n",
    "    conn = psycopg2.connect(conn_str)   \n",
    "    cur = conn.cursor()   \n",
    "    cur.execute(\"select index, name from poi_detail_table where county='%s' and state='%s'\" %(county,state))  \n",
    "    poi_lst = [item for item in cur.fetchall()]\n",
    "    conn.close()\n",
    "    return poi_lst\n",
    "\n",
    "def add_event(trip_locations_id, event_day, event_id=None, event_name=None, full_day = True, unseen_event = False):\n",
    "    conn = psycopg2.connect(conn_str)   \n",
    "    cur = conn.cursor()   \n",
    "    cur.execute(\"select * from day_trip_table where trip_locations_id='%s'\" %(trip_locations_id))  \n",
    "    (index, trip_locations_id, full_day, default, county, state, detail, event_type, event_ids) = cur.fetchone()\n",
    "    if unseen_event:\n",
    "        index += 1\n",
    "        trip_locations_id = '-'.join([str(eval(i)['id']) for i in eval(detail)])+'-'+event_name.replace(' ','-')+'-'+event_day\n",
    "        cur.execute(\"select details from day_trip_locations where trip_locations_id='%s'\" %(trip_locations_id))\n",
    "        a = cur.fetchone()\n",
    "        if bool(a):\n",
    "            conn.close()\n",
    "            return trip_locations_id, a[0]\n",
    "        else:\n",
    "            cur.execute(\"select max(index) from day_trip_locations\")\n",
    "            index = cur.fetchone()[0]+1\n",
    "            detail = list(eval(detail))\n",
    "            #need to make sure the type is correct for detail!\n",
    "            new_event = \"{'address': 'None', 'id': 'None', 'day': %s, 'name': u'%s'}\"%(event_day, event_name)\n",
    "            detail.append(new_event)\n",
    "            #get the right format of detail: change from list to string and remove brackets and convert quote type\n",
    "            new_detail = str(detail).replace('\"','').replace('[','').replace(']','').replace(\"'\",'\"')\n",
    "            cur.execute(\"INSERT INTO day_trip_locations VALUES (%i, '%s',%s,%s,'%s','%s','%s');\" %(index, trip_locations_id, full_day, False, county, state, new_detail))\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            return trip_locations_id, detail\n",
    "    else:\n",
    "        event_ids = add_event_cloest_distance(trip_locations_id, event_id)\n",
    "        event_ids, google_ids, name_list, driving_time_list, walking_time_list = db_google_driving_walking_time(event_ids,event_type = 'add')\n",
    "        trip_locations_id = '-'.join(event_ids)+'-'+event_day\n",
    "        cur.execute(\"select details from day_trip_locations where trip_locations_id='%s'\" %(trip_locations_id)) \n",
    "        a = cur.fetchone()\n",
    "        if not a:\n",
    "            details = []\n",
    "            db_address(event_ids)\n",
    "            for item in event_ids:\n",
    "                cur.execute(\"select index, name, address from poi_detail_table where index = '%s';\" %(item))\n",
    "                a = cur.fetchone()\n",
    "                detail = {'id': a[0],'name': a[1],'address': a[2], 'day': event_day}\n",
    "                details.append(detail)\n",
    "            #need to make sure event detail can append to table!\n",
    "            cur.execute(\"insert into day_trip_table (trip_locations_id,full_day, default, county, state, details, event_type, event_ids) VALUES ( '%s', %s, %s, '%s', '%s', '%s', '%s', '%s')\" %( trip_location_id, full_day, False, county, state, details, event_type, event_ids))\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            return trip_locations_id, details\n",
    "        else:\n",
    "            conn.close()\n",
    "            #need to make sure type is correct.\n",
    "            return trip_locations_id, a[0]\n",
    "\n",
    "def remove_event(trip_locations_id, remove_event_id, remove_event_name=None, event_day=None, full_day = True):\n",
    "    conn = psycopg2.connect(conn_str)   \n",
    "    cur = conn.cursor()   \n",
    "    cur.execute(\"select * from day_trip_table where trip_locations_id='%s'\" %(trip_locations_id))  \n",
    "    (index, trip_locations_id, full_day, default, county, state, detail, event_type, event_ids) = cur.fetchone()\n",
    "    new_event_ids = ast.literal_eval(event_ids)\n",
    "    new_event_ids.remove(remove_event_id)\n",
    "    new_trip_locations_id = '-'.join(str(event_id) for event_id in new_event_ids)\n",
    "    cur.execute(\"select * from day_trip_table where trip_locations_id='%s'\" %(new_trip_locations_id))  \n",
    "    check_id = cur.fetchone()\n",
    "    if check_id:\n",
    "        return new_trip_locations_id, check_id[-3]\n",
    "    detail = ast.literal_eval(detail[1:-1])\n",
    "    for index, trip_detail in enumerate(detail):\n",
    "        if ast.literal_eval(trip_detail)['id'] == remove_event_id:\n",
    "            remove_index = index\n",
    "            break\n",
    "    new_detail = list(detail)\n",
    "    new_detail.pop(remove_index)\n",
    "    new_detail =  str(new_detail).replace(\"'\",\"''\")\n",
    "    default = False\n",
    "    cur.execute(\"select max(index) from day_trip_table where trip_locations_id='%s'\" %(trip_locations_id)) \n",
    "    new_index = cur.fetchone()[0]\n",
    "    new_index+=1\n",
    "    cur.execute(\"INSERT INTO day_trip_table VALUES (%i, '%s', %s, %s, '%s', '%s', '%s', '%s','%s');\" \\\n",
    "                %(new_index, new_trip_locations_id, full_day, default, county, state, new_detail, event_type, new_event_ids))  \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return new_trip_locations_id, new_detail\n",
    "\n",
    "def event_type_time_spent(adjusted_normal_time_spent):\n",
    "    if adjusted_normal_time_spent > 180:\n",
    "        return 'big'\n",
    "    elif adjusted_normal_time_spent >= 120:\n",
    "        return 'med'\n",
    "    else:\n",
    "        return 'small'\n",
    "def switch_event_list(full_trip_id, trip_locations_id, switch_event_id, switch_event_name=None, event_day=None, full_day = True):\n",
    "#     new_trip_locations_id, new_detail = remove_event(trip_locations_id, switch_event_id)\n",
    "    conn = psycopg2.connect(conn_str)   \n",
    "    cur = conn.cursor()   \n",
    "    cur.execute(\"select name, city, county, state, coord0, coord1,poi_rank, adjusted_normal_time_spent from poi_detail_table where index=%s\" %(switch_event_id))\n",
    "    name, city, county, state,coord0, coord1,poi_rank, adjusted_normal_time_spent = cur.fetchone()\n",
    "    event_type = event_type_time_spent(adjusted_normal_time_spent)\n",
    "    avialable_lst = ajax_available_events(county, state)\n",
    "    cur.execute(\"select trip_location_ids,details from full_trip_table where full_trip_id=%s\" %(full_trip_id))\n",
    "    full_trip_detail = cur.fetchone()\n",
    "    full_trip_detail = ast.literal_eval(full_trip_detail)\n",
    "    full_trip_ids = [ast.literal_eval(item)['id'] for item in full_trip_detail]\n",
    "    switch_lst = []\n",
    "    for item in avialable_lst:\n",
    "        index = item[0]\n",
    "        if index not in full_trip_ids:\n",
    "            event_ids = [switch_event_id, index]\n",
    "            event_ids, google_ids, name_list, driving_time_list, walking_time_list = db_google_driving_walking_time(event_ids, event_type='switch')\n",
    "            if min(driving_time_list[0], walking_time_list[0]) <= 60:\n",
    "                cur.execute(\"select poi_rank, rating, adjusted_normal_time_spent from poi_detail_table where index=%s\" %(index))\n",
    "                target_poi_rank, target_rating, target_adjusted_normal_time_spent = cur.fetchone()\n",
    "                target_event_type = event_type_time_spent(target_adjusted_normal_time_spent)\n",
    "                switch_lst.append([target_poi_rank, target_rating, target_event_type==event_type])\n",
    "    #need to sort target_event_type, target_poi_rank and target_rating\n",
    "    return {switch_event_id: switch_lst}\n",
    "\n",
    "def switch_event(trip_locations_id, switch_event_id, final_event_id, event_day):\n",
    "    new_trip_locations_id, new_detail = remove_event(trip_locations_id, switch_event_id)\n",
    "    new_trip_locations_id, new_detail = add_event(new_trip_locations_id, event_day, final_event_id, full_day = True, unseen_event = False)\n",
    "    return new_trip_locations_id, new_detail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2259,\n",
       " 2260,\n",
       " 3486,\n",
       " 3487,\n",
       " 4951,\n",
       " 4953,\n",
       " 4952,\n",
       " 2870,\n",
       " 2871,\n",
       " 2089,\n",
       " 2090,\n",
       " 2872,\n",
       " 147,\n",
       " 152,\n",
       " 148,\n",
       " 4630,\n",
       " 4545,\n",
       " 4544,\n",
       " 1325,\n",
       " 1326]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ajax_available_events(county='San Francisco', state = \"California\")\n",
    "county='San Francisco'.upper()\n",
    "state = \"California\"\n",
    "conn = psycopg2.connect(conn_str)   \n",
    "cur = conn.cursor()   \n",
    "cur.execute(\"select index, name from poi_detail_table where county='%s' and state='%s'\" %(county,state))  \n",
    "full_trip_id = 'CALIFORNIA-SAN-DIEGO-1-3'\n",
    "cur.execute(\"select details from full_trip_table where full_trip_id='%s'\" %(full_trip_id))\n",
    "full_trip_detail = cur.fetchone()[0]\n",
    "full_trip_detail = ast.literal_eval(full_trip_detail)\n",
    "[ast.literal_eval(item)['id'] for item in full_trip_detail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "trip_locations_id = 'CALIFORNIA-SAN-DIEGO-1-3-0'\n",
    "remove_event_id = 3486\n",
    "conn = psycopg2.connect(conn_str)   \n",
    "cur = conn.cursor()   \n",
    "cur.execute(\"select * from day_trip_table where trip_locations_id='%s'\" %(trip_locations_id))  \n",
    "(index, trip_locations_id, full_day, default, county, state, detail, event_type, event_ids) = cur.fetchone()\n",
    "# event_ids = ast.literal_eval(event_ids)\n",
    "# print detail, '\\n'\n",
    "new_event_ids = ast.literal_eval(event_ids)\n",
    "new_event_ids.remove(remove_event_id)\n",
    "new_trip_locations_id = '-'.join(str(id_) for id_ in new_event_ids)\n",
    "# event_ids.remove(remove_event_id)\n",
    "detail = ast.literal_eval(detail[1:-1])\n",
    "print type(detail[0])\n",
    "for index, trip_detail in enumerate(detail):\n",
    "    if ast.literal_eval(trip_detail)['id'] == remove_event_id:\n",
    "        remove_index = index\n",
    "        break\n",
    "new_detail = list(detail)\n",
    "new_detail.pop(remove_index)\n",
    "new_detail =  str(new_detail).replace(\"'\",\"''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Tasks:\n",
    "#0. Run the initial to debug with all the cities and counties for the poi_detail_table in hand. \n",
    "#1. Continue working on add/suggest/remove features\n",
    "#2. Start the new feature that allows user to generate the google map route for the day\n",
    "#3. new feature that allows user to explore outside the city from a direction away from the started location\n",
    "#4. get all the state and national park data into database and rework the ranking system and the poi_detail_table!\n",
    "remove_event_id = 3486\n",
    "\n",
    "#3.Travel Outside:\n",
    "current_city = 'San Francisco'\n",
    "current_state = 'California'\n",
    "direction = 'N'\n",
    "n_days = 1\n",
    "\n",
    "#Travel outside: 1 day 2hr driving, first set up distL2 < 1.7.  Find all the locations with in the range. \n",
    "#And exclude the started city. Need to take care of total travel time. should be less than 5 hrs for 1 day round trip\n",
    "#for 2 days: total 50% more driving time than 1 day.\n",
    "#for 3 days: total 100% more driving time than 1 day \n",
    "a,b =np.array([36.50641,-121.1095823]), np.array([37.0792134,-121.9502674])\n",
    "def angle_between(p1, p2):\n",
    "    ang1 = np.arctan2(*p1[::-1])\n",
    "    ang2 = np.arctan2(*p2[::-1])\n",
    "    return np.rad2deg((ang1 - ang2) % (2 * np.pi))\n",
    "\n",
    "def direction_from_orgin(start_coord_long,  start_coord_lat, target_coord_long, target_coord_lat):\n",
    "    diff =  [target_coord_long - start_coord_long, target_coord_lat- start_coord_lat]\n",
    "    angle = angle_between(diff,[0,0])\n",
    "    if (angle > 45) and (angle < 135):\n",
    "        return 'N'\n",
    "    elif (angle > 135) and (angle < 215):\n",
    "        return 'W'\n",
    "    elif (angle > 215) and (angle < 305):\n",
    "        return 'S'\n",
    "    else:\n",
    "        return 'E'\n",
    "    \n",
    "def travel_outside_coords(current_city, current_state, direction=None, n_days=1):\n",
    "    conn = psycopg2.connect(conn_str)   \n",
    "    cur = conn.cursor() \n",
    "    #coord_long, coord_lat\n",
    "    cur.execute(\"select coord0, coord1 from all_cities_coords where city ='%s' and state = '%s';\" %(current_city, current_state)) \n",
    "    coord0, coord1 = cur.fetchone()\n",
    "    #city, coord_lat, coord_long\n",
    "    cur.execute(\"select distinct city, coord0, coord1 from all_cities_coords where city !='%s' and state = '%s';\" %(current_city, current_state))  \n",
    "    coords = cur.fetchall()     \n",
    "    conn.close()\n",
    "    \n",
    "    return coords, coord0, coord1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 60 (60, 6)\n",
      "[2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "[[  2.71600000e+03   2.00000000e+00   4.00000000e+00]] 1 2 39\n",
      "0 [ 4517.  4519.  4703.  4704.  3751.]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'db_day_trip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-97aa92aba371>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#     db_address(event_ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_day_trip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_day\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_days\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'db_day_trip' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#Get events outside the city!!!\n",
    "\n",
    "target_direction = 'N'\n",
    "#possible city coords, target city coord_lat, target city coord_long\n",
    "coords, coord_lat, coord_long = travel_outside_coords(current_city, current_state)\n",
    "#coords: city, lat, long\n",
    "check_cities_info = []\n",
    "for item in coords:\n",
    "    direction = direction_from_orgin(coord_long,  coord_lat, item[2], item[1])\n",
    "    if (target_direction == direction) and (distL2([item[1], item[2]], [coord_lat, coord_long]) <1.7):\n",
    "        check_cities_info.append(item)\n",
    "city_infos = []\n",
    "for city, _, _ in check_cities_info:\n",
    "    county = None\n",
    "    #index, coord0, coord1, adjusted_normal_time_spent, poi_rank, rating\n",
    "    city_info = db_start_location(county, current_state, city)\n",
    "    city_infos.extend(city_info)\n",
    "city_infos = np.array(city_infos)\n",
    "poi_coords = city_infos[:,1:3]\n",
    "n_routes = sum(1 for t in np.array(city_infos)[:,3] if t >= 120)    \n",
    "if (n_routes>1) and (city_infos.shape[0]>=10):\n",
    "    kmeans = KMeans(n_clusters=n_routes).fit(poi_coords)\n",
    "elif (city_infos.shape[0]> 20) or (n_routes>1):\n",
    "    kmeans = KMeans(n_clusters=2).fit(poi_coords)\n",
    "else:\n",
    "    kmeans = KMeans(n_clusters=1).fit(poi_coords)\n",
    "route_labels = kmeans.labels_\n",
    "\n",
    "print n_routes, len(route_labels), city_infos.shape\n",
    "print route_labels\n",
    "for i in range(n_routes):\n",
    "    current_events, big_ix, med_ix, small_ix = [], [],[], []\n",
    "    for ix, label in enumerate(route_labels):\n",
    "        if label == i:\n",
    "            time = city_infos[ix,3]\n",
    "            event_ix = city_infos[ix,0]\n",
    "            current_events.append(event_ix)\n",
    "            if time > 180 :\n",
    "                big_ix.append(ix)\n",
    "            elif time >= 120 :\n",
    "                med_ix.append(ix)\n",
    "            else:\n",
    "                small_ix.append(ix)\n",
    "    big_ = sorted_events(city_infos, big_ix)\n",
    "    med_ = sorted_events(city_infos, med_ix)\n",
    "    small_ = sorted_events(city_infos, small_ix)\n",
    "    print big_, len(big_), len(med_), len(small_)\n",
    "    \n",
    "    # need to update!!!!!!!!\n",
    "\n",
    "    event_ids, event_type = create_event_id_list(big_, med_, small_)\n",
    "    event_ids, event_type = db_event_cloest_distance(event_ids = event_ids, event_type = event_type)\n",
    "    event_ids, google_ids, name_list, driving_time_list, walking_time_list =db_google_driving_walking_time(event_ids, event_type)\n",
    "    event_ids, driving_time_list, walking_time_list, total_time_spent = db_remove_extra_events(event_ids, driving_time_list, walking_time_list)\n",
    "#     db_address(event_ids)\n",
    "    print i, event_ids\n",
    "    values = db_day_trip(event_ids, county, state, default, full_day,n_days,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_start_location(county, current_state, city).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(conn_str)   \n",
    "cur = conn.cursor()   \n",
    "# cur.execute(\"select index, name, coord0, coord1 from poi_detail_table where city !='%s' and state = '%s';\" %(current_city, current_state))\n",
    "cur.execute(\"select distinct city, state from poi_detail_table;\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cities = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.7186735714 -122.468147\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim()\n",
    "location = geolocator.geocode(\"343 Vernon St., San Francisco, California\")\n",
    "print location.latitude, location.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.indexing._LocIndexer object at 0x10bb76ed0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10bffd510>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c01c750>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c01ce10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c279790>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c279790>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c01c750>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c57dd10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c57dd10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c57dd10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c57dd10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c57dd10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5d7e10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5d7e10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5d7e10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5decd0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5decd0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5decd0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c279790>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10610fdd0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c01ce10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c01c750>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c279790>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c279790>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c01ce10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5d75d0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5de6d0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5de6d0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5de6d0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e8f10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e8990>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5d75d0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5de6d0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e8990>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e8990>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e1f90>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e1ed0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e1610>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10610fdd0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10610fdd0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5c8a50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e1ed0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e0ad0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e0150>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e1ed0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e0150>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e0ad0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5dd710>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e1ed0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e1ed0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e1ed0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e2a50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e2350>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e2350>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e2e10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e2e50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5c8510>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5ddc50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5de550>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5de890>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5ddc50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5ddc50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5de550>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5de890>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5ddc50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5edf90>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5de550>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5f29d0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5f29d0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5f29d0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5f4e10>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5f4d50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5f4dd0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5f4c50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5f4d50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5f4dd0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e1610>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5f4dd0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5edb50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5e27d0>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5ddc50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5edb50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5edb50>\n",
      "<pandas.core.indexing._LocIndexer object at 0x10c5edb50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoesh/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "for items in all_cities:\n",
    "    if cities_coords[cities_coords['state'] == items[1]][cities_coords.city == items[0]].shape[0] == 0:\n",
    "        location_name = ', '.join([items[0], items[1]])\n",
    "        location = geolocator.geocode(location_name)\n",
    "        cities_coords.loc[len(cities_coords)] = [999,items[0], items[1], 'US', location.latitude, location.longitude]\n",
    "        print cities_coords.loc(len(cities_coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities_coords = pd.read_csv('cities_coords.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cities_coords.columns = ['area_code','city','state','nation', 'coord0','coord1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoesh/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_code</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>nation</th>\n",
       "      <th>coord0</th>\n",
       "      <th>coord1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>415</td>\n",
       "      <td>Novato</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>38.10742</td>\n",
       "      <td>-122.56970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>415</td>\n",
       "      <td>San Anselmo</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>37.97465</td>\n",
       "      <td>-122.56164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>415</td>\n",
       "      <td>South San Francisco</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>37.65466</td>\n",
       "      <td>-122.40775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>415</td>\n",
       "      <td>San Rafael</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>37.97353</td>\n",
       "      <td>-122.53109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     area_code                 city       state nation    coord0     coord1\n",
       "834        415               Novato  California     US  38.10742 -122.56970\n",
       "835        415          San Anselmo  California     US  37.97465 -122.56164\n",
       "836        415  South San Francisco  California     US  37.65466 -122.40775\n",
       "837        415           San Rafael  California     US  37.97353 -122.53109"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_coords[cities_coords['state'] == current_state][cities_coords.area_code == 415]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[999, 'Portsmouth', 'Virginia', 'US', 37.7792808, -122.4192362]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[999,items[0], items[1], 'US', location.latitude, location.longitude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cities_coords.to_csv('all_cities_coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://zoesh@localhost:5432/travel_with_friends')\n",
    "\n",
    "\n",
    "new_cities_coords.to_sql('all_cities_coords',engine, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoesh/anaconda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cities_coords = pd.read_csv('all_cities_coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>area_code</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>nation</th>\n",
       "      <th>coord0</th>\n",
       "      <th>coord1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>Bayonne</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.668710</td>\n",
       "      <td>-74.114310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>Bergenfield</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.927600</td>\n",
       "      <td>-73.997360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>Cliffside Park</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.821490</td>\n",
       "      <td>-73.987640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>201</td>\n",
       "      <td>Englewood</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.892880</td>\n",
       "      <td>-73.972640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>201</td>\n",
       "      <td>Fair Lawn</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.940380</td>\n",
       "      <td>-74.131810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>201</td>\n",
       "      <td>Fort Lee</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.850930</td>\n",
       "      <td>-73.970140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>201</td>\n",
       "      <td>Hackensack</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.885930</td>\n",
       "      <td>-74.043470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>201</td>\n",
       "      <td>Hoboken</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.743990</td>\n",
       "      <td>-74.032360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>201</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.728160</td>\n",
       "      <td>-74.077640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>201</td>\n",
       "      <td>Kearny</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.768430</td>\n",
       "      <td>-74.145420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>201</td>\n",
       "      <td>North Bergen</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.804270</td>\n",
       "      <td>-74.012080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>201</td>\n",
       "      <td>Paramus</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.944540</td>\n",
       "      <td>-74.075420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>201</td>\n",
       "      <td>Ridgewood</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.979260</td>\n",
       "      <td>-74.116530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>201</td>\n",
       "      <td>Teaneck</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.897600</td>\n",
       "      <td>-74.015970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>201</td>\n",
       "      <td>Union City</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.779550</td>\n",
       "      <td>-74.023750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>201</td>\n",
       "      <td>West New York</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.787880</td>\n",
       "      <td>-74.014310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>202</td>\n",
       "      <td>Washington</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>US</td>\n",
       "      <td>38.895110</td>\n",
       "      <td>-77.036370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>203</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.167040</td>\n",
       "      <td>-73.204830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>203</td>\n",
       "      <td>Danbury</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.394820</td>\n",
       "      <td>-73.454010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>203</td>\n",
       "      <td>East Haven</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.276210</td>\n",
       "      <td>-72.868430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>203</td>\n",
       "      <td>Meriden</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.538150</td>\n",
       "      <td>-72.807040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>203</td>\n",
       "      <td>Milford</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.222320</td>\n",
       "      <td>-73.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>203</td>\n",
       "      <td>Naugatuck</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.485930</td>\n",
       "      <td>-73.050660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>203</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.308150</td>\n",
       "      <td>-72.928160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>203</td>\n",
       "      <td>North Haven</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.390930</td>\n",
       "      <td>-72.859540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>203</td>\n",
       "      <td>Norwalk</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.117600</td>\n",
       "      <td>-73.407900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>203</td>\n",
       "      <td>Shelton</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.316490</td>\n",
       "      <td>-73.093160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>203</td>\n",
       "      <td>Stamford</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.053430</td>\n",
       "      <td>-73.538730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>203</td>\n",
       "      <td>Stratford</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.184540</td>\n",
       "      <td>-73.133170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>203</td>\n",
       "      <td>Trumbull</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.242870</td>\n",
       "      <td>-73.200670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>2820</td>\n",
       "      <td>999</td>\n",
       "      <td>Warwick</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>US</td>\n",
       "      <td>41.700202</td>\n",
       "      <td>-71.416111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>2821</td>\n",
       "      <td>999</td>\n",
       "      <td>Winter Garden</td>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>28.550269</td>\n",
       "      <td>-81.592597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>2822</td>\n",
       "      <td>999</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>US</td>\n",
       "      <td>33.348830</td>\n",
       "      <td>-112.491230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>2823</td>\n",
       "      <td>999</td>\n",
       "      <td>Compton</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>33.894882</td>\n",
       "      <td>-118.226043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>2824</td>\n",
       "      <td>999</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>38.350599</td>\n",
       "      <td>-81.633281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>2825</td>\n",
       "      <td>999</td>\n",
       "      <td>Concord</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>US</td>\n",
       "      <td>43.207106</td>\n",
       "      <td>-71.537021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>2826</td>\n",
       "      <td>999</td>\n",
       "      <td>St. Paul</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>US</td>\n",
       "      <td>44.950404</td>\n",
       "      <td>-93.101503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>2827</td>\n",
       "      <td>999</td>\n",
       "      <td>Buckeye</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>US</td>\n",
       "      <td>33.370275</td>\n",
       "      <td>-112.583867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>2828</td>\n",
       "      <td>999</td>\n",
       "      <td>Glendale</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>34.142498</td>\n",
       "      <td>-118.248596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>2829</td>\n",
       "      <td>999</td>\n",
       "      <td>Jurupa Valley</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>33.979847</td>\n",
       "      <td>-117.451575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2830</td>\n",
       "      <td>999</td>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>26.640628</td>\n",
       "      <td>-81.872308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>2831</td>\n",
       "      <td>999</td>\n",
       "      <td>Rockwall</td>\n",
       "      <td>Texas</td>\n",
       "      <td>US</td>\n",
       "      <td>32.931234</td>\n",
       "      <td>-96.459709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>2832</td>\n",
       "      <td>999</td>\n",
       "      <td>Eastvale</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>33.976680</td>\n",
       "      <td>-117.559844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>2833</td>\n",
       "      <td>999</td>\n",
       "      <td>Menifee</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>33.686443</td>\n",
       "      <td>-117.177044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>2834</td>\n",
       "      <td>999</td>\n",
       "      <td>St. Petersburg</td>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>27.770380</td>\n",
       "      <td>-82.669508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>2835</td>\n",
       "      <td>999</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>25.774266</td>\n",
       "      <td>-80.193659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>2836</td>\n",
       "      <td>999</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>US</td>\n",
       "      <td>42.360482</td>\n",
       "      <td>-71.059568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>2837</td>\n",
       "      <td>999</td>\n",
       "      <td>Goodyear</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>US</td>\n",
       "      <td>33.435609</td>\n",
       "      <td>-112.357912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>2838</td>\n",
       "      <td>999</td>\n",
       "      <td>Bentonville</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>US</td>\n",
       "      <td>36.372854</td>\n",
       "      <td>-94.208817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>2839</td>\n",
       "      <td>999</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>35.780398</td>\n",
       "      <td>-78.639099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>2840</td>\n",
       "      <td>999</td>\n",
       "      <td>Canton</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>US</td>\n",
       "      <td>40.798952</td>\n",
       "      <td>-81.378444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841</th>\n",
       "      <td>2841</td>\n",
       "      <td>999</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>US</td>\n",
       "      <td>36.166286</td>\n",
       "      <td>-115.149225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>2842</td>\n",
       "      <td>999</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>US</td>\n",
       "      <td>42.101483</td>\n",
       "      <td>-72.589811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>2843</td>\n",
       "      <td>999</td>\n",
       "      <td>Bend</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>US</td>\n",
       "      <td>44.058173</td>\n",
       "      <td>-121.315309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>2844</td>\n",
       "      <td>999</td>\n",
       "      <td>Miami Beach</td>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>25.788144</td>\n",
       "      <td>-80.127270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>2845</td>\n",
       "      <td>999</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>37.779281</td>\n",
       "      <td>-122.419236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>2846</td>\n",
       "      <td>999</td>\n",
       "      <td>Eugene</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>US</td>\n",
       "      <td>44.101181</td>\n",
       "      <td>-123.152384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>2847</td>\n",
       "      <td>999</td>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>42.651167</td>\n",
       "      <td>-73.754968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>2848</td>\n",
       "      <td>999</td>\n",
       "      <td>Kent</td>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>47.382690</td>\n",
       "      <td>-122.227027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>2849</td>\n",
       "      <td>999</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>US</td>\n",
       "      <td>41.505161</td>\n",
       "      <td>-81.693444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2850 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  area_code            city                 state nation  \\\n",
       "0              0        201         Bayonne            New Jersey     US   \n",
       "1              1        201     Bergenfield            New Jersey     US   \n",
       "2              2        201  Cliffside Park            New Jersey     US   \n",
       "3              3        201       Englewood            New Jersey     US   \n",
       "4              4        201       Fair Lawn            New Jersey     US   \n",
       "5              5        201        Fort Lee            New Jersey     US   \n",
       "6              6        201      Hackensack            New Jersey     US   \n",
       "7              7        201         Hoboken            New Jersey     US   \n",
       "8              8        201     Jersey City            New Jersey     US   \n",
       "9              9        201          Kearny            New Jersey     US   \n",
       "10            10        201    North Bergen            New Jersey     US   \n",
       "11            11        201         Paramus            New Jersey     US   \n",
       "12            12        201       Ridgewood            New Jersey     US   \n",
       "13            13        201         Teaneck            New Jersey     US   \n",
       "14            14        201      Union City            New Jersey     US   \n",
       "15            15        201   West New York            New Jersey     US   \n",
       "16            16        202      Washington  District of Columbia     US   \n",
       "17            17        203      Bridgeport           Connecticut     US   \n",
       "18            18        203         Danbury           Connecticut     US   \n",
       "19            19        203      East Haven           Connecticut     US   \n",
       "20            20        203         Meriden           Connecticut     US   \n",
       "21            21        203         Milford           Connecticut     US   \n",
       "22            22        203       Naugatuck           Connecticut     US   \n",
       "23            23        203       New Haven           Connecticut     US   \n",
       "24            24        203     North Haven           Connecticut     US   \n",
       "25            25        203         Norwalk           Connecticut     US   \n",
       "26            26        203         Shelton           Connecticut     US   \n",
       "27            27        203        Stamford           Connecticut     US   \n",
       "28            28        203       Stratford           Connecticut     US   \n",
       "29            29        203        Trumbull           Connecticut     US   \n",
       "...          ...        ...             ...                   ...    ...   \n",
       "2820        2820        999         Warwick          Rhode Island     US   \n",
       "2821        2821        999   Winter Garden               Florida     US   \n",
       "2822        2822        999        Maricopa               Arizona     US   \n",
       "2823        2823        999         Compton            California     US   \n",
       "2824        2824        999      Charleston         West Virginia     US   \n",
       "2825        2825        999         Concord         New Hampshire     US   \n",
       "2826        2826        999        St. Paul             Minnesota     US   \n",
       "2827        2827        999         Buckeye               Arizona     US   \n",
       "2828        2828        999        Glendale            California     US   \n",
       "2829        2829        999   Jurupa Valley            California     US   \n",
       "2830        2830        999      Fort Myers               Florida     US   \n",
       "2831        2831        999        Rockwall                 Texas     US   \n",
       "2832        2832        999        Eastvale            California     US   \n",
       "2833        2833        999         Menifee            California     US   \n",
       "2834        2834        999  St. Petersburg               Florida     US   \n",
       "2835        2835        999           Miami               Florida     US   \n",
       "2836        2836        999          Boston         Massachusetts     US   \n",
       "2837        2837        999        Goodyear               Arizona     US   \n",
       "2838        2838        999     Bentonville              Arkansas     US   \n",
       "2839        2839        999         Raleigh        North Carolina     US   \n",
       "2840        2840        999          Canton                  Ohio     US   \n",
       "2841        2841        999       Las Vegas                Nevada     US   \n",
       "2842        2842        999     Springfield         Massachusetts     US   \n",
       "2843        2843        999            Bend                Oregon     US   \n",
       "2844        2844        999     Miami Beach               Florida     US   \n",
       "2845        2845        999   San Francisco            California     US   \n",
       "2846        2846        999          Eugene                Oregon     US   \n",
       "2847        2847        999          Albany              New York     US   \n",
       "2848        2848        999            Kent            Washington     US   \n",
       "2849        2849        999       Cleveland                  Ohio     US   \n",
       "\n",
       "         coord0      coord1  \n",
       "0     40.668710  -74.114310  \n",
       "1     40.927600  -73.997360  \n",
       "2     40.821490  -73.987640  \n",
       "3     40.892880  -73.972640  \n",
       "4     40.940380  -74.131810  \n",
       "5     40.850930  -73.970140  \n",
       "6     40.885930  -74.043470  \n",
       "7     40.743990  -74.032360  \n",
       "8     40.728160  -74.077640  \n",
       "9     40.768430  -74.145420  \n",
       "10    40.804270  -74.012080  \n",
       "11    40.944540  -74.075420  \n",
       "12    40.979260  -74.116530  \n",
       "13    40.897600  -74.015970  \n",
       "14    40.779550  -74.023750  \n",
       "15    40.787880  -74.014310  \n",
       "16    38.895110  -77.036370  \n",
       "17    41.167040  -73.204830  \n",
       "18    41.394820  -73.454010  \n",
       "19    41.276210  -72.868430  \n",
       "20    41.538150  -72.807040  \n",
       "21    41.222320  -73.056500  \n",
       "22    41.485930  -73.050660  \n",
       "23    41.308150  -72.928160  \n",
       "24    41.390930  -72.859540  \n",
       "25    41.117600  -73.407900  \n",
       "26    41.316490  -73.093160  \n",
       "27    41.053430  -73.538730  \n",
       "28    41.184540  -73.133170  \n",
       "29    41.242870  -73.200670  \n",
       "...         ...         ...  \n",
       "2820  41.700202  -71.416111  \n",
       "2821  28.550269  -81.592597  \n",
       "2822  33.348830 -112.491230  \n",
       "2823  33.894882 -118.226043  \n",
       "2824  38.350599  -81.633281  \n",
       "2825  43.207106  -71.537021  \n",
       "2826  44.950404  -93.101503  \n",
       "2827  33.370275 -112.583867  \n",
       "2828  34.142498 -118.248596  \n",
       "2829  33.979847 -117.451575  \n",
       "2830  26.640628  -81.872308  \n",
       "2831  32.931234  -96.459709  \n",
       "2832  33.976680 -117.559844  \n",
       "2833  33.686443 -117.177044  \n",
       "2834  27.770380  -82.669508  \n",
       "2835  25.774266  -80.193659  \n",
       "2836  42.360482  -71.059568  \n",
       "2837  33.435609 -112.357912  \n",
       "2838  36.372854  -94.208817  \n",
       "2839  35.780398  -78.639099  \n",
       "2840  40.798952  -81.378444  \n",
       "2841  36.166286 -115.149225  \n",
       "2842  42.101483  -72.589811  \n",
       "2843  44.058173 -121.315309  \n",
       "2844  25.788144  -80.127270  \n",
       "2845  37.779281 -122.419236  \n",
       "2846  44.101181 -123.152384  \n",
       "2847  42.651167  -73.754968  \n",
       "2848  47.382690 -122.227027  \n",
       "2849  41.505161  -81.693444  \n",
       "\n",
       "[2850 rows x 7 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1958, 5)\n"
     ]
    }
   ],
   "source": [
    "new_cities_coords = cities_coords[['city', 'state','nation','coord0','coord1']].drop_duplicates()\n",
    "print new_cities_coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>nation</th>\n",
       "      <th>coord0</th>\n",
       "      <th>coord1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayonne</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.668710</td>\n",
       "      <td>-74.114310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bergenfield</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.927600</td>\n",
       "      <td>-73.997360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cliffside Park</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.821490</td>\n",
       "      <td>-73.987640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Englewood</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.892880</td>\n",
       "      <td>-73.972640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fair Lawn</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.940380</td>\n",
       "      <td>-74.131810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fort Lee</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.850930</td>\n",
       "      <td>-73.970140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hackensack</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.885930</td>\n",
       "      <td>-74.043470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hoboken</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.743990</td>\n",
       "      <td>-74.032360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jersey City</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.728160</td>\n",
       "      <td>-74.077640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kearny</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.768430</td>\n",
       "      <td>-74.145420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>North Bergen</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.804270</td>\n",
       "      <td>-74.012080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Paramus</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.944540</td>\n",
       "      <td>-74.075420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ridgewood</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.979260</td>\n",
       "      <td>-74.116530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Teaneck</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.897600</td>\n",
       "      <td>-74.015970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Union City</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.779550</td>\n",
       "      <td>-74.023750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>West New York</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>40.787880</td>\n",
       "      <td>-74.014310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Washington</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>US</td>\n",
       "      <td>38.895110</td>\n",
       "      <td>-77.036370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.167040</td>\n",
       "      <td>-73.204830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Danbury</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.394820</td>\n",
       "      <td>-73.454010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>East Haven</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.276210</td>\n",
       "      <td>-72.868430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Meriden</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.538150</td>\n",
       "      <td>-72.807040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Milford</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.222320</td>\n",
       "      <td>-73.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Naugatuck</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.485930</td>\n",
       "      <td>-73.050660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>New Haven</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.308150</td>\n",
       "      <td>-72.928160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>North Haven</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.390930</td>\n",
       "      <td>-72.859540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Norwalk</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.117600</td>\n",
       "      <td>-73.407900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Shelton</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.316490</td>\n",
       "      <td>-73.093160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Stamford</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.053430</td>\n",
       "      <td>-73.538730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Stratford</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.184540</td>\n",
       "      <td>-73.133170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Trumbull</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>US</td>\n",
       "      <td>41.242870</td>\n",
       "      <td>-73.200670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>Warwick</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>US</td>\n",
       "      <td>41.700202</td>\n",
       "      <td>-71.416111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>Winter Garden</td>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>28.550269</td>\n",
       "      <td>-81.592597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>US</td>\n",
       "      <td>33.348830</td>\n",
       "      <td>-112.491230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>Compton</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>33.894882</td>\n",
       "      <td>-118.226043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>Charleston</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>38.350599</td>\n",
       "      <td>-81.633281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>Concord</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>US</td>\n",
       "      <td>43.207106</td>\n",
       "      <td>-71.537021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>St. Paul</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>US</td>\n",
       "      <td>44.950404</td>\n",
       "      <td>-93.101503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>Buckeye</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>US</td>\n",
       "      <td>33.370275</td>\n",
       "      <td>-112.583867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>Glendale</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>34.142498</td>\n",
       "      <td>-118.248596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>Jurupa Valley</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>33.979847</td>\n",
       "      <td>-117.451575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>26.640628</td>\n",
       "      <td>-81.872308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>Rockwall</td>\n",
       "      <td>Texas</td>\n",
       "      <td>US</td>\n",
       "      <td>32.931234</td>\n",
       "      <td>-96.459709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>Eastvale</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>33.976680</td>\n",
       "      <td>-117.559844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>Menifee</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>33.686443</td>\n",
       "      <td>-117.177044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>St. Petersburg</td>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>27.770380</td>\n",
       "      <td>-82.669508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>Miami</td>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>25.774266</td>\n",
       "      <td>-80.193659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>US</td>\n",
       "      <td>42.360482</td>\n",
       "      <td>-71.059568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>Goodyear</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>US</td>\n",
       "      <td>33.435609</td>\n",
       "      <td>-112.357912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>Bentonville</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>US</td>\n",
       "      <td>36.372854</td>\n",
       "      <td>-94.208817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>Raleigh</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>35.780398</td>\n",
       "      <td>-78.639099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>Canton</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>US</td>\n",
       "      <td>40.798952</td>\n",
       "      <td>-81.378444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841</th>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>US</td>\n",
       "      <td>36.166286</td>\n",
       "      <td>-115.149225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>Springfield</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>US</td>\n",
       "      <td>42.101483</td>\n",
       "      <td>-72.589811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>Bend</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>US</td>\n",
       "      <td>44.058173</td>\n",
       "      <td>-121.315309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>Miami Beach</td>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>25.788144</td>\n",
       "      <td>-80.127270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>37.779281</td>\n",
       "      <td>-122.419236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>Eugene</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>US</td>\n",
       "      <td>44.101181</td>\n",
       "      <td>-123.152384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>42.651167</td>\n",
       "      <td>-73.754968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>Kent</td>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>47.382690</td>\n",
       "      <td>-122.227027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>US</td>\n",
       "      <td>41.505161</td>\n",
       "      <td>-81.693444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1958 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                city                 state nation     coord0      coord1\n",
       "0            Bayonne            New Jersey     US  40.668710  -74.114310\n",
       "1        Bergenfield            New Jersey     US  40.927600  -73.997360\n",
       "2     Cliffside Park            New Jersey     US  40.821490  -73.987640\n",
       "3          Englewood            New Jersey     US  40.892880  -73.972640\n",
       "4          Fair Lawn            New Jersey     US  40.940380  -74.131810\n",
       "5           Fort Lee            New Jersey     US  40.850930  -73.970140\n",
       "6         Hackensack            New Jersey     US  40.885930  -74.043470\n",
       "7            Hoboken            New Jersey     US  40.743990  -74.032360\n",
       "8        Jersey City            New Jersey     US  40.728160  -74.077640\n",
       "9             Kearny            New Jersey     US  40.768430  -74.145420\n",
       "10      North Bergen            New Jersey     US  40.804270  -74.012080\n",
       "11           Paramus            New Jersey     US  40.944540  -74.075420\n",
       "12         Ridgewood            New Jersey     US  40.979260  -74.116530\n",
       "13           Teaneck            New Jersey     US  40.897600  -74.015970\n",
       "14        Union City            New Jersey     US  40.779550  -74.023750\n",
       "15     West New York            New Jersey     US  40.787880  -74.014310\n",
       "16        Washington  District of Columbia     US  38.895110  -77.036370\n",
       "17        Bridgeport           Connecticut     US  41.167040  -73.204830\n",
       "18           Danbury           Connecticut     US  41.394820  -73.454010\n",
       "19        East Haven           Connecticut     US  41.276210  -72.868430\n",
       "20           Meriden           Connecticut     US  41.538150  -72.807040\n",
       "21           Milford           Connecticut     US  41.222320  -73.056500\n",
       "22         Naugatuck           Connecticut     US  41.485930  -73.050660\n",
       "23         New Haven           Connecticut     US  41.308150  -72.928160\n",
       "24       North Haven           Connecticut     US  41.390930  -72.859540\n",
       "25           Norwalk           Connecticut     US  41.117600  -73.407900\n",
       "26           Shelton           Connecticut     US  41.316490  -73.093160\n",
       "27          Stamford           Connecticut     US  41.053430  -73.538730\n",
       "28         Stratford           Connecticut     US  41.184540  -73.133170\n",
       "29          Trumbull           Connecticut     US  41.242870  -73.200670\n",
       "...              ...                   ...    ...        ...         ...\n",
       "2820         Warwick          Rhode Island     US  41.700202  -71.416111\n",
       "2821   Winter Garden               Florida     US  28.550269  -81.592597\n",
       "2822        Maricopa               Arizona     US  33.348830 -112.491230\n",
       "2823         Compton            California     US  33.894882 -118.226043\n",
       "2824      Charleston         West Virginia     US  38.350599  -81.633281\n",
       "2825         Concord         New Hampshire     US  43.207106  -71.537021\n",
       "2826        St. Paul             Minnesota     US  44.950404  -93.101503\n",
       "2827         Buckeye               Arizona     US  33.370275 -112.583867\n",
       "2828        Glendale            California     US  34.142498 -118.248596\n",
       "2829   Jurupa Valley            California     US  33.979847 -117.451575\n",
       "2830      Fort Myers               Florida     US  26.640628  -81.872308\n",
       "2831        Rockwall                 Texas     US  32.931234  -96.459709\n",
       "2832        Eastvale            California     US  33.976680 -117.559844\n",
       "2833         Menifee            California     US  33.686443 -117.177044\n",
       "2834  St. Petersburg               Florida     US  27.770380  -82.669508\n",
       "2835           Miami               Florida     US  25.774266  -80.193659\n",
       "2836          Boston         Massachusetts     US  42.360482  -71.059568\n",
       "2837        Goodyear               Arizona     US  33.435609 -112.357912\n",
       "2838     Bentonville              Arkansas     US  36.372854  -94.208817\n",
       "2839         Raleigh        North Carolina     US  35.780398  -78.639099\n",
       "2840          Canton                  Ohio     US  40.798952  -81.378444\n",
       "2841       Las Vegas                Nevada     US  36.166286 -115.149225\n",
       "2842     Springfield         Massachusetts     US  42.101483  -72.589811\n",
       "2843            Bend                Oregon     US  44.058173 -121.315309\n",
       "2844     Miami Beach               Florida     US  25.788144  -80.127270\n",
       "2845   San Francisco            California     US  37.779281 -122.419236\n",
       "2846          Eugene                Oregon     US  44.101181 -123.152384\n",
       "2847          Albany              New York     US  42.651167  -73.754968\n",
       "2848            Kent            Washington     US  47.382690 -122.227027\n",
       "2849       Cleveland                  Ohio     US  41.505161  -81.693444\n",
       "\n",
       "[1958 rows x 5 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cities_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_cities_coords = new_cities_coords.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_cities_coords.reset_index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_cities_coords.to_csv('all_cities_coords2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_initial_compass_bearing(pointA, pointB):\n",
    "    \"\"\"\n",
    "    Calculates the bearing between two points.\n",
    "    The formulae used is the following:\n",
    "        θ = atan2(sin(Δlong).cos(lat2),\n",
    "                  cos(lat1).sin(lat2) − sin(lat1).cos(lat2).cos(Δlong))\n",
    "    :Parameters:\n",
    "      - `pointA: The tuple representing the latitude/longitude for the\n",
    "        first point. Latitude and longitude must be in decimal degrees\n",
    "      - `pointB: The tuple representing the latitude/longitude for the\n",
    "        second point. Latitude and longitude must be in decimal degrees\n",
    "    :Returns:\n",
    "      The bearing in degrees\n",
    "    :Returns Type:\n",
    "      float\n",
    "    \"\"\"\n",
    "    if (type(pointA) != tuple) or (type(pointB) != tuple):\n",
    "        raise TypeError(\"Only tuples are supported as arguments\")\n",
    "\n",
    "    lat1 = math.radians(pointA[0])\n",
    "    lat2 = math.radians(pointB[0])\n",
    "\n",
    "    diffLong = math.radians(pointB[1] - pointA[1])\n",
    "\n",
    "    x = math.sin(diffLong) * math.cos(lat2)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - (math.sin(lat1)\n",
    "            * math.cos(lat2) * math.cos(diffLong))\n",
    "\n",
    "    initial_bearing = math.atan2(x, y)\n",
    "\n",
    "    # Now we have the initial bearing but math.atan2 return values\n",
    "    # from -180° to + 180° which is not what we want for a compass bearing\n",
    "    # The solution is to normalize the initial bearing as shown below\n",
    "    initial_bearing = math.degrees(initial_bearing)\n",
    "    compass_bearing = (initial_bearing + 360) % 360\n",
    "\n",
    "    return compass_bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = psycopg2.connect(conn_str)   \n",
    "cur = conn.cursor() \n",
    "cur.execute(\"select details from day_trip_locations where trip_locations_id='%s'\" %(123)) \n",
    "not cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-310-67c82e74fc34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m91\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "np.concatenate(np.array([0, 91,23]),np.zeros((len(event_ids), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = np.zeros((len(event_ids), 3))\n",
    "points = np.vstack((np.array(['test',91,23]),np.zeros((len(event_ids), 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['test', '91', '23'],\n",
       "       ['0.0', '0.0', '0.0'],\n",
       "       ['0.0', '0.0', '0.0'],\n",
       "       ['0.0', '0.0', '0.0'],\n",
       "       ['0.0', '0.0', '0.0'],\n",
       "       ['0.0', '0.0', '0.0']], \n",
       "      dtype='|S32')"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "t.extend(['12']*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12', '12']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
