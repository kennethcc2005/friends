{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import requests\n",
    "import psycopg2\n",
    "import json\n",
    "import simplejson\n",
    "import urllib\n",
    "import config\n",
    "import ast\n",
    "import bs4\n",
    "import pprint\n",
    "import progressbar\n",
    "from pymongo import MongoClient\n",
    "from geopy.geocoders import Nominatim\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from operator import itemgetter\n",
    "from sklearn.cluster import KMeans\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade progressbar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_str = \"dbname='travel_with_friends' user='Gon' host='localhost'\"\n",
    "# conn_str = \"dbname='travel_with_friends' user='Zoesh' host='localhost'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(conn_str)   \n",
    "cur = conn.cursor()   \n",
    "# cur.execute(\"select index, name, coord0, coord1 from poi_detail_table where city !='%s' and state = '%s';\" %(current_city, current_state))\n",
    "cur.execute(\"select distinct city, state from poi_detail_table;\" )\n",
    "all_cities = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cities[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cities_coords = pd.read_csv('cities_coords.csv', header=None)\n",
    "cities_coords.columns = ['area_code', 'city','state','nation', 'coord0','coord1']\n",
    "cities_coords = cities_coords[['city','state','nation', 'coord0','coord1']].drop_duplicates()\n",
    "cities_coords.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geolocator = Nominatim()\n",
    "\n",
    "for items in all_cities:\n",
    "    if cities_coords[cities_coords['state'] == items[1]][cities_coords.city == items[0]].shape[0] == 0:\n",
    "        location_name = ', '.join([items[0], items[1]])\n",
    "        try:\n",
    "            location = geolocator.geocode(location_name)\n",
    "            cities_coords.loc[len(cities_coords)] = [items[0], items[1], 'US', location.latitude, location.longitude]\n",
    "        except:\n",
    "            \"error, rest\"\n",
    "            time.sleep(20)\n",
    "            print\" start again\"\n",
    "            \n",
    "            \n",
    "#         print cities_coords.loc(len(cities_coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities_coords.to_csv('all_cities_coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://Gon@localhost:5432/travel_with_friends')\n",
    "cities_coords.to_sql('all_cities_coords',engine, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import us_state_abbrevation as abb\n",
    "state_abb_dict = abb.abb2state\n",
    "state_abb_dict['CA']\n",
    "# print state_abb_dict.keys()[state_abb_dict.values().index('CA')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from googleplaces import GooglePlaces, types, lang\n",
    "YOUR_API_KEY = 'AIzaSyDMbpmHBLl7dTOXUOMZP7Vi3zbMJlByEKM'\n",
    "google_places = GooglePlaces(YOUR_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import geocoder\n",
    "api_key1 = 'AIzaSyCrgwS_L75NfO9qzIKG8L0ox7zGw81BpRU'\n",
    "api_key2 = 'AIzaSyBwh4WqOIVJGJuKkmzpQxlkjahgx6qzimk'\n",
    "api_key3 = 'AIzaSyA25LW2CRcD9mSmiAWBYSPOSoiKP_m2plQ'\n",
    "api_key4 = 'AIzaSyB3l2Trzm4LnrC0nyUwwoM9803Fuwf0my4'\n",
    "api_key5 = 'AIzaSyDj0yH_35G1zMq5uYPF6X0ogkHYcLsNN1w'\n",
    "add = ' 497 lakeside drive'\n",
    "g = geocoder.google(add, key = api_key5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('api_key_list.config') as api_key_list_file:\n",
    "    api_key_list = json.load(api_key_list_file)\n",
    "api_key_list['api_key_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'AIzaSyCrgwS_L75NfO9qzIKG8L0ox7zGw81BpRU',\n",
       " u'AIzaSyBwh4WqOIVJGJuKkmzpQxlkjahgx6qzimk',\n",
       " u'AIzaSyA25LW2CRcD9mSmiAWBYSPOSoiKP_m2plQ',\n",
       " u'AIzaSyB3l2Trzm4LnrC0nyUwwoM9803Fuwf0my4',\n",
       " u'AIzaSyDj0yH_35G1zMq5uYPF6X0ogkHYcLsNN1w',\n",
       " u'AIzaSyADO1wlwWDW-XaNwQ-p50Q3yMRxtRascdU']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tmp = pd.read_csv('test_poi_detail_df_100.csv', index_col = 0)\n",
    "# df_tmp.to_csv('test_poi_detail_df_100.csv', index_col=None)\n",
    "df_tmp.head()\n",
    "s.find(text =\"Recommended length of visit:\")\n",
    "#         visit_length = s.find(text =\"Recommended length of visit:\").parent.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.zoeshrm\n",
    "db.TripAdvisor_state_park.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from web_scraping_tripadvisor import state_park_web as web\n",
    "state_park_pages = db.TripAdvisor_state_park.find()\n",
    "poi_detail_state_park_df, error_message_df = web(state_park_pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "page = db.TripAdvisor.find_one({'city': 'San Francisco, California'})\n",
    "search_visit_length = re.compile('Recommended length of visit:')\n",
    "s = BS(page['html'], \"html.parser\")\n",
    "#index\n",
    "#name\n",
    "input_list, error_message = [],[]\n",
    "state_abb_error, state_error, address_error, geo_error, review_error, score_error, ranking_error, tag_error = 0,0,0,0,0,0,0,0\n",
    "latitude, longitude, geo_content = None, None, None\n",
    "#     print name\n",
    "url = page['url']\n",
    "name = s.find('h1', attrs = {'class':'heading_name'}).text.strip()\n",
    "\n",
    "#street_address\n",
    "street_address = s.find('span', attrs = {'class':'street-address'}).text.strip()\n",
    "#city\n",
    "city = s.find('span', attrs = {'property':'addressLocality'}).text.strip()\n",
    "#state\n",
    "state_abb = s.find('span', attrs = {'property':'addressRegion'}).text.strip()\n",
    "if state_abb:\n",
    "    try:\n",
    "        # state = state_abb_dict.keys()[state_abb_dict.values().index(state_abb)]\n",
    "        state = abb2state_dict[state_abb]\n",
    "    except:\n",
    "        state_abb_error = 1\n",
    "        state = state_abb\n",
    "else:\n",
    "    state_error =1\n",
    "    state_abb = None\n",
    "    state = None\n",
    "#postal_code\n",
    "postal_code = s.find('span', attrs = {'property':'postalCode'}).text.strip()\n",
    "#country\n",
    "if s.find('span', attrs = {'property':'addressCountry'}).get('content'):\n",
    "    country = s.find('span',{'property':'addressCountry'}).get('content')\n",
    "elif s.find('span',{'property':'addressCountry'}).get('content') == None:\n",
    "    country = s.find('span',{'property':'addressCountry'}).text.strip()\n",
    "else:\n",
    "    country = 'United States'\n",
    "#address\n",
    "if state:\n",
    "    full_address = street_address+', '+city+', '+state+', '+postal_code[:5]+', '+country\n",
    "else:\n",
    "    address_error =1\n",
    "    full_address = street_address+', '+city+', '+postal_code[:5]+', '+country\n",
    "# if (name in name_lst) and (full_address in full_address_lst):\n",
    "#     continue\n",
    "# else:\n",
    "#     name_lst.append(name)\n",
    "#     full_address_lst.append(full_address)\n",
    "#coord\n",
    "try:\n",
    "    latitude, longitude, geo_content = find_latlng(full_address, name)\n",
    "except:\n",
    "    geo_error =1\n",
    "    latitude, longitude, geo_content = None, None, None\n",
    "\n",
    "#num_reviews\n",
    "try:\n",
    "    num_reviews = s.find('div', attrs = {'class': 'rs rating'}).find('a').get('content')\n",
    "    if num_reviews == None:\n",
    "        num_reviews = s.find('a', {'property': \"reviewCount\"}).get('content')    \n",
    "except:\n",
    "    num_reviews = 0\n",
    "    review_error=1    \n",
    "#review_score\n",
    "try:\n",
    "    review_score = s.find('div', attrs = {'class': 'heading_rating separator'}).find('img').get('content')\n",
    "    if review_score == None:\n",
    "        review_score = s.find('a', {'property': \"ratingValue\"}).get('content')\n",
    "except:\n",
    "    review_score = 0 \n",
    "    score_error =1\n",
    "#ranking\n",
    "try:\n",
    "    ranking = s.find('b', attrs = {'class':'rank_text wrap'}).text.strip().replace('#',\"\")\n",
    "except:\n",
    "    ranking = 999\n",
    "    ranking_error=1\n",
    "#tag\n",
    "try:\n",
    "    tags = \", \".join(label.text.strip() for label in s.select('div.detail > a') + s.select('span.collapse.hidden > a'))\n",
    "except:\n",
    "    tags = None\n",
    "    tag_error =1\n",
    "#visit_length\n",
    "if s.find('b', text =search_visit_length):\n",
    "    raw_visit_length = s.find('b', text =search_visit_length).next_sibling.strip()\n",
    "else:\n",
    "    raw_visit_length = None\n",
    "#fee\n",
    "if s.find(text= \"Fee:\"):\n",
    "    fee = s.find(text= \"Fee:\").parent.next_sibling.upper()\n",
    "else:\n",
    "    fee = 'NO'\n",
    "#description\n",
    "if s.find('div', attrs = {'class': \"listing_details\"}):\n",
    "    description = s.find('div', attrs = {'class': \"listing_details\"}).text.strip()\n",
    "else:\n",
    "    description = None\n",
    "# error_message = [len(poi_detail_state_park_df), name, url,state_abb_error, state_error, address_error, geo_error, review_error, score_error, ranking_error, tag_error]\n",
    "# error_message_df.loc[len(poi_detail_state_park_df)] =error_message\n",
    "\n",
    "\n",
    "# input_list = [len(poi_detail_state_park_df), name, street_address, city, state_abb, state, postal_code, country, full_address, latitude, longitude, num_reviews, review_score, ranking, tags, visit_length, fee, description, url, geo_content]\n",
    "# poi_detail_state_park_df.loc[len(poi_detail_state_park_df)] = input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "search_visit_length = re.compile('Recommended length of visit:')\n",
    "test = s.find('b', text =search_visit_length).next_sibling.strip()\n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('api_key_list.config') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'api_key_list': [u'AIzaSyCrgwS_L75NfO9qzIKG8L0ox7zGw81BpRU',\n",
       "  u'AIzaSyBwh4WqOIVJGJuKkmzpQxlkjahgx6qzimk',\n",
       "  u'AIzaSyA25LW2CRcD9mSmiAWBYSPOSoiKP_m2plQ',\n",
       "  u'AIzaSyB3l2Trzm4LnrC0nyUwwoM9803Fuwf0my4',\n",
       "  u'AIzaSyDj0yH_35G1zMq5uYPF6X0ogkHYcLsNN1w',\n",
       "  u'AIzaSyADO1wlwWDW-XaNwQ-p50Q3yMRxtRascdU']}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#items in fee lst:  100\n",
      "#items in fee lst:  200\n",
      "#items in fee lst:  300\n",
      "#items in fee lst:  400\n",
      "#items in fee lst:  500\n",
      "#items in fee lst:  600\n",
      "#items in fee lst:  700\n",
      "#items in fee lst:  800\n",
      "#items in fee lst:  900\n",
      "#items in fee lst:  1000\n",
      "#items in fee lst:  1100\n",
      "#items in fee lst:  1200\n",
      "#items in fee lst:  1300\n",
      "#items in fee lst:  1400\n",
      "#items in fee lst:  1500\n",
      "#items in fee lst:  1600\n",
      "#items in fee lst:  1700\n",
      "#items in fee lst:  1800\n",
      "#items in fee lst:  1900\n",
      "#items in fee lst:  2000\n",
      "#items in fee lst:  2100\n",
      "#items in fee lst:  2200\n",
      "#items in fee lst:  2300\n",
      "#items in fee lst:  2400\n",
      "#items in fee lst:  2500\n",
      "#items in fee lst:  2600\n",
      "#items in fee lst:  2700\n",
      "#items in fee lst:  2800\n",
      "#items in fee lst:  2900\n",
      "#items in fee lst:  3000\n",
      "#items in fee lst:  3100\n",
      "#items in fee lst:  3200\n",
      "#items in fee lst:  3300\n",
      "#items in fee lst:  3400\n",
      "#items in fee lst:  3500\n",
      "#items in fee lst:  3600\n",
      "#items in fee lst:  3700\n",
      "#items in fee lst:  3800\n",
      "#items in fee lst:  3900\n",
      "#items in fee lst:  4000\n",
      "#items in fee lst:  4100\n",
      "#items in fee lst:  4200\n",
      "#items in fee lst:  4300\n",
      "#items in fee lst:  4400\n",
      "#items in fee lst:  4500\n",
      "#items in fee lst:  4600\n",
      "#items in fee lst:  4700\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-a3f77e65920d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoi_pages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msearch_fee\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfee\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msearch_fee\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_sibling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zoesh/anaconda/lib/python2.7/site-packages/bs4/__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                     \u001b[0mmarkup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 warnings.warn(\n\u001b[1;32m    217\u001b[0m                     \u001b[0;34m'\"%s\" looks like a filename, not markup. You should'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zoesh/anaconda/lib/python2.7/site-packages/bs4/__init__.pyc\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__copy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         copy = type(self)(\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         )\n",
      "\u001b[0;32m/Users/zoesh/anaconda/lib/python2.7/site-packages/bs4/builder/_htmlparser.pyc\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoupHTMLParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zoesh/anaconda/lib/python2.7/HTMLParser.pyc\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \"\"\"\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zoesh/anaconda/lib/python2.7/HTMLParser.pyc\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstarttagopen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# < + letter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zoesh/anaconda/lib/python2.7/HTMLParser.pyc\u001b[0m in \u001b[0;36mparse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mendpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrfind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_fee = re.compile('Fee:')\n",
    "df_poi = pd.read_csv('test_poi_detail_df.csv', index_col= 0)\n",
    "poi_pages = db.TripAdvisor.find()\n",
    "fee_lst = []\n",
    "cnt = 0\n",
    "for page in poi_pages:\n",
    "    s = BS(page['html'], \"html.parser\")\n",
    "    if s.find('b', text= search_fee):\n",
    "        fee = s.find('b',text= search_fee).next_sibling.strip()\n",
    "    else:\n",
    "        fee = 'Unknown'\n",
    "    fee_lst.append(fee)\n",
    "    cnt+=1\n",
    "    if cnt%100 ==0 :\n",
    "        print '#items in fee lst: ',len(fee_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fee_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_message_df.to_csv('error_message.csv', encoding=('utf-8'))\n",
    "poi_detail_state_park_df.to_csv(\"poi_detail_state_park.csv\", encoding=('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    poi_additional_detail = poi_detail_state_park[['index','name','url','address','geo_content']]\n",
    "\n",
    "    geo_content_detail=poi_detail_state_park.pop('geo_content')\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.geo_content.drop()\n",
    "db.geo_content.insert_many(poi_additional_detail.to_dict('records'))\n",
    "poi_detail_state_park.to_sql('poi_detail_state_park_table',engine, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print poi_detail_state_park_df.shape, error_message_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_message_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_latlng(full_address, name):\n",
    "    g_address = geocoder.google(full_address)\n",
    "    if g_address.ok:\n",
    "        latitude= g_address.lat\n",
    "        longitude = g_address.lng\n",
    "        return latitude, longitude, g_address.content\n",
    "    \n",
    "    g_name = geocoder.google(name)\n",
    "    if g_name.ok:\n",
    "        latitude= g_name.lat\n",
    "        longitude = g_name.lng\n",
    "        return latitude, longitude, g_name.content\n",
    "    else:\n",
    "        latitude = None\n",
    "        longitude = None\n",
    "        return latitude, longitude, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_geo_location(full_address, name):\n",
    "    query_result = google_places.nearby_search(location= full_address, keyword=name)\n",
    "    if len(query_result.places) >0:\n",
    "        best_result = query_result.places[0]\n",
    "        latitude = best_result.geo_location[\"lat\"]\n",
    "        longitude = best_result.geo_location[\"lng\"]\n",
    "        google_result_name = best_result.name\n",
    "\n",
    "        return latitude, longitude, google_result_name\n",
    "    else:\n",
    "        print name, \"google API cant find here.\"\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park=pd.DataFrame(columns=['index','name','street_address','city','state_abb','state','postal_code','country','address','coord_lat','coord_long','num_reviews','review_score','ranking','tag','visit_length','fee','description','url',\"geo_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_message_df = pd.DataFrame(columns=['index','name','url','state_abb_error','address_error','geo_error','review_error','score_error','ranking_error','tag_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# poi_detail_state_park2=pd.DataFrame(columns=['index','name','street_address','city','state_abb','state','postal_code','country','address','coord_lat','coord_long','num_reviews','review_score','ranking','tag','visit_length','fee','description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_park_pages = db.TripAdvisor_state_park.find()\n",
    "index = 0\n",
    "for page in state_park_pages[len(poi_detail_state_park):]:\n",
    "    s = BS(page['html'], \"html.parser\")\n",
    "    #index\n",
    "    #name\n",
    "    error_message = []\n",
    "    state_abb_error, address_error, geo_error, review_error, score_error, ranking_error, tag_error = 0,0,0,0,0,0,0\n",
    "    input_list = []\n",
    "#     print name\n",
    "\n",
    "    url = page['url']\n",
    "    name = s.find('h1', attrs = {'class':'heading_name'}).text.strip()\n",
    "\n",
    "    #street_address\n",
    "    street_address = s.find('span', attrs = {'class':'street-address'}).text.strip()\n",
    "    #city\n",
    "    city = s.find('span', attrs = {'property':'addressLocality'}).text.strip()\n",
    "\n",
    "    #state\n",
    "    state_abb = s.find('span', attrs = {'property':'addressRegion'}).text.strip()\n",
    "    if state_abb:\n",
    "        try:\n",
    "            state = state_abb_dict[state_abb]\n",
    "        except:\n",
    "            state_abb_error = 1\n",
    "            state = state_abb\n",
    "    else:\n",
    "        state_abb = None\n",
    "        state = None\n",
    "    #postal_code\n",
    "    postal_code = s.find('span', attrs = {'property':'postalCode'}).text.strip()\n",
    "    #country\n",
    "    if s.find('span', attrs = {'property':'addressCountry'}).get('content'):\n",
    "        country = s.find('span',{'property':'addressCountry'}).get('content')\n",
    "    elif s.find('span',{'property':'addressCountry'}).get('content') == None:\n",
    "        country = s.find('span',{'property':'addressCountry'}).text.strip()\n",
    "    else:\n",
    "        country = 'United States'\n",
    "    #address\n",
    "    if state_abb:\n",
    "        full_address = street_address+', '+city+', '+state_abb+', '+postal_code[:5]+', '+country\n",
    "    else:\n",
    "        address_error =1\n",
    "        full_address = street_address+', '+city+', '+postal_code[:5]+', '+country\n",
    "\n",
    "    #coord\n",
    "    try:\n",
    "        latitude, longitude, geo_content = find_latlng(full_address, name)\n",
    "    except:\n",
    "        geo_error =1\n",
    "        latitude, longitude, geo_content = None, None, None\n",
    "#         break\n",
    "    #num_reviews\n",
    "    try:\n",
    "        num_reviews = s.find('div', attrs = {'class': 'rs rating'}).find('a').get('content')\n",
    "        if num_reviews == None:\n",
    "            num_reviews = s.find('a', {'property': \"reviewCount\"}).get('content')    \n",
    "    except:\n",
    "        num_reviews = 0\n",
    "        review_error=1    \n",
    "    #review_score\n",
    "    try:\n",
    "        review_score = s.find('div', attrs = {'class': 'heading_rating separator'}).find('img').get('content')\n",
    "        if review_score == None:\n",
    "            review_score = s.find('a', {'property': \"ratingValue\"}).get('content')\n",
    "    except:\n",
    "        review_score = 0 \n",
    "        score_error =1\n",
    "    #ranking\n",
    "    try:\n",
    "        ranking = s.find('b', attrs = {'class':'rank_text wrap'}).text.strip().replace('#',\"\")\n",
    "    except:\n",
    "        ranking = 999\n",
    "        ranking_error=1\n",
    "    #tag\n",
    "    try:\n",
    "        tags = \", \".join(label.text.strip() for label in s.select('div.detail > a') + s.select('span.collapse.hidden > a'))\n",
    "    except:\n",
    "        tags = None\n",
    "        tag_error =1\n",
    "    #visit_length\n",
    "    if s.find(text =\"Recommended length of visit:\"):\n",
    "        visit_length = s.find(text =\"Recommended length of visit:\").parent.next_sibling\n",
    "    else:\n",
    "        visit_length = None\n",
    "    #fee\n",
    "    if s.find(text= \"Fee:\"):\n",
    "        fee = s.find(text= \"Fee:\").parent.next_sibling.upper()\n",
    "    else:\n",
    "        fee = 'NO'\n",
    "    #description\n",
    "    if s.find('div', attrs = {'class': \"listing_details\"}):\n",
    "        description = s.find('div', attrs = {'class': \"listing_details\"}).text.strip()\n",
    "    else:\n",
    "        description = None\n",
    "\n",
    "    input_list = [index, name, street_address, city, state_abb, state, postal_code, country, full_address, latitude, longitude, num_reviews, review_score, ranking, tags, visit_length, fee, description, url, geo_content]\n",
    "    poi_detail_state_park.loc[len(poi_detail_state_park)] = input_list\n",
    "    \n",
    "    error_message = [index, name, url,state_abb_error, address_error, geo_error, review_error, score_error, ranking_error, tag_error]\n",
    "    error_message_df.loc[len(poi_detail_state_park)] =error_message\n",
    "    index += 1\n",
    "#     time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import web_scraping_tripadvisor as web\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_message_df.to_csv('error_message.csv', encoding=('utf-8'))\n",
    "poi_detail_state_park.to_csv(\"poi_detail_state_park.csv\", encoding=('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    poi_additional_detail = poi_detail_state_park[['index','name','url','address','geo_content']]\n",
    "\n",
    "    geo_content_detail=poi_detail_state_park.pop('geo_content')\n",
    "except:\n",
    "    None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "db.geo_content.insert_many(poi_additional_detail.to_dict('records'))\n",
    "poi_detail_state_park.to_sql('poi_detail_state_park_table',engine, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# poi_detail_state_park[poi_detail_state_park['name']== 'Jessie M. Honeyman Memorial State Park']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# poi_detail_state_park.loc[2065]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# poi_detail_state_park.drop(poi_detail_state_park.index[2065:], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park.to_csv(\"poi_detail_state_park.csv\", encoding=('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park = pd.read_csv('poi_detail_state_park.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incorrect_long = poi_detail_state_park.coord_long.loc[2646]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_idx = poi_detail_state_park[poi_detail_state_park.coord_long == incorrect_long].index.values\n",
    "for index in update_idx:\n",
    "    full_address = poi_detail_state_park.loc[index].address\n",
    "    name = poi_detail_state_park.loc[index].name\n",
    "    try:\n",
    "        print 'start index: ', index\n",
    "        latitude, longitude, geo_content = find_latlng(full_address, name)\n",
    "        poi_detail_state_park.set_value(index, 'coord_long', longitude)\n",
    "        poi_detail_state_park.set_value(index, 'coord_lat', latitude)\n",
    "        poi_detail_state_park.set_value(index, 'geo_content', geo_content)\n",
    "        print poi_detail_state_park.loc[index][['coord_long','coord_lat','geo_content']]\n",
    "    except:\n",
    "        print 'why', index\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park.to_csv('poi_detail_state_park_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_additional_detail = poi_detail_state_park[['index','name','url','address','geo_content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_content_detail=poi_detail_state_park.pop('geo_content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park['geo_content'] = geo_content_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.geo_content.insert_many(poi_additional_detail.to_dict('records'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park.to_sql('poi_detail_state_park_table',engine, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g35805-d1134861-Reviews-Cloud_Gate-Chicago_Illinois.html'\n",
    "htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g60713-d127854-Reviews-San_Francisco_Zoo-San_Francisco_California.html'\n",
    "htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g60750-d104122-Reviews-San_Diego_Zoo-San_Diego_California.html'\n",
    "htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g60713-d102523-Reviews-Alcatraz_Island-San_Francisco_California.html'\n",
    "# htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g32474-d4236729-Reviews-Harmony_Headlands_State_Park-Harmony_San_Luis_Obispo_County_California.html'\n",
    "# htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g42926-d142814-Reviews-Cannon_Valley_Trail-Cannon_Falls_Minnesota.html'\n",
    "# htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g42891-d126627-Reviews-Paul_Bunyan_State_Trail-Brainerd_Minnesota.html'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "r=requests.get(htmlurl,headers=headers)\n",
    "s = BS(r.text, 'html.parser')\n",
    "\n",
    "\n",
    "# for div in s.find('div', attrs = {'class' : \"separator\" }):\n",
    "#     for tag in div.:\n",
    "#         if tag.name == 'div' and tag.get('class', '') == ['detail']:\n",
    "#             print tag.text\n",
    "#     for item in div.contents:\n",
    "# #         print item\n",
    "#         if type(item)== 'bs4.element.Tag' and item.name == \"detail\":\n",
    "#             print 1234567890\n",
    "st = time.time()\n",
    "for div in s.findAll(\"div\", {\"class\": \"separator\"}):\n",
    "    for tag in div.contents:\n",
    "        if isinstance(tag, bs4.element.Tag) and tag.get('class',\"\") == ['detail'] :\n",
    "            tags =  tag.text.encode('utf8').strip()\n",
    "print time.time() - st\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# s.find('span',{'property':'addressCountry'}).get('content')\n",
    "# s.select('span[property=\"addressCountry\"]').get('content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#index\n",
    "\n",
    "#name\n",
    "name = s.find('h1', attrs = {'class':'heading_name'}).text.strip()\n",
    "#city\n",
    "city = s.find('span', attrs = {'property':'addressLocality'}).text.strip()\n",
    "street_address = s.find('span', attrs = {'class':'street-address'}).text.strip()\n",
    "#state\n",
    "state_abb = s.find('span', attrs = {'property':'addressRegion'}).text.strip()\n",
    "# state = state_abb_dict.keys()[state_abb_dict.values().index(state_abb)]\n",
    "postal_code = s.find('span', attrs = {'property':'postalCode'}).text.strip()\n",
    "\n",
    "#country\n",
    "country = s.find('span',{'property':'addressCountry'}).get('content')\n",
    "#address\n",
    "full_address = street_address+', '+city+', '+state_abb+', '+postal_code+', '+country\n",
    "\n",
    "# from geopy.geocoders import Nominatim\n",
    "# geolocator = Nominatim()\n",
    "# location =geolocator.geocode(street_address+', '+city+', '+state_abb+', '+country)\n",
    "# #coord_lat\n",
    "# coord_lat = location.latitude \n",
    "# #coord_long\n",
    "# coord_long =location.longitude\n",
    "#num_reviews\n",
    "# num_reviews = s.find('div', attrs = {'class': 'rs rating'}).find('a').get('content')\n",
    "\n",
    "#review_score\n",
    "# review_score = s.find('div', attrs = {'class': 'heading_rating separator'}).find('img').get('content')\n",
    "\n",
    "#ranking\n",
    "ranking = s.find('b', attrs = {'class':'rank_text wrap'}).text.strip().replace('#',\"\")\n",
    "\n",
    "#tag\n",
    "tags = \", \".join(label.text for label in s.select('div.detail > a') + s.select('span[class=\"collapse hidden\"] > a'))\n",
    "\n",
    "#visit_length\n",
    "# visit_length = s.find(text =\"Recommended length of visit:\").parent.next_sibling\n",
    "\n",
    "# #fee\n",
    "# fee = s.find(text= \"Fee:\").parent.next_sibling\n",
    "\n",
    "#description\n",
    "description = s.find('div', attrs = {'class': \"listing_details\"}).text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st =time.time()\n",
    "d =\", \".join(label.text.strip() for label in s.select('div.listing_details'))\n",
    "# print d \n",
    "ed = time.time() -st\n",
    "print ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st =time.time()\n",
    "s.find('div', attrs = {'class': \"listing_details\"}).text.strip()\n",
    "ed = time.time() -st\n",
    "print ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# s.select('span.hidden.collapse > a')\n",
    "postal_code = s.find('span', attrs = {'property':'postalCode'}).text.strip()\n",
    "print postal_code[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# num_reviews = s.find('div', attrs = {'class': 'rs rating'}).find('a').get('content')\n",
    "t1 = time.time()\n",
    "s.select('a[property=\"reviewCount\"]')[0].get(\"content\")\n",
    "t2 = time.time()\n",
    "s.find('a', {'property': \"reviewCount\"}).get('content')\n",
    "et = time.time()\n",
    "print et -t1, et-t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install python-google-places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from googleplaces import GooglePlaces, types, lang\n",
    "\n",
    "YOUR_API_KEY = 'AIzaSyDJh9EWCA_v0_B3SvjzjUA3OSVYufPJeGE'\n",
    "google_places = GooglePlaces(YOUR_API_KEY)\n",
    "print name, full_address\n",
    "address1 = \"393 County Road 174, Grove Hill, AL, 35975, United States\"\n",
    "query_result = google_places.nearby_search(location = address1, keyword=name)\n",
    "query_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name, full_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# s.select('div[class=\"detail\"] > a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# <span class=\"collapse hidden\">, <a href=\"/Attractions-g60713-Activities-c57-t68-San_Francisco_California.html\">Nature &amp; Wildlife Areas</a></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# detail = {}\n",
    "# addition_info = s.find('div', attrs = {'class':'details_wrapper'}).text.strip('\\n').replace(\"\\n\\n\",\"\\n\").split('\\n')\n",
    "# # if addition_info[0] == 'Description':\n",
    "# #     print addition_info[1]\n",
    "# addition_info\n",
    "\n",
    "# for info in addition_info:\n",
    "#     info_list = info.split(':')\n",
    "#     if info_list[0]==\"Fee\":\n",
    "#         details[\"Fee\"] = info_list[1]\n",
    "#     else:\n",
    "#         details[\"length of visit\"] = info_list[1]\n",
    "# details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fee = s.find('div', {'class':'details_wrapper'})\n",
    "# fee\n",
    "# length_visit = s.find(text =\"Recommended length of visit:\").parent.next_sibling\n",
    "# length_visit\n",
    "# fee = s.find(text= \"Fee:\").parent.next_sibling\n",
    "# fee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# description = s.find('div', attrs = {'class': \"listing_details\"}).text.strip()\n",
    "# print description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(query_result.places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## different api try\n",
    "\n",
    "#     try:\n",
    "#         YOUR_API_KEY = 'AIzaSyDMbpmHBLl7dTOXUOMZP7Vi3zbMJlByEKM'\n",
    "#         google_places = GooglePlaces(YOUR_API_KEY)\n",
    "#         latitude, longitude, google_result_name =  find_geo_location(full_address, name)\n",
    "#     except:\n",
    "#         print \"API error, try different key\"\n",
    "#         time.sleep(20)\n",
    "#         try:\n",
    "#             YOUR_API_KEY = 'AIzaSyAwx3xg6oJ0yiPV3MIunBa1kx6N7v5Tcw8'\n",
    "#             google_places = GooglePlaces(YOUR_API_KEY)\n",
    "#             latitude, longitude, google_result_name =  find_geo_location(full_address, name)\n",
    "#         except:\n",
    "#             print \"both Key dont work\"\n",
    "#             print\" location not found: \", name, \"address : \", full_address\n",
    "#             break\n",
    "#     if location:\n",
    "#         #coord_lat\n",
    "#         poi_detail_state_park['coord_lat'] = location.latitude \n",
    "#         #coord_long\n",
    "#         poi_detail_state_park['coord_long'] =location.longitude\n",
    "#     else:\n",
    "#         print\" location not found: \", name, \"address : \", full_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_abb_error_ix = error_message_df[error_message_df['state_abb_error']==1]['index']\n",
    "address_error_ix = error_message_df[error_message_df['address_error']==1]['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# poi_detail_state_park_df.ix[state_abb_error_ix][['state_abb','state','country']]\n",
    "poi_detail_state_park_df.ix[address_error_ix][['address','country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_message_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# poi_detail_state_park.fee[poi_detail_state_park.fee == 'NO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "err = error_message_df[error_message_df.review_error == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, link in enumerate(poi_detail_state_park_df.ix[err][['name','url']].url):\n",
    "    print i, link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_message_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park_df.drop_duplicates('coord_lat').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# htmlurl = 'https://en.wikipedia.org/wiki/List_of_areas_in_the_United_States_National_Park_System'\n",
    "htmlurl= 'https://en.wikipedia.org/wiki/List_of_national_parks_of_the_United_States'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "r=requests.get(htmlurl,headers=headers)\n",
    "s = BS(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "national_park_US_df= pd.DataFrame(columns=[\"name\",\"state\"])\n",
    "name, state =None, None\n",
    "table =  s.find('table', {\"class\" : \"wikitable\"})\n",
    "for row in table.findAll(\"tr\")[1:]:\n",
    "    if row.find('th', {'scope':\"row\"}) != None:\n",
    "        name = row.find('th', {'scope':\"row\"}).next_element.get('title')\n",
    "    cells = row.findAll(\"td\")\n",
    "    #For each \"tr\", assign each \"td\" to a variable.\n",
    "    if len(cells) == 6:\n",
    "        state = cells[1].find(text=True)\n",
    "    national_park_US_df.loc[len(national_park_US_df)] = [name, state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acadia National Park</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>National Park of American Samoa</td>\n",
       "      <td>American Samoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arches National Park</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Badlands National Park</td>\n",
       "      <td>South Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Big Bend National Park</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Biscayne National Park</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Black Canyon of the Gunnison National Park</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bryce Canyon National Park</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Canyonlands National Park</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Capitol Reef National Park</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Carlsbad Caverns National Park</td>\n",
       "      <td>New Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Channel Islands National Park</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Congaree National Park</td>\n",
       "      <td>South Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Crater Lake National Park</td>\n",
       "      <td>Oregon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cuyahoga Valley National Park</td>\n",
       "      <td>Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Death Valley National Park</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Denali National Park and Preserve</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dry Tortugas National Park</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Everglades National Park</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gates of the Arctic National Park and Preserve</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Glacier National Park (U.S.)</td>\n",
       "      <td>Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Glacier Bay National Park and Preserve</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Grand Canyon National Park</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Grand Teton National Park</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Great Basin National Park</td>\n",
       "      <td>Nevada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Great Sand Dunes National Park and Preserve</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Great Smoky Mountains National Park</td>\n",
       "      <td>Tennessee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Guadalupe Mountains National Park</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Haleakal National Park</td>\n",
       "      <td>Hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Hawaii Volcanoes National Park</td>\n",
       "      <td>Hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Hot Springs National Park</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Isle Royale National Park</td>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Joshua Tree National Park</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Katmai National Park and Preserve</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Kenai Fjords National Park</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kings Canyon National Park</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Kobuk Valley National Park</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lake Clark National Park and Preserve</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Lassen Volcanic National Park</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Mammoth Cave National Park</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Mesa Verde National Park</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Mount Rainier National Park</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>North Cascades National Park</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Olympic National Park</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Petrified Forest National Park</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Pinnacles National Park</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Redwood National and State Parks</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rocky Mountain National Park</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Saguaro National Park</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sequoia National Park</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Shenandoah National Park</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Theodore Roosevelt National Park</td>\n",
       "      <td>North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Virgin Islands National Park</td>\n",
       "      <td>United States Virgin Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Voyageurs National Park</td>\n",
       "      <td>Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Wind Cave National Park</td>\n",
       "      <td>South Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>WrangellSt. Elias National Park and Preserve</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Yellowstone National Park</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Yosemite National Park</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Zion National Park</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              name  \\\n",
       "0                             Acadia National Park   \n",
       "1                  National Park of American Samoa   \n",
       "2                             Arches National Park   \n",
       "3                           Badlands National Park   \n",
       "4                           Big Bend National Park   \n",
       "5                           Biscayne National Park   \n",
       "6       Black Canyon of the Gunnison National Park   \n",
       "7                       Bryce Canyon National Park   \n",
       "8                        Canyonlands National Park   \n",
       "9                       Capitol Reef National Park   \n",
       "10                  Carlsbad Caverns National Park   \n",
       "11                   Channel Islands National Park   \n",
       "12                          Congaree National Park   \n",
       "13                       Crater Lake National Park   \n",
       "14                   Cuyahoga Valley National Park   \n",
       "15                      Death Valley National Park   \n",
       "16               Denali National Park and Preserve   \n",
       "17                      Dry Tortugas National Park   \n",
       "18                        Everglades National Park   \n",
       "19  Gates of the Arctic National Park and Preserve   \n",
       "20                    Glacier National Park (U.S.)   \n",
       "21          Glacier Bay National Park and Preserve   \n",
       "22                      Grand Canyon National Park   \n",
       "23                       Grand Teton National Park   \n",
       "24                       Great Basin National Park   \n",
       "25     Great Sand Dunes National Park and Preserve   \n",
       "26             Great Smoky Mountains National Park   \n",
       "27               Guadalupe Mountains National Park   \n",
       "28                         Haleakal National Park   \n",
       "29                  Hawaii Volcanoes National Park   \n",
       "30                       Hot Springs National Park   \n",
       "31                       Isle Royale National Park   \n",
       "32                       Joshua Tree National Park   \n",
       "33               Katmai National Park and Preserve   \n",
       "34                      Kenai Fjords National Park   \n",
       "35                      Kings Canyon National Park   \n",
       "36                      Kobuk Valley National Park   \n",
       "37           Lake Clark National Park and Preserve   \n",
       "38                   Lassen Volcanic National Park   \n",
       "39                      Mammoth Cave National Park   \n",
       "40                        Mesa Verde National Park   \n",
       "41                     Mount Rainier National Park   \n",
       "42                    North Cascades National Park   \n",
       "43                           Olympic National Park   \n",
       "44                  Petrified Forest National Park   \n",
       "45                         Pinnacles National Park   \n",
       "46                Redwood National and State Parks   \n",
       "47                    Rocky Mountain National Park   \n",
       "48                           Saguaro National Park   \n",
       "49                           Sequoia National Park   \n",
       "50                        Shenandoah National Park   \n",
       "51                Theodore Roosevelt National Park   \n",
       "52                    Virgin Islands National Park   \n",
       "53                         Voyageurs National Park   \n",
       "54                         Wind Cave National Park   \n",
       "55   WrangellSt. Elias National Park and Preserve   \n",
       "56                       Yellowstone National Park   \n",
       "57                          Yosemite National Park   \n",
       "58                              Zion National Park   \n",
       "\n",
       "                           state  \n",
       "0                          Maine  \n",
       "1                 American Samoa  \n",
       "2                           Utah  \n",
       "3                   South Dakota  \n",
       "4                          Texas  \n",
       "5                        Florida  \n",
       "6                       Colorado  \n",
       "7                           Utah  \n",
       "8                           Utah  \n",
       "9                           Utah  \n",
       "10                    New Mexico  \n",
       "11                    California  \n",
       "12                South Carolina  \n",
       "13                        Oregon  \n",
       "14                          Ohio  \n",
       "15                    California  \n",
       "16                        Alaska  \n",
       "17                       Florida  \n",
       "18                       Florida  \n",
       "19                        Alaska  \n",
       "20                       Montana  \n",
       "21                        Alaska  \n",
       "22                       Arizona  \n",
       "23                       Wyoming  \n",
       "24                        Nevada  \n",
       "25                      Colorado  \n",
       "26                     Tennessee  \n",
       "27                         Texas  \n",
       "28                        Hawaii  \n",
       "29                        Hawaii  \n",
       "30                      Arkansas  \n",
       "31                      Michigan  \n",
       "32                    California  \n",
       "33                        Alaska  \n",
       "34                        Alaska  \n",
       "35                    California  \n",
       "36                        Alaska  \n",
       "37                        Alaska  \n",
       "38                    California  \n",
       "39                      Kentucky  \n",
       "40                      Colorado  \n",
       "41                    Washington  \n",
       "42                    Washington  \n",
       "43                    Washington  \n",
       "44                       Arizona  \n",
       "45                    California  \n",
       "46                    California  \n",
       "47                      Colorado  \n",
       "48                       Arizona  \n",
       "49                    California  \n",
       "50                      Virginia  \n",
       "51                  North Dakota  \n",
       "52  United States Virgin Islands  \n",
       "53                     Minnesota  \n",
       "54                  South Dakota  \n",
       "55                        Alaska  \n",
       "56                       Wyoming  \n",
       "57                    California  \n",
       "58                          Utah  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_park_US_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 https://www.tripadvisor.com/Search?q=Acadia+National+Park+Maine&queryParsed=true&searchSessionId\n",
      "1 https://www.tripadvisor.com/Search?q=National+Park+of+American+Samoa+American+Samoa&queryParsed=true&searchSessionId\n",
      "2 https://www.tripadvisor.com/Search?q=Arches+National+Park+Utah&queryParsed=true&searchSessionId\n",
      "3 https://www.tripadvisor.com/Search?q=Badlands+National+Park+South+Dakota&queryParsed=true&searchSessionId\n",
      "4 https://www.tripadvisor.com/Search?q=Big+Bend+National+Park+Texas&queryParsed=true&searchSessionId\n",
      "5 https://www.tripadvisor.com/Search?q=Biscayne+National+Park+Florida&queryParsed=true&searchSessionId\n",
      "6 https://www.tripadvisor.com/Search?q=Black+Canyon+of+the+Gunnison+National+Park+Colorado&queryParsed=true&searchSessionId\n",
      "7 https://www.tripadvisor.com/Search?q=Bryce+Canyon+National+Park+Utah&queryParsed=true&searchSessionId\n",
      "8 https://www.tripadvisor.com/Search?q=Canyonlands+National+Park+Utah&queryParsed=true&searchSessionId\n",
      "9 https://www.tripadvisor.com/Search?q=Capitol+Reef+National+Park+Utah&queryParsed=true&searchSessionId\n",
      "10 https://www.tripadvisor.com/Search?q=Carlsbad+Caverns+National+Park+New+Mexico&queryParsed=true&searchSessionId\n",
      "11 https://www.tripadvisor.com/Search?q=Channel+Islands+National+Park+California&queryParsed=true&searchSessionId\n",
      "12 https://www.tripadvisor.com/Search?q=Congaree+National+Park+South+Carolina&queryParsed=true&searchSessionId\n",
      "13 https://www.tripadvisor.com/Search?q=Crater+Lake+National+Park+Oregon&queryParsed=true&searchSessionId\n",
      "14 https://www.tripadvisor.com/Search?q=Cuyahoga+Valley+National+Park+Ohio&queryParsed=true&searchSessionId\n",
      "15 https://www.tripadvisor.com/Search?q=Death+Valley+National+Park+California&queryParsed=true&searchSessionId\n",
      "16 https://www.tripadvisor.com/Search?q=Denali+National+Park+and+Preserve+Alaska&queryParsed=true&searchSessionId\n",
      "17 https://www.tripadvisor.com/Search?q=Dry+Tortugas+National+Park+Florida&queryParsed=true&searchSessionId\n",
      "18 https://www.tripadvisor.com/Search?q=Everglades+National+Park+Florida&queryParsed=true&searchSessionId\n",
      "19 https://www.tripadvisor.com/Search?q=Gates+of+the+Arctic+National+Park+and+Preserve+Alaska&queryParsed=true&searchSessionId\n",
      "20 https://www.tripadvisor.com/Search?q=Glacier+National+Park+(U.S.)+Montana&queryParsed=true&searchSessionId\n",
      "21 https://www.tripadvisor.com/Search?q=Glacier+Bay+National+Park+and+Preserve+Alaska&queryParsed=true&searchSessionId\n",
      "22 https://www.tripadvisor.com/Search?q=Grand+Canyon+National+Park+Arizona&queryParsed=true&searchSessionId\n",
      "23 https://www.tripadvisor.com/Search?q=Grand+Teton+National+Park+Wyoming&queryParsed=true&searchSessionId\n",
      "24 https://www.tripadvisor.com/Search?q=Great+Basin+National+Park+Nevada&queryParsed=true&searchSessionId\n",
      "25 https://www.tripadvisor.com/Search?q=Great+Sand+Dunes+National+Park+and+Preserve+Colorado&queryParsed=true&searchSessionId\n",
      "26 https://www.tripadvisor.com/Search?q=Great+Smoky+Mountains+National+Park+Tennessee&queryParsed=true&searchSessionId\n",
      "27 https://www.tripadvisor.com/Search?q=Guadalupe+Mountains+National+Park+Texas&queryParsed=true&searchSessionId\n",
      "28 https://www.tripadvisor.com/Search?q=Haleakal+National+Park+Hawaii&queryParsed=true&searchSessionId\n",
      "29 https://www.tripadvisor.com/Search?q=Hawaii+Volcanoes+National+Park+Hawaii&queryParsed=true&searchSessionId\n",
      "30 https://www.tripadvisor.com/Search?q=Hot+Springs+National+Park+Arkansas&queryParsed=true&searchSessionId\n",
      "31 https://www.tripadvisor.com/Search?q=Isle+Royale+National+Park+Michigan&queryParsed=true&searchSessionId\n",
      "32 https://www.tripadvisor.com/Search?q=Joshua+Tree+National+Park+California&queryParsed=true&searchSessionId\n",
      "33 https://www.tripadvisor.com/Search?q=Katmai+National+Park+and+Preserve+Alaska&queryParsed=true&searchSessionId\n",
      "34 https://www.tripadvisor.com/Search?q=Kenai+Fjords+National+Park+Alaska&queryParsed=true&searchSessionId\n",
      "35 https://www.tripadvisor.com/Search?q=Kings+Canyon+National+Park+California&queryParsed=true&searchSessionId\n",
      "36 https://www.tripadvisor.com/Search?q=Kobuk+Valley+National+Park+Alaska&queryParsed=true&searchSessionId\n",
      "37 https://www.tripadvisor.com/Search?q=Lake+Clark+National+Park+and+Preserve+Alaska&queryParsed=true&searchSessionId\n",
      "38 https://www.tripadvisor.com/Search?q=Lassen+Volcanic+National+Park+California&queryParsed=true&searchSessionId\n",
      "39 https://www.tripadvisor.com/Search?q=Mammoth+Cave+National+Park+Kentucky&queryParsed=true&searchSessionId\n",
      "40 https://www.tripadvisor.com/Search?q=Mesa+Verde+National+Park+Colorado&queryParsed=true&searchSessionId\n",
      "41 https://www.tripadvisor.com/Search?q=Mount+Rainier+National+Park+Washington&queryParsed=true&searchSessionId\n",
      "42 https://www.tripadvisor.com/Search?q=North+Cascades+National+Park+Washington&queryParsed=true&searchSessionId\n",
      "43 https://www.tripadvisor.com/Search?q=Olympic+National+Park+Washington&queryParsed=true&searchSessionId\n",
      "44 https://www.tripadvisor.com/Search?q=Petrified+Forest+National+Park+Arizona&queryParsed=true&searchSessionId\n",
      "45 https://www.tripadvisor.com/Search?q=Pinnacles+National+Park+California&queryParsed=true&searchSessionId\n",
      "46 https://www.tripadvisor.com/Search?q=Redwood+National+and+State+Parks+California&queryParsed=true&searchSessionId\n",
      "47 https://www.tripadvisor.com/Search?q=Rocky+Mountain+National+Park+Colorado&queryParsed=true&searchSessionId\n",
      "48 https://www.tripadvisor.com/Search?q=Saguaro+National+Park+Arizona&queryParsed=true&searchSessionId\n",
      "49 https://www.tripadvisor.com/Search?q=Sequoia+National+Park+California&queryParsed=true&searchSessionId\n",
      "50 https://www.tripadvisor.com/Search?q=Shenandoah+National+Park+Virginia&queryParsed=true&searchSessionId\n",
      "51 https://www.tripadvisor.com/Search?q=Theodore+Roosevelt+National+Park+North+Dakota&queryParsed=true&searchSessionId\n",
      "52 https://www.tripadvisor.com/Search?q=Virgin+Islands+National+Park+United+States+Virgin+Islands&queryParsed=true&searchSessionId\n",
      "53 https://www.tripadvisor.com/Search?q=Voyageurs+National+Park+Minnesota&queryParsed=true&searchSessionId\n",
      "54 https://www.tripadvisor.com/Search?q=Wind+Cave+National+Park+South+Dakota&queryParsed=true&searchSessionId\n",
      "55 https://www.tripadvisor.com/Search?q=WrangellSt.+Elias+National+Park+and+Preserve+Alaska&queryParsed=true&searchSessionId\n",
      "56 https://www.tripadvisor.com/Search?q=Yellowstone+National+Park+Wyoming&queryParsed=true&searchSessionId\n",
      "57 https://www.tripadvisor.com/Search?q=Yosemite+National+Park+California&queryParsed=true&searchSessionId\n",
      "58 https://www.tripadvisor.com/Search?q=Zion+National+Park+Utah&queryParsed=true&searchSessionId\n"
     ]
    }
   ],
   "source": [
    "for index in national_park_US_df.index:\n",
    "    keyword = national_park_US_df.name[index].replace(' ','+')+\"+\"+national_park_US_df.state[index].replace(' ','+')\n",
    "#     keyword = national_park_US_df.name[index].replace(' ','+')\n",
    "    trip_url = \"https://www.tripadvisor.com/Search?q=\" +keyword+\"&queryParsed=true&searchSessionId\"\n",
    "#     headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "#     r=requests.get(trip_url,headers=headers)\n",
    "#     test_s = BS(r.text, 'html.parser')\n",
    "    print index, trip_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import wikipedia\n",
    "# wiki =  wikipedia.page('List_of_national_parks_of_the_United_States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method WikipediaPage.section of <WikipediaPage 'List of national parks of the United States'>>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "https://www.tripadvisor.com/Search?q=Acadia+National+Park&geo=28940&queryParsed=true&searchSessionId=F658A1719FACDE7E30D13912D3D1B3381492826820567ssid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "https://www.tripadvisor.com/Search?q=Pinnacles+national+park&queryParsed=true&searchSessionId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://www.tripadvisor.com/Search?q=Acadia+National+Park&queryParsed=true&searchSessionId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test =national_park_US_df.name[0].replace(\" \", \"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip_url = \"https://www.tripadvisor.com/Search?q=\" +test+\"&queryParsed=true&searchSessionId\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "r=requests.get(trip_url,headers=headers)\n",
    "test_s = BS(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'Sequio National Park'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
