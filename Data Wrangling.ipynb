{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import requests\n",
    "import psycopg2\n",
    "import json\n",
    "import simplejson\n",
    "import urllib\n",
    "import config\n",
    "import ast\n",
    "import bs4\n",
    "import pprint\n",
    "import progressbar\n",
    "from pymongo import MongoClient\n",
    "from geopy.geocoders import Nominatim\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from operator import itemgetter\n",
    "from sklearn.cluster import KMeans\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade progressbar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_str = \"dbname='travel_with_friends' user='Gon' host='localhost'\"\n",
    "# conn_str = \"dbname='travel_with_friends' user='Zoesh' host='localhost'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(conn_str)   \n",
    "cur = conn.cursor()   \n",
    "# cur.execute(\"select index, name, coord0, coord1 from poi_detail_table where city !='%s' and state = '%s';\" %(current_city, current_state))\n",
    "cur.execute(\"select distinct city, state from poi_detail_table;\" )\n",
    "all_cities = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cities[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cities_coords = pd.read_csv('cities_coords.csv', header=None)\n",
    "cities_coords.columns = ['area_code', 'city','state','nation', 'coord0','coord1']\n",
    "cities_coords = cities_coords[['city','state','nation', 'coord0','coord1']].drop_duplicates()\n",
    "cities_coords.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geolocator = Nominatim()\n",
    "\n",
    "for items in all_cities:\n",
    "    if cities_coords[cities_coords['state'] == items[1]][cities_coords.city == items[0]].shape[0] == 0:\n",
    "        location_name = ', '.join([items[0], items[1]])\n",
    "        try:\n",
    "            location = geolocator.geocode(location_name)\n",
    "            cities_coords.loc[len(cities_coords)] = [items[0], items[1], 'US', location.latitude, location.longitude]\n",
    "        except:\n",
    "            \"error, rest\"\n",
    "            time.sleep(20)\n",
    "            print\" start again\"\n",
    "            \n",
    "            \n",
    "#         print cities_coords.loc(len(cities_coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities_coords.to_csv('all_cities_coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://Gon@localhost:5432/travel_with_friends')\n",
    "cities_coords.to_sql('all_cities_coords',engine, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import us_state_abbrevation as abb\n",
    "state_abb_dict = abb.abb2state\n",
    "state_abb_dict['CA']\n",
    "# print state_abb_dict.keys()[state_abb_dict.values().index('CA')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from googleplaces import GooglePlaces, types, lang\n",
    "YOUR_API_KEY = 'AIzaSyDMbpmHBLl7dTOXUOMZP7Vi3zbMJlByEKM'\n",
    "google_places = GooglePlaces(YOUR_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import geocoder\n",
    "api_key1 = 'AIzaSyCrgwS_L75NfO9qzIKG8L0ox7zGw81BpRU'\n",
    "api_key2 = 'AIzaSyBwh4WqOIVJGJuKkmzpQxlkjahgx6qzimk'\n",
    "api_key3 = 'AIzaSyA25LW2CRcD9mSmiAWBYSPOSoiKP_m2plQ'\n",
    "api_key4 = 'AIzaSyB3l2Trzm4LnrC0nyUwwoM9803Fuwf0my4'\n",
    "api_key5 = 'AIzaSyDj0yH_35G1zMq5uYPF6X0ogkHYcLsNN1w'\n",
    "add = ' 497 lakeside drive'\n",
    "g = geocoder.google(add, key = api_key5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('api_key_list.config') as api_key_list_file:\n",
    "    api_key_list = json.load(api_key_list_file)\n",
    "api_key_list['api_key_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api_key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tmp = pd.read_csv('test_poi_detail_df_100.csv', index_col = 0)\n",
    "# df_tmp.to_csv('test_poi_detail_df_100.csv', index_col=None)\n",
    "df_tmp.head()\n",
    "s.find(text =\"Recommended length of visit:\")\n",
    "#         visit_length = s.find(text =\"Recommended length of visit:\").parent.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.zoeshrm\n",
    "db.TripAdvisor_state_park.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from web_scraping_tripadvisor import state_park_web as web\n",
    "state_park_pages = db.TripAdvisor_state_park.find()\n",
    "poi_detail_state_park_df, error_message_df = web(state_park_pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "page = db.TripAdvisor.find_one({'city': 'San Francisco, California'})\n",
    "search_visit_length = re.compile('Recommended length of visit:')\n",
    "s = BS(page['html'], \"html.parser\")\n",
    "#index\n",
    "#name\n",
    "input_list, error_message = [],[]\n",
    "state_abb_error, state_error, address_error, geo_error, review_error, score_error, ranking_error, tag_error = 0,0,0,0,0,0,0,0\n",
    "latitude, longitude, geo_content = None, None, None\n",
    "#     print name\n",
    "url = page['url']\n",
    "name = s.find('h1', attrs = {'class':'heading_name'}).text.strip()\n",
    "\n",
    "#street_address\n",
    "street_address = s.find('span', attrs = {'class':'street-address'}).text.strip()\n",
    "#city\n",
    "city = s.find('span', attrs = {'property':'addressLocality'}).text.strip()\n",
    "#state\n",
    "state_abb = s.find('span', attrs = {'property':'addressRegion'}).text.strip()\n",
    "if state_abb:\n",
    "    try:\n",
    "        # state = state_abb_dict.keys()[state_abb_dict.values().index(state_abb)]\n",
    "        state = abb2state_dict[state_abb]\n",
    "    except:\n",
    "        state_abb_error = 1\n",
    "        state = state_abb\n",
    "else:\n",
    "    state_error =1\n",
    "    state_abb = None\n",
    "    state = None\n",
    "#postal_code\n",
    "postal_code = s.find('span', attrs = {'property':'postalCode'}).text.strip()\n",
    "#country\n",
    "if s.find('span', attrs = {'property':'addressCountry'}).get('content'):\n",
    "    country = s.find('span',{'property':'addressCountry'}).get('content')\n",
    "elif s.find('span',{'property':'addressCountry'}).get('content') == None:\n",
    "    country = s.find('span',{'property':'addressCountry'}).text.strip()\n",
    "else:\n",
    "    country = 'United States'\n",
    "#address\n",
    "if state:\n",
    "    full_address = street_address+', '+city+', '+state+', '+postal_code[:5]+', '+country\n",
    "else:\n",
    "    address_error =1\n",
    "    full_address = street_address+', '+city+', '+postal_code[:5]+', '+country\n",
    "# if (name in name_lst) and (full_address in full_address_lst):\n",
    "#     continue\n",
    "# else:\n",
    "#     name_lst.append(name)\n",
    "#     full_address_lst.append(full_address)\n",
    "#coord\n",
    "try:\n",
    "    latitude, longitude, geo_content = find_latlng(full_address, name)\n",
    "except:\n",
    "    geo_error =1\n",
    "    latitude, longitude, geo_content = None, None, None\n",
    "\n",
    "#num_reviews\n",
    "try:\n",
    "    num_reviews = s.find('div', attrs = {'class': 'rs rating'}).find('a').get('content')\n",
    "    if num_reviews == None:\n",
    "        num_reviews = s.find('a', {'property': \"reviewCount\"}).get('content')    \n",
    "except:\n",
    "    num_reviews = 0\n",
    "    review_error=1    \n",
    "#review_score\n",
    "try:\n",
    "    review_score = s.find('div', attrs = {'class': 'heading_rating separator'}).find('img').get('content')\n",
    "    if review_score == None:\n",
    "        review_score = s.find('a', {'property': \"ratingValue\"}).get('content')\n",
    "except:\n",
    "    review_score = 0 \n",
    "    score_error =1\n",
    "#ranking\n",
    "try:\n",
    "    ranking = s.find('b', attrs = {'class':'rank_text wrap'}).text.strip().replace('#',\"\")\n",
    "except:\n",
    "    ranking = 999\n",
    "    ranking_error=1\n",
    "#tag\n",
    "try:\n",
    "    tags = \", \".join(label.text.strip() for label in s.select('div.detail > a') + s.select('span.collapse.hidden > a'))\n",
    "except:\n",
    "    tags = None\n",
    "    tag_error =1\n",
    "#visit_length\n",
    "if s.find('b', text =search_visit_length):\n",
    "    raw_visit_length = s.find('b', text =search_visit_length).next_sibling.strip()\n",
    "else:\n",
    "    raw_visit_length = None\n",
    "#fee\n",
    "if s.find(text= \"Fee:\"):\n",
    "    fee = s.find(text= \"Fee:\").parent.next_sibling.upper()\n",
    "else:\n",
    "    fee = 'NO'\n",
    "#description\n",
    "if s.find('div', attrs = {'class': \"listing_details\"}):\n",
    "    description = s.find('div', attrs = {'class': \"listing_details\"}).text.strip()\n",
    "else:\n",
    "    description = None\n",
    "# error_message = [len(poi_detail_state_park_df), name, url,state_abb_error, state_error, address_error, geo_error, review_error, score_error, ranking_error, tag_error]\n",
    "# error_message_df.loc[len(poi_detail_state_park_df)] =error_message\n",
    "\n",
    "\n",
    "# input_list = [len(poi_detail_state_park_df), name, street_address, city, state_abb, state, postal_code, country, full_address, latitude, longitude, num_reviews, review_score, ranking, tags, visit_length, fee, description, url, geo_content]\n",
    "# poi_detail_state_park_df.loc[len(poi_detail_state_park_df)] = input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "search_visit_length = re.compile('Recommended length of visit:')\n",
    "test = s.find('b', text =search_visit_length).next_sibling.strip()\n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('api_key_list.config') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['api_key_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_poi = pd.read_csv('poi_detail_df.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_fee = re.compile('Fee:')\n",
    "df_poi = pd.read_csv('test_poi_detail_df.csv', index_col= 0)\n",
    "poi_pages = db.TripAdvisor.find()\n",
    "fee_lst = []\n",
    "cnt = 0\n",
    "for page in poi_pages:\n",
    "    s = BS(page['html'], \"html.parser\")\n",
    "    if s.find('b', text= search_fee):\n",
    "        fee = s.find('b',text= search_fee).next_sibling.strip()\n",
    "    else:\n",
    "        fee = 'Unknown'\n",
    "    fee_lst.append(fee)\n",
    "    cnt+=1\n",
    "    if cnt%100 ==0 :\n",
    "        print '#items in fee lst: ',len(fee_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fee_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_message_df.to_csv('error_message.csv', encoding=('utf-8'))\n",
    "poi_detail_state_park_df.to_csv(\"poi_detail_state_park.csv\", encoding=('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    poi_additional_detail = poi_detail_state_park[['index','name','url','address','geo_content']]\n",
    "\n",
    "    geo_content_detail=poi_detail_state_park.pop('geo_content')\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.geo_content.drop()\n",
    "db.geo_content.insert_many(poi_additional_detail.to_dict('records'))\n",
    "poi_detail_state_park.to_sql('poi_detail_state_park_table',engine, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print poi_detail_state_park_df.shape, error_message_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_message_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_latlng(full_address, name):\n",
    "    g_address = geocoder.google(full_address)\n",
    "    if g_address.ok:\n",
    "        latitude= g_address.lat\n",
    "        longitude = g_address.lng\n",
    "        return latitude, longitude, g_address.content\n",
    "    \n",
    "    g_name = geocoder.google(name)\n",
    "    if g_name.ok:\n",
    "        latitude= g_name.lat\n",
    "        longitude = g_name.lng\n",
    "        return latitude, longitude, g_name.content\n",
    "    else:\n",
    "        latitude = None\n",
    "        longitude = None\n",
    "        return latitude, longitude, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_geo_location(full_address, name):\n",
    "    query_result = google_places.nearby_search(location= full_address, keyword=name)\n",
    "    if len(query_result.places) >0:\n",
    "        best_result = query_result.places[0]\n",
    "        latitude = best_result.geo_location[\"lat\"]\n",
    "        longitude = best_result.geo_location[\"lng\"]\n",
    "        google_result_name = best_result.name\n",
    "\n",
    "        return latitude, longitude, google_result_name\n",
    "    else:\n",
    "        print name, \"google API cant find here.\"\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park=pd.DataFrame(columns=['index','name','street_address','city','state_abb','state','postal_code','country','address','coord_lat','coord_long','num_reviews','review_score','ranking','tag','visit_length','fee','description','url',\"geo_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_message_df = pd.DataFrame(columns=['index','name','url','state_abb_error','address_error','geo_error','review_error','score_error','ranking_error','tag_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# poi_detail_state_park2=pd.DataFrame(columns=['index','name','street_address','city','state_abb','state','postal_code','country','address','coord_lat','coord_long','num_reviews','review_score','ranking','tag','visit_length','fee','description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_park_pages = db.TripAdvisor_state_park.find()\n",
    "index = 0\n",
    "for page in state_park_pages[len(poi_detail_state_park):]:\n",
    "    s = BS(page['html'], \"html.parser\")\n",
    "    #index\n",
    "    #name\n",
    "    error_message = []\n",
    "    state_abb_error, address_error, geo_error, review_error, score_error, ranking_error, tag_error = 0,0,0,0,0,0,0\n",
    "    input_list = []\n",
    "#     print name\n",
    "\n",
    "    url = page['url']\n",
    "    name = s.find('h1', attrs = {'class':'heading_name'}).text.strip()\n",
    "\n",
    "    #street_address\n",
    "    street_address = s.find('span', attrs = {'class':'street-address'}).text.strip()\n",
    "    #city\n",
    "    city = s.find('span', attrs = {'property':'addressLocality'}).text.strip()\n",
    "\n",
    "    #state\n",
    "    state_abb = s.find('span', attrs = {'property':'addressRegion'}).text.strip()\n",
    "    if state_abb:\n",
    "        try:\n",
    "            state = state_abb_dict[state_abb]\n",
    "        except:\n",
    "            state_abb_error = 1\n",
    "            state = state_abb\n",
    "    else:\n",
    "        state_abb = None\n",
    "        state = None\n",
    "    #postal_code\n",
    "    postal_code = s.find('span', attrs = {'property':'postalCode'}).text.strip()\n",
    "    #country\n",
    "    if s.find('span', attrs = {'property':'addressCountry'}).get('content'):\n",
    "        country = s.find('span',{'property':'addressCountry'}).get('content')\n",
    "    elif s.find('span',{'property':'addressCountry'}).get('content') == None:\n",
    "        country = s.find('span',{'property':'addressCountry'}).text.strip()\n",
    "    else:\n",
    "        country = 'United States'\n",
    "    #address\n",
    "    if state_abb:\n",
    "        full_address = street_address+', '+city+', '+state_abb+', '+postal_code[:5]+', '+country\n",
    "    else:\n",
    "        address_error =1\n",
    "        full_address = street_address+', '+city+', '+postal_code[:5]+', '+country\n",
    "\n",
    "    #coord\n",
    "    try:\n",
    "        latitude, longitude, geo_content = find_latlng(full_address, name)\n",
    "    except:\n",
    "        geo_error =1\n",
    "        latitude, longitude, geo_content = None, None, None\n",
    "#         break\n",
    "    #num_reviews\n",
    "    try:\n",
    "        num_reviews = s.find('div', attrs = {'class': 'rs rating'}).find('a').get('content')\n",
    "        if num_reviews == None:\n",
    "            num_reviews = s.find('a', {'property': \"reviewCount\"}).get('content')    \n",
    "    except:\n",
    "        num_reviews = 0\n",
    "        review_error=1    \n",
    "    #review_score\n",
    "    try:\n",
    "        review_score = s.find('div', attrs = {'class': 'heading_rating separator'}).find('img').get('content')\n",
    "        if review_score == None:\n",
    "            review_score = s.find('a', {'property': \"ratingValue\"}).get('content')\n",
    "    except:\n",
    "        review_score = 0 \n",
    "        score_error =1\n",
    "    #ranking\n",
    "    try:\n",
    "        ranking = s.find('b', attrs = {'class':'rank_text wrap'}).text.strip().replace('#',\"\")\n",
    "    except:\n",
    "        ranking = 999\n",
    "        ranking_error=1\n",
    "    #tag\n",
    "    try:\n",
    "        tags = \", \".join(label.text.strip() for label in s.select('div.detail > a') + s.select('span.collapse.hidden > a'))\n",
    "    except:\n",
    "        tags = None\n",
    "        tag_error =1\n",
    "    #visit_length\n",
    "    if s.find(text =\"Recommended length of visit:\"):\n",
    "        visit_length = s.find(text =\"Recommended length of visit:\").parent.next_sibling\n",
    "    else:\n",
    "        visit_length = None\n",
    "    #fee\n",
    "    if s.find(text= \"Fee:\"):\n",
    "        fee = s.find(text= \"Fee:\").parent.next_sibling.upper()\n",
    "    else:\n",
    "        fee = 'NO'\n",
    "    #description\n",
    "    if s.find('div', attrs = {'class': \"listing_details\"}):\n",
    "        description = s.find('div', attrs = {'class': \"listing_details\"}).text.strip()\n",
    "    else:\n",
    "        description = None\n",
    "\n",
    "    input_list = [index, name, street_address, city, state_abb, state, postal_code, country, full_address, latitude, longitude, num_reviews, review_score, ranking, tags, visit_length, fee, description, url, geo_content]\n",
    "    poi_detail_state_park.loc[len(poi_detail_state_park)] = input_list\n",
    "    \n",
    "    error_message = [index, name, url,state_abb_error, address_error, geo_error, review_error, score_error, ranking_error, tag_error]\n",
    "    error_message_df.loc[len(poi_detail_state_park)] =error_message\n",
    "    index += 1\n",
    "#     time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import web_scraping_tripadvisor as web\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_message_df.to_csv('error_message.csv', encoding=('utf-8'))\n",
    "poi_detail_state_park.to_csv(\"poi_detail_state_park.csv\", encoding=('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    poi_additional_detail = poi_detail_state_park[['index','name','url','address','geo_content']]\n",
    "\n",
    "    geo_content_detail=poi_detail_state_park.pop('geo_content')\n",
    "except:\n",
    "    None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "db.geo_content.insert_many(poi_additional_detail.to_dict('records'))\n",
    "poi_detail_state_park.to_sql('poi_detail_state_park_table',engine, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# poi_detail_state_park[poi_detail_state_park['name']== 'Jessie M. Honeyman Memorial State Park']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# poi_detail_state_park.loc[2065]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# poi_detail_state_park.drop(poi_detail_state_park.index[2065:], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park.to_csv(\"poi_detail_state_park.csv\", encoding=('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park = pd.read_csv('poi_detail_state_park.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_df = pd.read_csv('poi_detail_coords_1000.csv', index_col = 0)\n",
    "# np.isnan(poi_detail_df.coord_lat[0])\n",
    "poi_detail_df.coord_lat[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_idx = poi_detail_state_park[poi_detail_state_park.coord_long == incorrect_long].index.values\n",
    "for index in update_idx:\n",
    "    full_address = poi_detail_state_park.loc[index].address\n",
    "    name = poi_detail_state_park.loc[index].name\n",
    "    try:\n",
    "        print 'start index: ', index\n",
    "        latitude, longitude, geo_content = find_latlng(full_address, name)\n",
    "        poi_detail_state_park.set_value(index, 'coord_long', longitude)\n",
    "        poi_detail_state_park.set_value(index, 'coord_lat', latitude)\n",
    "        poi_detail_state_park.set_value(index, 'geo_content', geo_content)\n",
    "        print poi_detail_state_park.loc[index][['coord_long','coord_lat','geo_content']]\n",
    "    except:\n",
    "        print 'why', index\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park.to_csv('poi_detail_state_park_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_additional_detail = poi_detail_state_park[['index','name','url','address','geo_content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_content_detail=poi_detail_state_park.pop('geo_content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park['geo_content'] = geo_content_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.geo_content.insert_many(poi_additional_detail.to_dict('records'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park.to_sql('poi_detail_state_park_table',engine, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g35805-d1134861-Reviews-Cloud_Gate-Chicago_Illinois.html'\n",
    "htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g60713-d127854-Reviews-San_Francisco_Zoo-San_Francisco_California.html'\n",
    "htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g60750-d104122-Reviews-San_Diego_Zoo-San_Diego_California.html'\n",
    "htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g60713-d102523-Reviews-Alcatraz_Island-San_Francisco_California.html'\n",
    "# htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g32474-d4236729-Reviews-Harmony_Headlands_State_Park-Harmony_San_Luis_Obispo_County_California.html'\n",
    "# htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g42926-d142814-Reviews-Cannon_Valley_Trail-Cannon_Falls_Minnesota.html'\n",
    "# htmlurl = 'https://www.tripadvisor.com/Attraction_Review-g42891-d126627-Reviews-Paul_Bunyan_State_Trail-Brainerd_Minnesota.html'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "r=requests.get(htmlurl,headers=headers)\n",
    "s = BS(r.text, 'html.parser')\n",
    "\n",
    "\n",
    "# for div in s.find('div', attrs = {'class' : \"separator\" }):\n",
    "#     for tag in div.:\n",
    "#         if tag.name == 'div' and tag.get('class', '') == ['detail']:\n",
    "#             print tag.text\n",
    "#     for item in div.contents:\n",
    "# #         print item\n",
    "#         if type(item)== 'bs4.element.Tag' and item.name == \"detail\":\n",
    "#             print 1234567890\n",
    "st = time.time()\n",
    "for div in s.findAll(\"div\", {\"class\": \"separator\"}):\n",
    "    for tag in div.contents:\n",
    "        if isinstance(tag, bs4.element.Tag) and tag.get('class',\"\") == ['detail'] :\n",
    "            tags =  tag.text.encode('utf8').strip()\n",
    "print time.time() - st\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# s.find('span',{'property':'addressCountry'}).get('content')\n",
    "# s.select('span[property=\"addressCountry\"]').get('content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#index\n",
    "\n",
    "#name\n",
    "name = s.find('h1', attrs = {'class':'heading_name'}).text.strip()\n",
    "#city\n",
    "city = s.find('span', attrs = {'property':'addressLocality'}).text.strip()\n",
    "street_address = s.find('span', attrs = {'class':'street-address'}).text.strip()\n",
    "#state\n",
    "state_abb = s.find('span', attrs = {'property':'addressRegion'}).text.strip()\n",
    "# state = state_abb_dict.keys()[state_abb_dict.values().index(state_abb)]\n",
    "postal_code = s.find('span', attrs = {'property':'postalCode'}).text.strip()\n",
    "\n",
    "#country\n",
    "country = s.find('span',{'property':'addressCountry'}).get('content')\n",
    "#address\n",
    "full_address = street_address+', '+city+', '+state_abb+', '+postal_code+', '+country\n",
    "\n",
    "# from geopy.geocoders import Nominatim\n",
    "# geolocator = Nominatim()\n",
    "# location =geolocator.geocode(street_address+', '+city+', '+state_abb+', '+country)\n",
    "# #coord_lat\n",
    "# coord_lat = location.latitude \n",
    "# #coord_long\n",
    "# coord_long =location.longitude\n",
    "#num_reviews\n",
    "# num_reviews = s.find('div', attrs = {'class': 'rs rating'}).find('a').get('content')\n",
    "\n",
    "#review_score\n",
    "# review_score = s.find('div', attrs = {'class': 'heading_rating separator'}).find('img').get('content')\n",
    "\n",
    "#ranking\n",
    "ranking = s.find('b', attrs = {'class':'rank_text wrap'}).text.strip().replace('#',\"\")\n",
    "\n",
    "#tag\n",
    "tags = \", \".join(label.text for label in s.select('div.detail > a') + s.select('span[class=\"collapse hidden\"] > a'))\n",
    "\n",
    "#visit_length\n",
    "# visit_length = s.find(text =\"Recommended length of visit:\").parent.next_sibling\n",
    "\n",
    "# #fee\n",
    "# fee = s.find(text= \"Fee:\").parent.next_sibling\n",
    "\n",
    "#description\n",
    "description = s.find('div', attrs = {'class': \"listing_details\"}).text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st =time.time()\n",
    "d =\", \".join(label.text.strip() for label in s.select('div.listing_details'))\n",
    "# print d \n",
    "ed = time.time() -st\n",
    "print ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st =time.time()\n",
    "s.find('div', attrs = {'class': \"listing_details\"}).text.strip()\n",
    "ed = time.time() -st\n",
    "print ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# s.select('span.hidden.collapse > a')\n",
    "postal_code = s.find('span', attrs = {'property':'postalCode'}).text.strip()\n",
    "print postal_code[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# num_reviews = s.find('div', attrs = {'class': 'rs rating'}).find('a').get('content')\n",
    "t1 = time.time()\n",
    "s.select('a[property=\"reviewCount\"]')[0].get(\"content\")\n",
    "t2 = time.time()\n",
    "s.find('a', {'property': \"reviewCount\"}).get('content')\n",
    "et = time.time()\n",
    "print et -t1, et-t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install python-google-places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from googleplaces import GooglePlaces, types, lang\n",
    "\n",
    "YOUR_API_KEY = 'AIzaSyDJh9EWCA_v0_B3SvjzjUA3OSVYufPJeGE'\n",
    "google_places = GooglePlaces(YOUR_API_KEY)\n",
    "print name, full_address\n",
    "address1 = \"393 County Road 174, Grove Hill, AL, 35975, United States\"\n",
    "query_result = google_places.nearby_search(location = address1, keyword=name)\n",
    "query_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name, full_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# s.select('div[class=\"detail\"] > a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# <span class=\"collapse hidden\">, <a href=\"/Attractions-g60713-Activities-c57-t68-San_Francisco_California.html\">Nature &amp; Wildlife Areas</a></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# detail = {}\n",
    "# addition_info = s.find('div', attrs = {'class':'details_wrapper'}).text.strip('\\n').replace(\"\\n\\n\",\"\\n\").split('\\n')\n",
    "# # if addition_info[0] == 'Description':\n",
    "# #     print addition_info[1]\n",
    "# addition_info\n",
    "\n",
    "# for info in addition_info:\n",
    "#     info_list = info.split(':')\n",
    "#     if info_list[0]==\"Fee\":\n",
    "#         details[\"Fee\"] = info_list[1]\n",
    "#     else:\n",
    "#         details[\"length of visit\"] = info_list[1]\n",
    "# details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fee = s.find('div', {'class':'details_wrapper'})\n",
    "# fee\n",
    "# length_visit = s.find(text =\"Recommended length of visit:\").parent.next_sibling\n",
    "# length_visit\n",
    "# fee = s.find(text= \"Fee:\").parent.next_sibling\n",
    "# fee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# description = s.find('div', attrs = {'class': \"listing_details\"}).text.strip()\n",
    "# print description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(query_result.places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## different api try\n",
    "\n",
    "#     try:\n",
    "#         YOUR_API_KEY = 'AIzaSyDMbpmHBLl7dTOXUOMZP7Vi3zbMJlByEKM'\n",
    "#         google_places = GooglePlaces(YOUR_API_KEY)\n",
    "#         latitude, longitude, google_result_name =  find_geo_location(full_address, name)\n",
    "#     except:\n",
    "#         print \"API error, try different key\"\n",
    "#         time.sleep(20)\n",
    "#         try:\n",
    "#             YOUR_API_KEY = 'AIzaSyAwx3xg6oJ0yiPV3MIunBa1kx6N7v5Tcw8'\n",
    "#             google_places = GooglePlaces(YOUR_API_KEY)\n",
    "#             latitude, longitude, google_result_name =  find_geo_location(full_address, name)\n",
    "#         except:\n",
    "#             print \"both Key dont work\"\n",
    "#             print\" location not found: \", name, \"address : \", full_address\n",
    "#             break\n",
    "#     if location:\n",
    "#         #coord_lat\n",
    "#         poi_detail_state_park['coord_lat'] = location.latitude \n",
    "#         #coord_long\n",
    "#         poi_detail_state_park['coord_long'] =location.longitude\n",
    "#     else:\n",
    "#         print\" location not found: \", name, \"address : \", full_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_abb_error_ix = error_message_df[error_message_df['state_abb_error']==1]['index']\n",
    "address_error_ix = error_message_df[error_message_df['address_error']==1]['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# poi_detail_state_park_df.ix[state_abb_error_ix][['state_abb','state','country']]\n",
    "poi_detail_state_park_df.ix[address_error_ix][['address','country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_message_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# poi_detail_state_park.fee[poi_detail_state_park.fee == 'NO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "err = error_message_df[error_message_df.review_error == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, link in enumerate(poi_detail_state_park_df.ix[err][['name','url']].url):\n",
    "    print i, link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_message_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_detail_state_park_df.drop_duplicates('coord_lat').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# htmlurl = 'https://en.wikipedia.org/wiki/List_of_areas_in_the_United_States_National_Park_System'\n",
    "htmlurl= 'https://en.wikipedia.org/wiki/List_of_national_parks_of_the_United_States'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "r=requests.get(htmlurl,headers=headers)\n",
    "s = BS(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "\n",
    "name, state =None, None\n",
    "table =  s.find('table', {\"class\" : \"wikitable\"})\n",
    "# col_name =  [x.text for x in table.findAll(\"th\",{\"scope\":\"col\"})]\n",
    "# num_col = len(col_name)\n",
    "\n",
    "# wiki_table= pd.DataFrame(columns=col_name)\n",
    "national_park_US_df2 = pd.DataFrame(columns = [\"name\",\"state\",\"description\"])\n",
    "for row in table.findAll(\"tr\")[1:]:\n",
    "    if row.find('th', {'scope':\"row\"}) != None:\n",
    "        name = row.find('th', {'scope':\"row\"}).next_element.get('title')\n",
    "    cells = row.findAll(\"td\")\n",
    "    #For each \"tr\", assign each \"td\" to a variable.\n",
    "    if len(cells) == 6:\n",
    "        state = cells[1].find(text=True)\n",
    "        des = str(\"\".join(cells[5].findAll(text=True)).encode('utf8'))\n",
    "        description = re.sub(r\"\\[\\d+\\]\",\"\",des)\n",
    "\n",
    "    national_park_US_df2.loc[len(national_park_US_df2)] = [name, state, description]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"\".join(national_park_US_df2.desciption[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in national_park_US_df.index:\n",
    "    keyword = national_park_US_df.name[index].replace(' ','+')+\"+\"+national_park_US_df.state[index].replace(' ','+')\n",
    "#     keyword = national_park_US_df.name[index].replace(' ','+')\n",
    "    trip_url = \"https://www.tripadvisor.com/Search?q=\" +keyword+\"&queryParsed=true&searchSessionId\"\n",
    "#     headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "#     r=requests.get(trip_url,headers=headers)\n",
    "#     test_s = BS(r.text, 'html.parser')\n",
    "#     print index, trip_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "wiki =  wikipedia.page('List_of_national_parks_of_the_United_States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "https://www.tripadvisor.com/Search?q=Acadia+National+Park&geo=28940&queryParsed=true&searchSessionId=F658A1719FACDE7E30D13912D3D1B3381492826820567ssid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "https://www.tripadvisor.com/Search?q=Pinnacles+national+park&queryParsed=true&searchSessionId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://www.tripadvisor.com/Search?q=Acadia+National+Park&queryParsed=true&searchSessionId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test =national_park_US_df.name[0].replace(\" \", \"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip_url = \"https://www.tripadvisor.com/Search?q=\" +test+\"&queryParsed=true&searchSessionId\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "r=requests.get(trip_url,headers=headers)\n",
    "test_s = BS(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trip_url_30 = \"https://www.tripadvisor.com/Search?geo=191&redirect&q=national+parks&uiOrigin=MASTHEAD&ssrc=A&returnTo=__2F__Tourism__2D__g143030__2D__Great__5F__Basin__5F__National__5F__Park__5F__Nevada__2D__Vacations__2E__html&pid=3825&startTime=1492837392267&searchSessionId=F658A1719FACDE7E30D13912D3D1B3381492834657203ssid#&ssrc=g&o=0\"\n",
    "# trip_url_60 = \"https://www.tripadvisor.com/Search?geo=191&redirect&q=national+parks&uiOrigin=MASTHEAD&ssrc=A&returnTo=__2F__Tourism__2D__g143030__2D__Great__5F__Basin__5F__National__5F__Park__5F__Nevada__2D__Vacations__2E__html&pid=3825&startTime=1492837392267&searchSessionId=F658A1719FACDE7E30D13912D3D1B3381492834657203ssid#&ssrc=g&o=30\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "r=requests.get(trip_url_30,headers=headers)\n",
    "# trip_30 = BS(r.text, 'html.parser')\n",
    "# r=requests.get(trip_url_60,headers=headers)\n",
    "# trip_60 = BS(r.text, 'html.parser')\n",
    "\n",
    "import urllib\n",
    "\n",
    "trip_30_html = urllib.urlopen(\"trip_30.html\").read()\n",
    "trip_60_html = urllib.urlopen(\"trip_60.html\").read()\n",
    "trip_30 = BS(trip_30_html, 'html.parser')\n",
    "trip_60 = BS(trip_60_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "to_do = re.compile(\"Things to do\")\n",
    "# trip_search_result = pd.DataFrame(columns=[\"name\",\"url\"])\n",
    "\n",
    "\n",
    "\n",
    "for poi in trip_60.findAll('div', {\"class\": \"title\"}):\n",
    "    name = poi.text\n",
    "    for child in poi.next_siblings:\n",
    "        if child.find(text=to_do) != None:\n",
    "            url =  child.find(text=to_do).parent.get('href')\n",
    "            \n",
    "    trip_search_result.loc[len(trip_search_result)] = [name, url]\n",
    "    \n",
    "# for link in trip_30.findAll(text = to_do):\n",
    "#     print link.parent.get('href')\n",
    "\n",
    "#     name = poi.text\n",
    "#     url = poi.get('onclick').replace(\"ta.setEvtCookie('Search_Results_Page', 'POI_Name', '', 0, '\", \"\").replace(\"')\",\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trip_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # for url in trip_search_result.url:\n",
    "    \n",
    "# url = trip_search_result.url[0]\n",
    "# headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "# r=requests.get(url,headers=headers)\n",
    "# s = BS(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def request_s(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    r=requests.get(url,headers=headers)\n",
    "    s = BS(r.text, 'html.parser')\n",
    "    return s\n",
    "def thing_to_do(s):\n",
    "    thing_to_do = pd.DataFrame(columns=[\"national_park_name\",\"activate_name\",\"url\",\"num_reviews\",\"score\",\"ranking\",\"tags\"])\n",
    "    national_park_name = s.find('h1', {\"id\": \"HEADING\"}).text.strip('\\n').replace(\"Things to Do in \",\"\")\n",
    "    print \"park name: \",national_park_name\n",
    "    for activate in s.findAll('div', {\"class\":\"listing_title\"}):\n",
    "        activate_name = activate.text.strip()\n",
    "        url =\"https://www.tripadvisor.com\"+ activate.find('a').get(\"href\")\n",
    "        if activate.find_next('div', {\"class\":\"rs rating\"}) ==None:\n",
    "            score, num_reviews = 0, 0\n",
    "        else:\n",
    "            score = activate.find_next('div', {\"class\":\"rs rating\"}).find('span').get('alt').replace(\" of 5 bubbles\",\"\")\n",
    "            num_reviews = activate.find_next('div', {\"class\":\"rs rating\"}).find('span', {'class': \"more\"}).text.strip().replace(\"reviews\",\"\")\n",
    "        ranking = activate.find_next('div', {'class':\"popRanking wrap\"}).text.strip().replace(\"#\",\"\")[0]\n",
    "        if activate.find_next('div',{'class':\"tag_line\"}).find('span') == None:\n",
    "            tags = None\n",
    "        else:\n",
    "            tags = activate.find_next('div',{'class':\"tag_line\"}).find('span').text\n",
    "        list_thing = [national_park_name, activate_name, url, num_reviews, score, ranking, tags]\n",
    "        thing_to_do.loc[len(thing_to_do)] = list_thing\n",
    "    return thing_to_do\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thing_to_do_national_park_df = pd.DataFrame(columns=[\"national_park_name\",\"activate_name\",\"url\",\"num_reviews\",\"score\",\"ranking\",\"tags\"])\n",
    "for url in national_park_US_df.url:\n",
    "    thing_to_do_page = request_s(url)\n",
    "    result =  (thing_to_do(thing_to_do_page))\n",
    "    thing_to_do_national_park_df = thing_to_do_national_park_df.append(result, ignore_index=True)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thing_to_do_national_park_df.to_csv('poi_detail_national_park_todo_df.csv',encoding=('utf-8'))\n",
    "name_list = set(thing_to_do_national_park_df.national_park_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "['index','name','street_address','city','state_abb','state','postal_code','country','address','coord_lat','coord_long','num_reviews','review_score','ranking','tag','raw_visit_length','fee','description','url',\"geo_content\"]\n",
    "# national_park_US_df[\"tags\"] = \"National Park\"\n",
    "# national_park_US_df[\"url\"] = None\n",
    "# national_park_US_df.rename(columns={'desciption': 'description'}, inplace=True)\n",
    "# national_park_US_df[\"index\"] = national_park_US_df.index\n",
    "national_park_US_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "national_park_US_df = national_park_US_df[['index','name','street_address','city','state_abb','state','postal_code','country','address','coord_lat','coord_long','num_reviews','review_score','ranking','tag','raw_visit_length','fee','description','url',\"geo_content\", \"check\"]]\n",
    "small_national_park = national_park_US_df[national_park_US_df.check == 0]\n",
    "national_park_US_df.to_csv(\"poi_detail_national_park.csv\", encoding=('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_national_park.ix[1].url = \"https://www.tripadvisor.com/Attractions-g143045-Activities-National_Park_of_American_Samoa_Tutuila.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "should_be_big = small_national_park.ix[[12, 14, 30, 45]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# small_national_park\n",
    "# 1,49,52\n",
    "small_national_park_df=pd.DataFrame(columns=['index','name','street_address','city','state_abb','state','postal_code','country','address','coord_lat','coord_long','num_reviews','review_score','ranking','tag','raw_visit_length','fee','description','url',\"geo_content\"])\n",
    "error_message_df = pd.DataFrame(columns=['index','name','url','state_abb_error', 'state_error','address_error','geo_error','review_error','score_error','ranking_error','tag_error']) \n",
    "search_visit_length = re.compile('Recommended length of visit:')\n",
    "search_fee = re.compile('Fee:')\n",
    "cnt = 0\n",
    "name_lst = []\n",
    "full_address_lst = []\n",
    "api_i = 0\n",
    "for url in small_nation_park.url:\n",
    "    s = request_s(url)\n",
    "    input_list, error_message = [],[]\n",
    "    state_abb_error, state_error, address_error, geo_error, review_error, score_error, ranking_error, tag_error = 0,0,0,0,0,0,0,0\n",
    "    latitude, longitude, geo_content = None, None, None\n",
    "\n",
    "    name = s.find('h1', attrs = {'class':'heading_name'}).text.strip()\n",
    "\n",
    "    #street_address\n",
    "    street_address = s.find('span', attrs = {'class':'street-address'}).text.strip()\n",
    "    #city\n",
    "    city = s.find('span', attrs = {'property':'addressLocality'}).text.strip()\n",
    "    #state\n",
    "    state_abb = s.find('span', attrs = {'property':'addressRegion'}).text.strip()\n",
    "    if state_abb:\n",
    "        try:\n",
    "            # state = state_abb_dict.keys()[state_abb_dict.values().index(state_abb)]\n",
    "            state = abb2state_dict[state_abb]\n",
    "        except:\n",
    "            state_abb_error = 1\n",
    "            state = state_abb\n",
    "    else:\n",
    "        state_error =1\n",
    "        state_abb = None\n",
    "        state = None\n",
    "    #postal_code\n",
    "    postal_code = s.find('span', attrs = {'property':'postalCode'}).text.strip()\n",
    "    #country\n",
    "    if s.find('span', attrs = {'property':'addressCountry'}).get('content'):\n",
    "        country = s.find('span',{'property':'addressCountry'}).get('content')\n",
    "    elif s.find('span',{'property':'addressCountry'}).get('content') == None:\n",
    "        country = s.find('span',{'property':'addressCountry'}).text.strip()\n",
    "    else:\n",
    "        country = 'United States'\n",
    "    #address\n",
    "    if state:\n",
    "        full_address = street_address+', '+city+', '+state+', '+postal_code[:5]+', '+country\n",
    "    else:\n",
    "        address_error =1\n",
    "        full_address = street_address+', '+city+', '+postal_code[:5]+', '+country\n",
    "    if (name in name_lst) and (full_address in full_address_lst):\n",
    "        continue\n",
    "    else:\n",
    "        name_lst.append(name)\n",
    "        full_address_lst.append(full_address)\n",
    "    try:\n",
    "#         latitude, longitude, geo_content = find_latlng(full_address, name, 1)\n",
    "        result_longlat = find_latlng(full_address, name, 1)\n",
    "        while result_longlat == False:\n",
    "            api_i+=1\n",
    "            result_longlat = find_latlng(full_address, name, 1)\n",
    "    except:\n",
    "        geo_error =1\n",
    "        latitude, longitude, geo_content = None, None, None\n",
    "\n",
    "    [latitude, longitude, geo_content] = result_longlat\n",
    "    #num_reviews\n",
    "    try:\n",
    "        num_reviews = s.find('div', attrs = {'class': 'rs rating'}).find('a').get('content')\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            num_reviews = s.find('a', {'property': \"reviewCount\"}).get('content')\n",
    "        except:\n",
    "            num_reviews = 0\n",
    "            review_error=1    \n",
    "    #review_score\n",
    "    try:\n",
    "        review_score = s.find('div', attrs = {'class': 'heading_rating separator'}).find('img').get('content')\n",
    "    except:\n",
    "        try:\n",
    "            review_score = s.find('span', {'property': \"ratingValue\"}).get('content')\n",
    "        except:\n",
    "            review_score = 0 \n",
    "            score_error =1\n",
    "    #ranking\n",
    "    try:\n",
    "        ranking = s.find('b', attrs = {'class':'rank_text wrap'}).text.strip().replace('#',\"\")\n",
    "    except:\n",
    "        ranking = 999\n",
    "        ranking_error=1\n",
    "    #tag\n",
    "    try:\n",
    "        tags = \", \".join(label.text.strip() for label in s.select('div.detail > a') + s.select('span.collapse.hidden > a'))\n",
    "    except:\n",
    "        tags = None\n",
    "        tag_error =1\n",
    "    #visit_length\n",
    "    if s.find('b', text =search_visit_length):\n",
    "        raw_visit_length = s.find('b', text =search_visit_length).next_sibling.strip()\n",
    "    else:\n",
    "        raw_visit_length = None\n",
    "    #fee\n",
    "    if s.find('b', text= search_fee):\n",
    "        fee = s.find('b',text= search_fee).next_sibling.strip()\n",
    "    else:\n",
    "        fee = 'Unknown'\n",
    "    #description\n",
    "    if s.find('div', attrs = {'class': \"listing_details\"}):\n",
    "        description = s.find('div', attrs = {'class': \"listing_details\"}).text.strip()\n",
    "    else:\n",
    "        description = None\n",
    "    error_message = [len(small_national_park_df), name, url,state_abb_error, state_error, address_error, geo_error, review_error, score_error, ranking_error, tag_error]\n",
    "    error_message_df.loc[len(small_national_park_df)] =error_message\n",
    "\n",
    "\n",
    "    input_list = [len(small_national_park_df), name, street_address, city, state_abb, state, postal_code, country, full_address, latitude, longitude, num_reviews, review_score, ranking, tags, raw_visit_length, fee, description, url, geo_content]\n",
    "    small_national_park_df.loc[len(small_national_park_df)] = input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for u in small_national_park_df.url:\n",
    "    print u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_national_park_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "national_park_US_df =national_park_US_df.drop(\"check\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "national_park_US_df.to_csv(\"poi_detail_national_park.csv\", encoding=('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# national_park_US_df[\"url\"][national_park_US_df.index == 52] = \"https://www.tripadvisor.com/Attractions-g147411-Activities-Virgin_Islands_National_Park_St_John_U_S_Virgin_Islands.html\"\n",
    "name_list=[]\n",
    "for name in national_park_US_df[\"name\"]:\n",
    "    name_list.append(name.split(\",\",1)[0])\n",
    "national_park_US_df[\"name\"]=name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "national_park_US_df[national_park_US_df.check ==0]\n",
    "#small 12 14 30 45\n",
    "small_nation_park = national_park_US_df.ix[[12 ,14, 30, 45]]\n",
    "national_park_US_df = national_park_US_df.drop(national_park_US_df.index[[12,14,30,45]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for address in national_park_US_df.address:\n",
    "    for address2 in trip_search_result.address:\n",
    "        if address == address2:\n",
    "            national_park_US_df.name[national_park_US_df.address == address] = trip_search_result.name[trip_search_result.address ==address2].values[0]\n",
    "#             national_park_US_df.url[national_park_US_df.address == address] = trip_search_result.url[trip_search_result.address ==address2].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip_search_result.name[trip_search_result.address ==\"Arches National Park, Utah, USA\"].values[0]\n",
    "# trip_search_result[(trip_search_result.address ==\"Arches National Park, Utah, USA\")].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# address, lat, lng = [],[],[]\n",
    "\n",
    "# park name:  Acadia National Park\n",
    "# park name:  National Park of American Samoa\n",
    "list1,list2 =[],[]\n",
    "# street_address, city, state_abb, postal_code, country,geo_content = [],[],[],[],[],[]\n",
    "\n",
    "g = geocoder.google(\"National Park of American Samoa\")\n",
    "name = \"National Park of American Samoa\"\n",
    "city = g.city\n",
    "street_address = g.street_long\n",
    "state_abb = g.state\n",
    "state = g.state_long\n",
    "postal_code=g.postal\n",
    "country=g.country_long\n",
    "geo_content=g.content\n",
    "full_address = g.address\n",
    "latitude =g.lat\n",
    "longitude = g.lng\n",
    "num_reviews, review_score, ranking = None, None ,None\n",
    "tags = \"National Park\"\n",
    "raw_visit_length, fee = None, None \n",
    "# url = \"https://www.tripadvisor.com/Attractions-g143010-Activities-Acadia_National_Park_Mount_Desert_Island_Maine.html\"\n",
    "url =\"https://www.tripadvisor.com/Attractions-g143045-Activities-National_Park_of_American_Samoa_Tutuila.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "national_park_US_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list2 = [1, name, street_address, city, state_abb, state, postal_code, country, full_address, latitude, longitude, num_reviews, review_score, ranking, tags, raw_visit_length, fee, description, url, geo_content, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# national_park_US_df[\"address\"] = address\n",
    "# national_park_US_df[\"lat\"] = lat\n",
    "# national_park_US_df[\"lng\"] = lng\n",
    "national_park_US_df[\"city\"] = city\n",
    "national_park_US_df[\"street_address\"] = street_address\n",
    "national_park_US_df[\"state_abb\"] = state_abb\n",
    "national_park_US_df[\"postal_code\"] = postal_code\n",
    "national_park_US_df[\"country\"] = country\n",
    "national_park_US_df[\"geo_content\"] = geo_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# national_park_US_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "address_match = []\n",
    "for address in national_park_US_df.address:\n",
    "    for address2 in trip_search_result.address:\n",
    "        if address == address2:\n",
    "            address_match.append(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "check_list = []\n",
    "for add in trip_search_result.address:\n",
    "    if add in address_match:\n",
    "        check_list.append(1)\n",
    "    else:\n",
    "        check_list.append(0)\n",
    "trip_search_result['check'] = check_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# national_park_US_df[national_park_US_df.check ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trip_search_result[trip_search_result.check == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trip_search_result.name\n",
    "# for link in trip_search_result.ix[[52,54,58,53,45,57,56]].url:\n",
    "#     print link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pop_list = [52,54,58,53,45,57,56]\n",
    "# trip_search_result = trip_search_result.drop(pop_list).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "national_park_US_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_poi_df= pd.read_csv(\"new_poi_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_poi_df.poi_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "national_park_US_df.to_csv(\"poi_detail_national_park.csv\", encoding = ('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_park_us_df = pd.read_csv(\"poi_detail_state_park.csv\", encoding = ('utf-8'), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# state_park_us_df.rename(columns={\"visit_length\": \"raw_visit_length\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2647\n"
     ]
    }
   ],
   "source": [
    "import web_scraping_tripadvisor as web\n",
    "client = MongoClient()\n",
    "db = client.zoeshrm\n",
    "db_html = db.TripAdvisor_state_park.find()\n",
    "print db_html.count()\n",
    "state_park_df2, error_state_park_df2 = web.state_park_web(db_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3332841"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_park_df2\n",
    "len(missing_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_name = []\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def raw_to_adjust_time(raw):\n",
    "    adjusted_time =0\n",
    "    if raw == \"1-2 hours\":\n",
    "        adjusted_time = 120\n",
    "    if raw == \"2-3 hours\":\n",
    "        adjusted_time = 180\n",
    "    if raw == \"More than 3 hours\":\n",
    "        adjusted_time = 360\n",
    "    if raw == \"<1 hour\":\n",
    "        adjusted_time = 60\n",
    "    return adjusted_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn_str = \"dbname='travel_with_friends' user='Gon' host='localhost'\"\n",
    "\n",
    "event_ids = [353,   355,   354,   360,  972,   361,   356,   357,  352,   359]\n",
    "conn = psycopg2.connect(conn_str)  \n",
    "cur = conn.cursor()\n",
    "\n",
    "# points = np.zeros((len(event_ids), 5))\n",
    "points = []\n",
    "for i,v in enumerate(event_ids):\n",
    "#     print i, v\n",
    "    cur.execute(\"select index, coord0, coord1, city , poi_rank from poi_detail_table   where index = %i;\"%(float(v)))\n",
    "    a = cur.fetchone()\n",
    "    points.append(list(a))    \n",
    "#     points[i] = cur.fetchone()\n",
    "conn.close()\n",
    "# points = np.array(points)\n",
    "# print points\n",
    "\n",
    "def check_NO_1(poi_list, city_name):\n",
    "    for i, poi in enumerate(poi_list):\n",
    "        if poi[3] == city_name and poi[4]==1:\n",
    "            number_one =poi_list.pop(i)\n",
    "            return np.vstack((np.array(number_one),np.array(poi_list)))\n",
    "    return poi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_points= check_NO_1(points, \"Detroit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['357' '-83.0491303816' '42.338920039' 'Detroit' '1']\n",
      " ['353' '-97.3573230444' '32.7235211292' 'Fort Worth' '18']\n",
      " ['355' '-97.3578115714' '32.7236274787' 'Fort Worth' '20']\n",
      " ['354' '-97.3663509267' '32.7358877338' 'Fort Worth' '19']\n",
      " ['360' '-83.2339359044' '42.303578362' 'Detroit' '4']\n",
      " ['972' '-90.0714194193' '29.9593253027' 'New Orleans' '9']\n",
      " ['361' '-83.044611217' '42.3292693302' 'Detroit' '5']\n",
      " ['356' '-97.363145917' '32.749042767' 'Fort Worth' '21']\n",
      " ['352' '-97.0827539875' '32.7514239792' 'Fort Worth' '17']\n",
      " ['359' '-83.052293024' '42.3385093537' 'Detroit' '3']]\n"
     ]
    }
   ],
   "source": [
    "print new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
