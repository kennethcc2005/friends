{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import psycopg2\n",
    "import json\n",
    "import simplejson\n",
    "import urllib\n",
    "import config\n",
    "from sklearn.cluster import KMeans\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Users/Gon/anaconda3/envs/python2/lib/python2.7/site-packages\n",
      "Requirement already satisfied: sqlalchemy in /Users/Gon/anaconda3/envs/python2/lib/python2.7/site-packages\n",
      "Requirement already satisfied: psycopg2 in /Users/Gon/anaconda3/envs/python2/lib/python2.7/site-packages\n",
      "Requirement already satisfied: simplejson in /Users/Gon/anaconda3/envs/python2/lib/python2.7/site-packages\n",
      "Collecting config\n",
      "  Downloading config-0.3.9.tar.gz\n",
      "Building wheels for collected packages: config\n",
      "  Running setup.py bdist_wheel for config ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/Gon/Library/Caches/pip/wheels/53/3d/4b/b65b93aeeb83b93dcc103f8addd3b4b7e5668496868c103b5a\n",
      "Successfully built config\n",
      "Installing collected packages: config\n",
      "Successfully installed config-0.3.9\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install sqlalchemy\n",
    "!pip install psycopg2\n",
    "!pip install simplejson\n",
    "!pip install config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_name = \"travel_with_friends\"\n",
    "TABLES ={}\n",
    "TABLES['full_trip_table'] = (\n",
    "    \"CREATE TABLE `full_trip_table` (\"\n",
    "    \"  `user_id` int(11) NOT NULL AUTO_INCREMENT,\"\n",
    "    \"  `full_trip_id` date NOT NULL,\"\n",
    "    \"  `trip_location_ids` varchar(14) NOT NULL,\"\n",
    "    \"  `default` varchar(16) NOT NULL,\"\n",
    "    \"  `county` enum('M','F') NOT NULL,\"\n",
    "    \"  `state` date NOT NULL,\"\n",
    "    \"  `details` ,\"\n",
    "    \"  `n_days`,\"\n",
    "    \"  PRIMARY KEY (`full_trip_id`)\"\n",
    "    \") ENGINE=InnoDB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tables():\n",
    "    \"\"\" create tables in the PostgreSQL database\"\"\"\n",
    "    commands = (\n",
    "        \"\"\"\n",
    "        CREATE TABLE full_trip_table (\n",
    "            index \n",
    "            user_id VARCHAR(225) NOT NULL\n",
    "            full_trip_id VARCHAR(225) NOT NULL\n",
    "            trip_location_ids VARCHAR(225)\n",
    "            default BOOLEAN NOT NULL\n",
    "            county VARCHAR(225)\n",
    "            state VARCHAR(225)\n",
    "            details VARCHAR(MAX)\n",
    "            n_days VARCHAR(225)\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"\"\" CREATE TABLE day_trip_table (\n",
    "                part_id SERIAL PRIMARY KEY,\n",
    "                part_name VARCHAR(255) NOT NULL\n",
    "                )\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE poi_details (\n",
    "                part_id INTEGER PRIMARY KEY,\n",
    "                file_extension VARCHAR(5) NOT NULL,\n",
    "                drawing_data BYTEA NOT NULL,\n",
    "                FOREIGN KEY (part_id)\n",
    "                REFERENCES parts (part_id)\n",
    "                ON UPDATE CASCADE ON DELETE CASCADE\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE vendor_parts (\n",
    "                vendor_id INTEGER NOT NULL,\n",
    "                part_id INTEGER NOT NULL,\n",
    "                PRIMARY KEY (vendor_id , part_id),\n",
    "                FOREIGN KEY (vendor_id)\n",
    "                    REFERENCES vendors (vendor_id)\n",
    "                    ON UPDATE CASCADE ON DELETE CASCADE,\n",
    "                FOREIGN KEY (part_id)\n",
    "                    REFERENCES parts (part_id)\n",
    "                    ON UPDATE CASCADE ON DELETE CASCADE\n",
    "        )\n",
    "        \"\"\")\n",
    "    conn = None\n",
    "    try:\n",
    "        # read the connection parameters\n",
    "        params = config()\n",
    "        # connect to the PostgreSQL server\n",
    "        conn = psycopg2.connect(**params)\n",
    "        cur = conn.cursor()\n",
    "        # create table one by one\n",
    "        for command in commands:\n",
    "            cur.execute(command)\n",
    "        # close communication with the PostgreSQL database server\n",
    "        cur.close()\n",
    "        # commit the changes\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read poi details csv file \n",
    "df = pd.read_csv(\"./step9_poi.csv\", index_col=0)\n",
    "#read US city state and county csv file\n",
    "df_counties = pd.read_csv('./us_cities_states_counties.csv',sep='|')\n",
    "#find counties without duplicate\n",
    "df_counties_u = df_counties.drop('City alias',axis = 1).drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['google_time_spent_txt', 'type', 'name', 'city', 'state', 'coord0',\n",
       "       'coord1', 'poi_rank', 'img_url', 'rating', 'reviews', 'city_rank',\n",
       "       'fee', 'visit_length', 'tag', 'google_normal_min',\n",
       "       'google_fast_min', 'tripadvisor_fast_min', 'tripadvisor_normal_min',\n",
       "       'adjusted_normal_time_spent', 'adjusted_fast_time_spent', 'county',\n",
       "       'theme_park', 'museum', 'stadium'], dtype=object)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cold_start_places(df, county, state, city, number_days, first_day_full = True, last_day_full = True):\n",
    "    \n",
    "    if len(county.values) != 0:\n",
    "        county = county.values[0]\n",
    "        temp_df = df[(df['county'] == county) & (df['state'] == state)]\n",
    "    else:\n",
    "        temp_df = df[(df['city'] == city) & (df['state'] == state)]\n",
    "\n",
    "    return county, temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = 'San Diego, California'\n",
    "\n",
    "def county_state(df_counites_u, location):\n",
    "    [city,state] = location.split(', ')\n",
    "    county = df_counties_u['County'][(df_counties_u['City'] == city) & (df_counties_u['State full'] == state)]\n",
    "    \n",
    "    return county, state, city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_days = 1\n",
    "county, state, city = county_state(df_counties_u, location)\n",
    "#df_events contains all the events include (big, median, small)\n",
    "c, df_events =cold_start_places(df, county, state, city, number_days)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_cold_start_places(df,df_counties_u, day_trip_locations,full_trip_table,df_poi_travel_info,number_days = [1,2,3,4,5]):\n",
    "    \n",
    "    df_c = df_counties_u.groupby(['State full','County']).count().reset_index()\n",
    "    for state, county,_,_ in df_c.values[105:150]:\n",
    "        temp_df = df[(df['county'] == county) & (df['state'] == state)]\n",
    "        if temp_df.shape[0]!=0:\n",
    "            if sum(temp_df.adjusted_normal_time_spent) < 360:\n",
    "                number_days = [1]\n",
    "            elif sum(temp_df.adjusted_normal_time_spent) < 720:\n",
    "                number_days = [1,2]\n",
    "            big_events = temp_df[temp_df.adjusted_normal_time_spent > 180]\n",
    "            med_events = temp_df[(temp_df.adjusted_normal_time_spent>= 120)&(temp_df.adjusted_normal_time_spent<=180)]\n",
    "            small_events = temp_df[temp_df.adjusted_normal_time_spent < 120]\n",
    "            for i in number_days:\n",
    "                n_days = i\n",
    "                full_trip_table, day_trip_locations, new_trip_df1, df_poi_travel_info = \\\n",
    "                        default_search_cluster_events(df, df_counties_u, county, state, big_events,med_events, \\\n",
    "                                                      small_events, temp_df, n_days,day_trip_locations, full_trip_table,\\\n",
    "                                                      df_poi_travel_info)\n",
    "                print county, state\n",
    "                print full_trip_table.shape, len(day_trip_locations), new_trip_df1.shape, df_poi_travel_info.shape\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_trip_table = pd.DataFrame(columns =['user_id', 'full_trip_id', 'trip_location_ids', 'default', 'county', 'state', 'details', 'n_days'])\n",
    "\n",
    "day_trip_locations_table = pd.DataFrame(columns =['trip_locations_id','full_day', 'default', 'county', 'state','details'])\n",
    "\n",
    "google_travel_time_table = pd.DataFrame(columns =['id_','orig_name','orig_idx','dest_name','dest_idx','orig_coord0','orig_coord1',\\\n",
    "                                       'dest_coord0','dest_coord1','orig_coords','dest_coords','google_driving_url',\\\n",
    "                                       'google_walking_url','driving_result','walking_result','google_driving_time',\\\n",
    "                                       'google_walking_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://Gon@localhost:5432/travel_with_friends')\n",
    "# full_trip_table = pd.read_csv('./full_trip_table.csv', index_col= 0)\n",
    "# full_trip_table.to_sql('full_trip_table', engine,if_exists='append')\n",
    "\n",
    "full_trip_table.to_sql('full_trip_table',engine, if_exists = \"append\")\n",
    "day_trip_locations_table.to_sql('day_trip_table',engine, if_exists = \"append\")\n",
    "google_travel_time_table.to_sql('google_travel_time_table',engine, if_exists = \"append\")\n",
    "df.to_sql('poi_detail_table',engine, if_exists = \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_full_trip_id(new_trip_id, debug):\n",
    "    conn = psycopg2.connect(\"dbname='travel_with_friends' user='Gon' host='localhost'\")  \n",
    "    cur = conn.cursor()  \n",
    "    cur.execute(\"select details from full_trip_table where full_trip_id = '%s'\" %(new_trip_id)) \n",
    "    a = cur.fetchall()\n",
    "    if bool(a):\n",
    "        if not debug: \n",
    "            return a[0][0]\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_travel_time_id(new_id):\n",
    "    conn = psycopg2.connect(\"dbname='travel_with_friends' user='Gon' host='localhost'\")\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"select google_driving_time from google_travel_time_table where id_ = '%s'\" %(new_id))\n",
    "    a = cur.fetchall()\n",
    "    if bool(a):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "def distL2((x1,y1), (x2,y2)):\n",
    "    \"\"\"Compute the L2-norm (Euclidean) distance between two points.\n",
    "\n",
    "    The distance is rounded to the closest integer, for compatibility\n",
    "    with the TSPLIB convention.\n",
    "\n",
    "    The two points are located on coordinates (x1,y1) and (x2,y2),\n",
    "    sent as parameters\"\"\"\n",
    "    xdiff = x2 - x1\n",
    "    ydiff = y2 - y1\n",
    "    return math.sqrt(xdiff*xdiff + ydiff*ydiff) + .5\n",
    "\n",
    "\n",
    "def distL1((x1,y1), (x2,y2)):\n",
    "    \"\"\"Compute the L1-norm (Manhattan) distance between two points.\n",
    "\n",
    "    The distance is rounded to the closest integer, for compatibility\n",
    "    with the TSPLIB convention.\n",
    "\n",
    "    The two points are located on coordinates (x1,y1) and (x2,y2),\n",
    "    sent as parameters\"\"\"\n",
    "    return abs(x2-x1) + abs(y2-y1)+.5\n",
    "\n",
    "\n",
    "def mk_matrix(coord, dist):\n",
    "    \"\"\"Compute a distance matrix for a set of points.\n",
    "\n",
    "    Uses function 'dist' to calculate distance between\n",
    "    any two points.  Parameters:\n",
    "    -coord -- list of tuples with coordinates of all points, [(x1,y1),...,(xn,yn)]\n",
    "    -dist -- distance function\n",
    "    \"\"\"\n",
    "    n = len(coord)\n",
    "    D = {}      # dictionary to hold n times n matrix\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1,n):\n",
    "            [x1,y1] = coord[i]\n",
    "            [x2,y2] = coord[j]\n",
    "            D[i,j] = dist((x1,y1), (x2,y2))\n",
    "            D[j,i] = D[i,j]\n",
    "    return n,D\n",
    "\n",
    "def read_tsplib(filename):\n",
    "    \"basic function for reading a TSP problem on the TSPLIB format\"\n",
    "    \"NOTE: only works for 2D euclidean or manhattan distances\"\n",
    "    f = open(filename, 'r');\n",
    "\n",
    "    line = f.readline()\n",
    "    while line.find(\"EDGE_WEIGHT_TYPE\") == -1:\n",
    "        line = f.readline()\n",
    "\n",
    "    if line.find(\"EUC_2D\") != -1:\n",
    "        dist = distL2\n",
    "    elif line.find(\"MAN_2D\") != -1:\n",
    "        dist = distL1\n",
    "    else:\n",
    "        print \"cannot deal with non-euclidean or non-manhattan distances\"\n",
    "        raise Exception\n",
    "\n",
    "    while line.find(\"NODE_COORD_SECTION\") == -1:\n",
    "        line = f.readline()\n",
    "\n",
    "    xy_positions = []\n",
    "    while 1:\n",
    "        line = f.readline()\n",
    "        if line.find(\"EOF\") != -1: break\n",
    "        (i,x,y) = line.split()\n",
    "        x = float(x)\n",
    "        y = float(y)\n",
    "        xy_positions.append((x,y))\n",
    "\n",
    "    n,D = mk_matrix(xy_positions, dist)\n",
    "    return n, xy_positions, D\n",
    "\n",
    "\n",
    "def mk_closest(D, n):\n",
    "    \"\"\"Compute a sorted list of the distances for each of the nodes.\n",
    "\n",
    "    For each node, the entry is in the form [(d1,i1), (d2,i2), ...]\n",
    "    where each tuple is a pair (distance,node).\n",
    "    \"\"\"\n",
    "    C = []\n",
    "    for i in range(n):\n",
    "        dlist = [(D[i,j], j) for j in range(n) if j != i]\n",
    "        dlist.sort()\n",
    "        C.append(dlist)\n",
    "    return C\n",
    "\n",
    "\n",
    "def length(tour, D):\n",
    "    \"\"\"Calculate the length of a tour according to distance matrix 'D'.\"\"\"\n",
    "    z = D[tour[-1], tour[0]]    # edge from last to first city of the tour\n",
    "    for i in range(1,len(tour)):\n",
    "        z += D[tour[i], tour[i-1]]      # add length of edge from city i-1 to i\n",
    "    return z\n",
    "\n",
    "\n",
    "def randtour(n):\n",
    "    \"\"\"Construct a random tour of size 'n'.\"\"\"\n",
    "    sol = range(n)      # set solution equal to [0,1,...,n-1]\n",
    "    random.shuffle(sol) # place it in a random order\n",
    "    return sol\n",
    "\n",
    "\n",
    "def nearest(last, unvisited, D):\n",
    "    \"\"\"Return the index of the node which is closest to 'last'.\"\"\"\n",
    "    near = unvisited[0]\n",
    "    min_dist = D[last, near]\n",
    "    for i in unvisited[1:]:\n",
    "        if D[last,i] < min_dist:\n",
    "            near = i\n",
    "            min_dist = D[last, near]\n",
    "    return near\n",
    "\n",
    "\n",
    "def nearest_neighbor(n, i, D):\n",
    "    \"\"\"Return tour starting from city 'i', using the Nearest Neighbor.\n",
    "\n",
    "    Uses the Nearest Neighbor heuristic to construct a solution:\n",
    "    - start visiting city i\n",
    "    - while there are unvisited cities, follow to the closest one\n",
    "    - return to city i\n",
    "    \"\"\"\n",
    "    unvisited = range(n)\n",
    "    unvisited.remove(i)\n",
    "    last = i\n",
    "    tour = [i]\n",
    "    while unvisited != []:\n",
    "        next = nearest(last, unvisited, D)\n",
    "        tour.append(next)\n",
    "        unvisited.remove(next)\n",
    "        last = next\n",
    "    return tour\n",
    "\n",
    "\n",
    "\n",
    "def exchange_cost(tour, i, j, D):\n",
    "    \"\"\"Calculate the cost of exchanging two arcs in a tour.\n",
    "\n",
    "    Determine the variation in the tour length if\n",
    "    arcs (i,i+1) and (j,j+1) are removed,\n",
    "    and replaced by (i,j) and (i+1,j+1)\n",
    "    (note the exception for the last arc).\n",
    "\n",
    "    Parameters:\n",
    "    -t -- a tour\n",
    "    -i -- position of the first arc\n",
    "    -j>i -- position of the second arc\n",
    "    \"\"\"\n",
    "    n = len(tour)\n",
    "    a,b = tour[i],tour[(i+1)%n]\n",
    "    c,d = tour[j],tour[(j+1)%n]\n",
    "    return (D[a,c] + D[b,d]) - (D[a,b] + D[c,d])\n",
    "\n",
    "\n",
    "def exchange(tour, tinv, i, j):\n",
    "    \"\"\"Exchange arcs (i,i+1) and (j,j+1) with (i,j) and (i+1,j+1).\n",
    "\n",
    "    For the given tour 't', remove the arcs (i,i+1) and (j,j+1) and\n",
    "    insert (i,j) and (i+1,j+1).\n",
    "\n",
    "    This is done by inverting the sublist of cities between i and j.\n",
    "    \"\"\"\n",
    "    n = len(tour)\n",
    "    if i>j:\n",
    "        i,j = j,i\n",
    "    assert i>=0 and i<j-1 and j<n\n",
    "    path = tour[i+1:j+1]\n",
    "    path.reverse()\n",
    "    tour[i+1:j+1] = path\n",
    "    for k in range(i+1,j+1):\n",
    "        tinv[tour[k]] = k\n",
    "\n",
    "\n",
    "def improve(tour, z, D, C):\n",
    "    \"\"\"Try to improve tour 't' by exchanging arcs; return improved tour length.\n",
    "\n",
    "    If possible, make a series of local improvements on the solution 'tour',\n",
    "    using a breadth first strategy, until reaching a local optimum.\n",
    "    \"\"\"\n",
    "    n = len(tour)\n",
    "    tinv = [0 for i in tour]\n",
    "    for k in range(n):\n",
    "        tinv[tour[k]] = k  # position of each city in 't'\n",
    "    for i in range(n):\n",
    "        a,b = tour[i],tour[(i+1)%n]\n",
    "        dist_ab = D[a,b]\n",
    "        improved = False\n",
    "        for dist_ac,c in C[a]:\n",
    "            if dist_ac >= dist_ab:\n",
    "                break\n",
    "            j = tinv[c]\n",
    "            d = tour[(j+1)%n]\n",
    "            dist_cd = D[c,d]\n",
    "            dist_bd = D[b,d]\n",
    "            delta = (dist_ac + dist_bd) - (dist_ab + dist_cd)\n",
    "            if delta < 0:       # exchange decreases length\n",
    "                exchange(tour, tinv, i, j);\n",
    "                z += delta\n",
    "                improved = True\n",
    "                break\n",
    "        if improved:\n",
    "            continue\n",
    "        for dist_bd,d in C[b]:\n",
    "            if dist_bd >= dist_ab:\n",
    "                break\n",
    "            j = tinv[d]-1\n",
    "            if j==-1:\n",
    "                j=n-1\n",
    "            c = tour[j]\n",
    "            dist_cd = D[c,d]\n",
    "            dist_ac = D[a,c]\n",
    "            delta = (dist_ac + dist_bd) - (dist_ab + dist_cd)\n",
    "            if delta < 0:       # exchange decreases length\n",
    "                exchange(tour, tinv, i, j);\n",
    "                z += delta\n",
    "                break\n",
    "    return z\n",
    "\n",
    "\n",
    "def localsearch(tour, z, D, C=None):\n",
    "    \"\"\"Obtain a local optimum starting from solution t; return solution length.\n",
    "\n",
    "    Parameters:\n",
    "      tour -- initial tour\n",
    "      z -- length of the initial tour\n",
    "      D -- distance matrix\n",
    "    \"\"\"\n",
    "    n = len(tour)\n",
    "    if C == None:\n",
    "        C = mk_closest(D, n)     # create a sorted list of distances to each node\n",
    "    while 1:\n",
    "        newz = improve(tour, z, D, C)\n",
    "        if newz < z:\n",
    "            z = newz\n",
    "        else:\n",
    "            break\n",
    "    return z\n",
    "\n",
    "\n",
    "def multistart_localsearch(k, n, D, report=None):\n",
    "    \"\"\"Do k iterations of local search, starting from random solutions.\n",
    "\n",
    "    Parameters:\n",
    "    -k -- number of iterations\n",
    "    -D -- distance matrix\n",
    "    -report -- if not None, call it to print verbose output\n",
    "\n",
    "    Returns best solution and its cost.\n",
    "    \"\"\"\n",
    "    C = mk_closest(D, n) # create a sorted list of distances to each node\n",
    "    bestt=None\n",
    "    bestz=None\n",
    "    for i in range(0,k):\n",
    "        tour = randtour(n)\n",
    "        z = length(tour, D)\n",
    "        z = localsearch(tour, z, D, C)\n",
    "        if z < bestz or bestz == None:\n",
    "            bestz = z\n",
    "            bestt = list(tour)\n",
    "            if report:\n",
    "                report(z, tour)\n",
    "\n",
    "    return bestt, bestz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_trip_df(big_,medium_,small_):\n",
    "    event_type = ''\n",
    "    if big_.shape[0] >= 1:\n",
    "        if (medium_.shape[0] < 2) or (big_.iloc[0].poi_rank <= medium_.iloc[0].poi_rank):\n",
    "            if small_.shape[0] >= 6:\n",
    "                trip_df = small_.iloc[0:6].append(big_.iloc[0])\n",
    "            else:\n",
    "                trip_df = small_.append(big_.iloc[0])\n",
    "            event_type = 'big'\n",
    "        else:\n",
    "            if small_.shape[0] >= 8:\n",
    "                trip_df = small_.iloc[0:8].append(medium_.iloc[0:2])\n",
    "            else:\n",
    "                trip_df = small_.append(medium_.iloc[0:2])\n",
    "            event_type = 'med'\n",
    "    elif medium_.shape[0] >= 2:\n",
    "        if small_.shape[0] >= 8:\n",
    "            trip_df = small_.iloc[0:8].append(medium_.iloc[0:2])\n",
    "        else:\n",
    "            trip_df = small_.append(medium_.iloc[0:2])\n",
    "        event_type = 'med'\n",
    "    else:\n",
    "        if small_.shape[0] >= 10:\n",
    "            trip_df = small_.iloc[0:10].append(medium_).sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "        else:\n",
    "            trip_df = small_.append(medium_).sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "        event_type = 'small'\n",
    "    return trip_df, event_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trip_df_cloest_distance(trip_df, event_type):\n",
    "    points = trip_df[['coord0','coord1']].values.tolist()\n",
    "    n, D = mk_matrix(points, distL2) # create the distance matrix\n",
    "    if len(points) >= 3:\n",
    "        if event_type == 'big':\n",
    "            tour = nearest_neighbor(n, trip_df.shape[0]-1, D)     # create a greedy tour, visiting city 'i' first\n",
    "            z = length(tour, D)\n",
    "            z = localsearch(tour, z, D)\n",
    "        elif event_type == 'med':\n",
    "            tour = nearest_neighbor(n, trip_df.shape[0]-2, D)     # create a greedy tour, visiting city 'i' first\n",
    "            z = length(tour, D)\n",
    "            z = localsearch(tour, z, D)\n",
    "        else:\n",
    "            tour = nearest_neighbor(n, 0, D)     # create a greedy tour, visiting city 'i' first\n",
    "            z = length(tour, D)\n",
    "            z = localsearch(tour, z, D)\n",
    "        return tour\n",
    "    else:\n",
    "        return range(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_key = 'AIzaSyDJh9EWCA_v0_B3SvjzjUA3OSVYufPJeGE'\n",
    "# my_key = 'AIzaSyAwx3xg6oJ0yiPV3MIunBa1kx6N7v5Tcw8'\n",
    "def google_driving_walking_time(tour,trip_df,event_type):\n",
    "#     poi_travel_time_df = pd.DataFrame(columns =['id_','orig_name','orig_idx','dest_name','dest_idx','orig_coord0','orig_coord1',\\\n",
    "#                                    'dest_coord0','dest_coord1','orig_coords','dest_coords','google_driving_url',\\\n",
    "#                                    'google_walking_url','driving_result','walking_result','google_driving_time',\\\n",
    "#                                    'google_walking_time'])\n",
    "#     ids_, orig_names,orid_idxs,dest_names,dest_idxs,orig_coord0s,orig_coord1s,dest_coord0s,dest_coord1s = [],[],[],[],[],[],[],[],[]\n",
    "#     orig_coordss,dest_coordss,driving_urls,walking_urls,driving_results,walking_results,driving_times,walking_times = [],[],[],[],[],[],[],[]\n",
    "    trip_id_list=[]\n",
    "    for i in range(len(tour)-1):\n",
    "        id_ = str(trip_df.loc[trip_df.index[tour[i]]].name) + '0000'+str(trip_df.loc[trip_df.index[tour[i+1]]].name)\n",
    "        \n",
    "        result_check_travel_time_id = check_travel_time_id(id_)\n",
    "        if not result_check_travel_time_id:\n",
    "    \n",
    "            orig_name = trip_df.loc[trip_df.index[tour[i]]]['name']\n",
    "            orig_idx = trip_df.loc[trip_df.index[tour[i]]].name\n",
    "            dest_name = trip_df.loc[trip_df.index[tour[i+1]]]['name']\n",
    "            dest_idx = trip_df.loc[trip_df.index[tour[i+1]]].name\n",
    "            orig_coord0 = trip_df.loc[trip_df.index[tour[i]]]['coord0']\n",
    "            orig_coord1 = trip_df.loc[trip_df.index[tour[i]]]['coord1']\n",
    "            dest_coord0 = trip_df.loc[trip_df.index[tour[i+1]]]['coord0']\n",
    "            dest_coord1 = trip_df.loc[trip_df.index[tour[i+1]]]['coord1']\n",
    "            orig_coords = str(orig_coord1)+','+str(orig_coord0)\n",
    "            dest_coords = str(dest_coord1)+','+str(dest_coord0)\n",
    "            \n",
    "            google_driving_url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins={0}&destinations={1}&mode=driving&language=en-EN&sensor=false&key={2}\".\\\n",
    "                                    format(orig_coords.replace(' ',''),dest_coords.replace(' ',''),my_key)\n",
    "            google_walking_url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins={0}&destinations={1}&mode=walking&language=en-EN&sensor=false&key={2}\".\\\n",
    "                                    format(orig_coords.replace(' ',''),dest_coords.replace(' ',''),my_key)\n",
    "            driving_result= simplejson.load(urllib.urlopen(google_driving_url))\n",
    "            walking_result= simplejson.load(urllib.urlopen(google_walking_url))\n",
    "            \n",
    "            if driving_result['rows'][0]['elements'][0]['status'] == 'ZERO_RESULTS':\n",
    "                google_driving_url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins={0}&destinations={1}&mode=driving&language=en-EN&sensor=false&key={2}\".\\\n",
    "                                    format(orig_name.replace(' ','+').replace('-','+'),dest_name.replace(' ','+').replace('-','+'),my_key)\n",
    "                driving_result= simplejson.load(urllib.urlopen(google_driving_url))\n",
    "                \n",
    "            if walking_result['rows'][0]['elements'][0]['status'] == 'ZERO_RESULTS':\n",
    "                google_walking_url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins={0}&destinations={1}&mode=walking&language=en-EN&sensor=false&key={2}\".\\\n",
    "                                        format(orig_name.replace(' ','+').replace('-','+'),dest_name.replace(' ','+').replace('-','+'),my_key)\n",
    "                walking_result= simplejson.load(urllib.urlopen(google_walking_url))\n",
    "                \n",
    "            if (driving_result['rows'][0]['elements'][0]['status'] == 'NOT_FOUND') and (walking_result['rows'][0]['elements'][0]['status'] == 'NOT_FOUND'):\n",
    "                new_df = trip_df.drop(trip_df.iloc[tour[i+1]].name)\n",
    "                new_tour = trip_df_cloest_distance(new_df,event_type)\n",
    "                return google_driving_walking_time(new_tour,new_df, event_type)\n",
    "            try:\n",
    "                google_driving_time = driving_result['rows'][0]['elements'][0]['duration']['value']/60\n",
    "            except:            \n",
    "                print driving_result\n",
    "\n",
    "            try:\n",
    "                google_walking_time = walking_result['rows'][0]['elements'][0]['duration']['value']/60\n",
    "            except:\n",
    "                google_walking_time = 9999\n",
    "                \n",
    "                \n",
    "#             poi_travel_time_df.loc[len(df_poi_travel_time)]=[id_,orig_name,orig_idx,dest_name,dest_idx,orig_coord0,orig_coord1,dest_coord0,\\\n",
    "#                                    dest_coord1,orig_coords,dest_coords,google_driving_url,google_walking_url,\\\n",
    "#                                    str(driving_result),str(walking_result),google_driving_time,google_walking_time]\n",
    "        \n",
    "    \n",
    "    \n",
    "        else:\n",
    "            trip_id_list.append(id_)\n",
    "    \n",
    "    return tour, trip_df, trip_id_list\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id_, orig_name, orig_idx, dest_name, dest_idx, orig_coord0, orig_coord1, dest_coord0, dest_coord1, orig_coords, dest_coords, google_driving_url, google_walking_url, driving_result, walking_result, google_driving_time, google_walking_time]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "n_days =3\n",
    "poi_coords = df_events[['coord0','coord1']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_days).fit(poi_coords)\n",
    "i=0\n",
    "\n",
    "current_events = []\n",
    "big_ix = []\n",
    "small_ix = []\n",
    "med_ix = []\n",
    "for ix, label in enumerate(kmeans.labels_):\n",
    "    if label == i:\n",
    "        time = df_events.iloc[ix].adjusted_normal_time_spent\n",
    "        event_ix = df_events.iloc[ix].name\n",
    "        current_events.append(event_ix)\n",
    "        if time > 180 :\n",
    "            big_ix.append(event_ix)\n",
    "        elif time >= 120 :\n",
    "            med_ix.append(event_ix)\n",
    "        else:\n",
    "            small_ix.append(event_ix)\n",
    "\n",
    "#         all_big = big.sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "big_ = df_events.loc[big_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "small_ = df_events.loc[small_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "medium_ = df_events.loc[med_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "\n",
    "trip_df, event_type = create_trip_df(big_,medium_,small_)\n",
    "# print trip_df\n",
    "tour = trip_df_cloest_distance(trip_df, event_type)\n",
    "# print tour\n",
    "new_tour, new_trip_df, df_poi_travel_time = google_driving_walking_time(tour,trip_df,event_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_for_trip_default(df, county, state, city, n_days, day_trip_locations = True, full_trip_table = True, default = True, debug = True):\n",
    "    \n",
    "    trip_location_ids = []\n",
    "    full_trip_details = []\n",
    "\n",
    "    for i in range(n_days):\n",
    "        if not day_trip_id():\n",
    "            values = day_trip(new_trip_df1, county, state, default, full_day,n_days,i)\n",
    "            current_events, big_ix, small_ix, med_ix = [],[],[],[]\n",
    "\n",
    "            for ix, label in enumerate(kmeans.labels_):\n",
    "                if label == i:\n",
    "                    time = df_events.iloc[ix].adjusted_normal_time_spent\n",
    "                    event_ix = df_events.iloc[ix].name\n",
    "                    current_events.append(event_ix)\n",
    "                    if time > 180 :\n",
    "                        big_ix.append(event_ix)\n",
    "                    elif time >= 120 :\n",
    "                        med_ix.append(event_ix)\n",
    "                    else:\n",
    "                        small_ix.append(event_ix)\n",
    "\n",
    "            big_ = df_events.loc[big_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "            small_ = df_events.loc[small_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "            medium_ = df_events.loc[med_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "\n",
    "            trip_df, event_type = create_trip_df(big_,medium_,small_)\n",
    "        #         print event_type\n",
    "            tour = trip_df_cloest_distance(trip_df, event_type)\n",
    "        #         print tour\n",
    "            new_tour, new_trip_df, df_poi_travel_time = google_driving_walking_time(tour,trip_df,event_type)\n",
    "                return new_trip_df, df_poi_travel_time\n",
    "#             new_trip_df = new_trip_df.iloc[new_tour]\n",
    "#             new_trip_df1,new_df_poi_travel_time,total_time = remove_extra_events(new_trip_df, df_poi_travel_time)\n",
    "#         #         print new_trip_df1\n",
    "#             new_trip_df1['address'] = df_addresses(new_trip_df1, new_df_poi_travel_time)\n",
    "#         #         print 'total time:', total_ti\n",
    "#             day_trip_locations.loc[len(day_trip_locations)] = values\n",
    "#             trip_location_ids.append(values[0])\n",
    "#             full_trip_details.extend(values[-1])\n",
    "#             df_poi_travel_info = df_poi_travel_info.append(new_df_poi_travel_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Most important event that will call all the functions and return the day details for the trip\n",
    "'''\n",
    "\n",
    "\n",
    "def search_cluster_events(df, county, state, city, n_days, day_trip_locations = True, full_trip_table = True, default = True, debug = True):\n",
    "    \n",
    "    county, df_events =cold_start_places(df, county, state, city, n_days) \n",
    "    \n",
    "    poi_coords = df_events[['coord0','coord1']]\n",
    "    kmeans = KMeans(n_clusters=n_days).fit(poi_coords)\n",
    "\n",
    "    new_trip_id = '-'.join([str(state.upper()), str(county.upper().replace(' ','-')),str(int(default)), str(n_days)])\n",
    "    if not check_full_trip_id(new_trip_id, debug):\n",
    "        \n",
    "        trip_location_ids = []\n",
    "        full_trip_details = []\n",
    "        for i in range(n_days):\n",
    "            current_events = []\n",
    "            big_ix = []\n",
    "            small_ix = []\n",
    "            med_ix = []\n",
    "            for ix, label in enumerate(kmeans.labels_):\n",
    "                if label == i:\n",
    "                    event_ix = poi_coords.index[ix]\n",
    "                    current_events.append(event_ix)\n",
    "                    if event_ix in big.index:\n",
    "                        big_ix.append(event_ix)\n",
    "                    elif event_ix in med.index:\n",
    "                        med_ix.append(event_ix)\n",
    "                    else:\n",
    "                        small_ix.append(event_ix)\n",
    "            all_big = big.sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "            big_ = big.loc[big_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "            small_ = small.loc[small_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "            medium_ = med.loc[med_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "    #         print 'big:', big_, 'small:', small_, 'msize:', medium_\n",
    "            trip_df, event_type = create_trip_df(big_,medium_,small_)\n",
    "    #         print event_type\n",
    "            tour = trip_df_cloest_distance(trip_df, event_type)\n",
    "    #         print tour\n",
    "            new_tour, new_trip_df, df_poi_travel_time = google_driving_walking_time(tour,trip_df,event_type)\n",
    "    #         print new_tour, new_trip_df\n",
    "    #         return new_trip_df, df_poi_travel_time\n",
    "            new_trip_df = new_trip_df.iloc[new_tour]\n",
    "            new_trip_df1,new_df_poi_travel_time,total_time = remove_extra_events(new_trip_df, df_poi_travel_time)\n",
    "    #         print new_trip_df1\n",
    "            new_trip_df1['address'] = df_addresses(new_trip_df1, new_df_poi_travel_time)\n",
    "    #         print 'total time:', total_ti\n",
    "            values = day_trip(new_trip_df1, county, state, default, full_day,n_days,i)\n",
    "            day_trip_locations.loc[len(day_trip_locations)] = values\n",
    "            trip_location_ids.append(values[0])\n",
    "            full_trip_details.extend(values[-1])\n",
    "            df_poi_travel_info = df_poi_travel_info.append(new_df_poi_travel_time)\n",
    "            \n",
    "    full_trip_id = '-'.join([str(state.upper()), str(county.upper().replace(' ','-')),str(int(default)), str(n_days)])\n",
    "    details = extend_full_trip_details(full_trip_details)\n",
    "    full_trip_table.loc[len(full_trip_table)] = [\"adam\", full_trip_id, str(trip_location_ids), default, county, state, details, n_days]\n",
    "    \n",
    "    \n",
    "    return full_trip_table, day_trip_locations, new_trip_df1, df_poi_travel_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_trip_locations = 'San Diego, California'\n",
    "\n",
    "f, d, n, d= search_cluster_events(df, county, state, city, 3, day_trip_locations, full_trip_table, default = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_search_cluster_events(df, df_counties_u, county, state, big,med, small, \\\n",
    "                                  temp, n_days,day_trip_locations, full_trip_table,df_poi_travel_info):\n",
    "#     df_poi_travel_info = pd.DataFrame(columns =['id_','orig_name','orig_idx','dest_name','dest_idx','orig_coord0','orig_coord1',\\\n",
    "#                                        'dest_coord0','dest_coord1','orig_coords','dest_coords','google_driving_url',\\\n",
    "#                                        'google_walking_url','driving_result','walking_result','google_driving_time',\\\n",
    "#                                        'google_walking_time'])\n",
    "    poi_coords = temp[['coord0','coord1']]\n",
    "    kmeans = KMeans(n_clusters=n_days, random_state=0).fit(poi_coords)\n",
    "#     print kmeans.labels_\n",
    "    full_trip_id = '-'.join([str(state.upper()), str(county.upper().replace(' ','-')),str(int(default)), str(n_days)])\n",
    "    trip_location_ids = []\n",
    "    full_trip_details = []\n",
    "    for i in range(n_days):\n",
    "        current_events = []\n",
    "        big_ix = []\n",
    "        small_ix = []\n",
    "        med_ix = []\n",
    "        for ix, label in enumerate(kmeans.labels_):\n",
    "            if label == i:\n",
    "                event_ix = poi_coords.index[ix]\n",
    "                current_events.append(event_ix)\n",
    "                if event_ix in big.index:\n",
    "                    big_ix.append(event_ix)\n",
    "                elif event_ix in med.index:\n",
    "                    med_ix.append(event_ix)\n",
    "                else:\n",
    "                    small_ix.append(event_ix)\n",
    "        all_big = big.sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "        big_ = big.loc[big_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "        small_ = small.loc[small_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "        medium_ = med.loc[med_ix].sort_values(['poi_rank', 'rating'], ascending=[True, False])\n",
    "        trip_df, event_type = create_trip_df(big_,medium_,small_)\n",
    "        tour = trip_df_cloest_distance(trip_df, event_type)\n",
    "        new_tour, new_trip_df, df_poi_travel_time = google_driving_walking_time(tour,trip_df,event_type)\n",
    "        new_trip_df = new_trip_df.iloc[new_tour]\n",
    "        new_trip_df1,new_df_poi_travel_time,total_time = remove_extra_events(new_trip_df, df_poi_travel_time)\n",
    "        new_trip_df1['address'] = df_addresses(new_trip_df1, new_df_poi_travel_time)\n",
    "        values = day_trip(new_trip_df1, county, state, default, full_day,n_days,i)\n",
    "        day_trip_locations.loc[len(day_trip_locations)] = values\n",
    "        trip_location_ids.append(values[0])\n",
    "        full_trip_details.extend(values[-1])\n",
    "#         print 'trave time df \\n',new_df_poi_travel_time\n",
    "        df_poi_travel_info = df_poi_travel_info.append(new_df_poi_travel_time)\n",
    "    full_trip_id = '-'.join([str(state.upper()), str(county.upper().replace(' ','-')),str(int(default)), str(n_days)])\n",
    "    details = extend_full_trip_details(full_trip_details)\n",
    "    full_trip_table.loc[len(full_trip_table)] = [user_id, full_trip_id, \\\n",
    "                                                 str(trip_location_ids), default, county, state, details, n_days]\n",
    "    return full_trip_table, day_trip_locations, new_trip_df1, df_poi_travel_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def day_trip(new_trip_df1, county, state, default, full_day,n_days,i):\n",
    "    if default:\n",
    "        trip_locations_id = '-'.join([str(state.upper()), str(county.upper().replace(' ','-')),str(int(default)), str(n_days),str(i)])\n",
    "    else:\n",
    "        trip_locations_id = '-'.join(map(str, new_trip_df1.index.values))\n",
    "    #details dict includes: id, name,address, day\n",
    "    details = [str({'id': new_trip_df1.index[x],'name': new_trip_df1.name.values[x],'address':new_trip_df1.address.values[x], 'day': i}) \\\n",
    "                for x in range(new_trip_df1.shape[0])]\n",
    "    return [trip_locations_id, full_day, default, county, state, details]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
