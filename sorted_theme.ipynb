{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi = pd.read_csv(\"poi_detail_table_final_v1.csv\", encoding = ('utf-8'), index_col =0)\n",
    "# poi.to_csv(\"poi_detail_table_final_v1.csv\", encoding = ('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([u'address', u'adjusted_visit_length', u'city', u'coord_lat',\n",
       "        u'coord_long', u'country', u'county', u'description', u'fee',\n",
       "        u'geo_content', u'name', u'num_reviews', u'poi_type', u'postal_code',\n",
       "        u'ranking', u'raw_visit_length', u'review_score', u'state',\n",
       "        u'state_abb', u'street_address', u'tag', u'url', u'icon_url',\n",
       "        u'check_full_address', u'img_url'],\n",
       "       dtype='object'), (16654, 25))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi.columns, poi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in poi.img_url[0:2]:\n",
    "#     print i\n",
    "poi[\"img_url\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already finish 0 images\n",
      "already finish 100 images\n",
      "already finish 200 images\n",
      "already finish 300 images\n",
      "already finish 400 images\n",
      "already finish 500 images\n",
      "already finish 600 images\n",
      "already finish 700 images\n",
      "already finish 800 images\n",
      "already finish 900 images\n",
      "already finish 1000 images\n",
      "already finish 1100 images\n",
      "already finish 1200 images\n",
      "already finish 1300 images\n",
      "already finish 1400 images\n",
      "already finish 1500 images\n",
      "already finish 1600 images\n",
      "already finish 1700 images\n",
      "already finish 1800 images\n",
      "already finish 1900 images\n",
      "already finish 2000 images\n",
      "already finish 2100 images\n",
      "already finish 2200 images\n",
      "already finish 2300 images\n",
      "already finish 2400 images\n",
      "already finish 2500 images\n",
      "already finish 2600 images\n",
      "already finish 2700 images\n",
      "already finish 2800 images\n",
      "already finish 2900 images\n",
      "already finish 3000 images\n",
      "already finish 3100 images\n",
      "already finish 3200 images\n",
      "already finish 3300 images\n",
      "already finish 3400 images\n",
      "already finish 3500 images\n",
      "already finish 3600 images\n",
      "already finish 3700 images\n",
      "already finish 3800 images\n",
      "already finish 3900 images\n",
      "already finish 4000 images\n",
      "already finish 4100 images\n",
      "already finish 4200 images\n",
      "already finish 4300 images\n",
      "already finish 4400 images\n",
      "already finish 4500 images\n",
      "already finish 4600 images\n",
      "already finish 4700 images\n",
      "already finish 4800 images\n",
      "already finish 4900 images\n",
      "already finish 5000 images\n",
      "already finish 5100 images\n",
      "already finish 5200 images\n",
      "already finish 5300 images\n",
      "already finish 5400 images\n",
      "already finish 5500 images\n",
      "already finish 5600 images\n",
      "already finish 5700 images\n",
      "already finish 5800 images\n",
      "already finish 5900 images\n",
      "already finish 6000 images\n",
      "already finish 6100 images\n",
      "already finish 6200 images\n",
      "already finish 6300 images\n",
      "already finish 6400 images\n",
      "already finish 6500 images\n",
      "already finish 6600 images\n",
      "already finish 6700 images\n",
      "already finish 6800 images\n",
      "already finish 6900 images\n",
      "already finish 7000 images\n",
      "already finish 7100 images\n",
      "already finish 7200 images\n",
      "already finish 7300 images\n",
      "already finish 7400 images\n",
      "already finish 7500 images\n",
      "already finish 7600 images\n",
      "already finish 7700 images\n",
      "already finish 7800 images\n",
      "already finish 7900 images\n",
      "already finish 8000 images\n",
      "already finish 8100 images\n",
      "already finish 8200 images\n",
      "already finish 8300 images\n",
      "already finish 8400 images\n",
      "already finish 8500 images\n",
      "already finish 8600 images\n",
      "already finish 8700 images\n",
      "already finish 8800 images\n",
      "already finish 8900 images\n",
      "already finish 9000 images\n",
      "already finish 9100 images\n",
      "already finish 9200 images\n",
      "already finish 9300 images\n",
      "already finish 9400 images\n",
      "already finish 9500 images\n",
      "already finish 9600 images\n",
      "already finish 9700 images\n",
      "already finish 9800 images\n",
      "already finish 9900 images\n",
      "already finish 10000 images\n",
      "already finish 10100 images\n",
      "already finish 10200 images\n",
      "already finish 10300 images\n",
      "already finish 10400 images\n",
      "already finish 10500 images\n",
      "already finish 10600 images\n",
      "already finish 10700 images\n",
      "already finish 10800 images\n",
      "already finish 10900 images\n",
      "already finish 11000 images\n",
      "already finish 11100 images\n",
      "already finish 11200 images\n",
      "already finish 11300 images\n",
      "already finish 11400 images\n",
      "already finish 11500 images\n",
      "already finish 11600 images\n",
      "already finish 11700 images\n",
      "already finish 11800 images\n",
      "already finish 11900 images\n",
      "already finish 12000 images\n",
      "already finish 12100 images\n",
      "already finish 12200 images\n",
      "already finish 12300 images\n",
      "already finish 12400 images\n",
      "already finish 12500 images\n",
      "already finish 12600 images\n",
      "already finish 12700 images\n",
      "already finish 12800 images\n",
      "already finish 12900 images\n",
      "already finish 13000 images\n",
      "already finish 13100 images\n",
      "already finish 13200 images\n",
      "already finish 13300 images\n",
      "already finish 13400 images\n",
      "already finish 13500 images\n",
      "already finish 13600 images\n",
      "already finish 13700 images\n",
      "already finish 13800 images\n",
      "already finish 13900 images\n",
      "already finish 14000 images\n",
      "already finish 14100 images\n",
      "already finish 14200 images\n",
      "already finish 14300 images\n",
      "already finish 14400 images\n",
      "already finish 14500 images\n",
      "already finish 14600 images\n",
      "already finish 14700 images\n",
      "already finish 14800 images\n",
      "already finish 14900 images\n",
      "already finish 15000 images\n",
      "already finish 15100 images\n",
      "already finish 15200 images\n",
      "already finish 15300 images\n",
      "already finish 15400 images\n",
      "already finish 15500 images\n",
      "already finish 15600 images\n",
      "already finish 15700 images\n",
      "already finish 15800 images\n",
      "already finish 15900 images\n",
      "already finish 16000 images\n",
      "already finish 16100 images\n",
      "already finish 16200 images\n",
      "already finish 16300 images\n",
      "already finish 16400 images\n",
      "already finish 16500 images\n",
      "already finish 16600 images\n"
     ]
    }
   ],
   "source": [
    "for i in poi.index:\n",
    "    \n",
    "    poi[\"img_url\"].loc[int(i)] = \"https://s3.amazonaws.com/travel-with-friends/img_file/\"+ str(i) + \".jpg\"\n",
    "    if i%100 ==0:\n",
    "        print(\"already finish \" + str(i) +\" images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in poi.index[0:2]:\n",
    "    print str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def outside_trip_poi(origin_city, origin_state, target_direction = 'N', n_days = 1, \\\n",
    "                    full_day = True, regular = True, debug = True, user_id = 'admin'):\n",
    "    outside_trip_id = '-'.join([str(origin_state.upper().replace(' ','-')), str(origin_city.upper().replace(' ','-')), \\\n",
    "                        target_direction,str(int(regular)), str(n_days)])\n",
    "    if not check_outside_trip_id(outside_trip_id, debug):\n",
    "        furthest_len = 140\n",
    "        if n_days == 1:\n",
    "            furthest_len = 140\n",
    "        #possible city coords, target city coord_lat, target city coord_long\n",
    "        # city_id, coords, coord_lat, coord_long = travel_outside_coords(origin_city, origin_state)\n",
    "        #coords: city, lat, long\n",
    "        # check_cities_info = []\n",
    "        # for item in coords:\n",
    "        #     direction = direction_from_orgin(coord_long,  coord_lat, item[2], item[1])\n",
    "        #     if (target_direction == direction) and (geopy_dist((item[1], item[2]), (coord_lat, coord_long)) < furthest_len):\n",
    "        #         check_cities_info.append(item)\n",
    "        # city_infos = []\n",
    "        # for city, _, _ in check_cities_info:\n",
    "        #     county = None\n",
    "        #     #index, coord0, coord1, adjusted_normal_time_spent, poi_rank, rating\n",
    "        #     city_info = db_start_location(county, origin_state, city)\n",
    "        #     city_infos.extend(city_info)\n",
    "        city_id, coord_lat, coord_long, city_infos = travel_outside_with_direction(origin_city, origin_state, target_direction, furthest_len, n_days=1)\n",
    "        if len(city_infos)<=0:\n",
    "            username_id = 1\n",
    "            conn = psycopg2.connect(conn_str)\n",
    "            cur = conn.cursor()\n",
    "            cur.execute('SELECT MAX(index) from outside_trip_table;')\n",
    "            new_index = cur.fetchone()[0] +1\n",
    "            cur.execute(\"INSERT into outside_trip_table(index, username_id, outside_trip_id, outside_route_ids, event_id_lst, origin_city, origin_state, target_direction, n_routes, regular, full_day, details) \\\n",
    "                         VALUES (%s,'%s', '%s', '%s','%s', '%s', '%s', '%s', %s,%s,%s,'%s');\" \\\n",
    "                         %(new_index, username_id, outside_trip_id, '[]', '[]', origin_city, origin_state, target_direction, 0, regular, full_day, '[]'))\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            print \"finish update None for %s, %s, direction %s into database\" %(origin_state, origin_city, target_direction)\n",
    "            return None\n",
    "        # city_infos = np.array(city_infos)\n",
    "        poi_coords = city_infos[:,1:3]\n",
    "        n_routes = sum(1 for t in np.array(city_infos)[:,3] if t >= 120)/10\n",
    "        if (n_routes>1) and (city_infos.shape[0]>=10):\n",
    "            kmeans = KMeans(n_clusters=n_routes).fit(poi_coords)\n",
    "        elif (city_infos.shape[0]> 20) or (n_routes>1):\n",
    "            kmeans = KMeans(n_clusters=2).fit(poi_coords)\n",
    "        else:\n",
    "            kmeans = KMeans(n_clusters=1).fit(poi_coords)\n",
    "        route_labels = kmeans.labels_\n",
    "        # print n_routes, len(route_labels), city_infos.shape\n",
    "        # print route_labels\n",
    "        outside_route_ids, outside_trip_details,event_id_lst ,details_theme =[],[],[],[]\n",
    "        for i in range(n_routes):\n",
    "            current_events, big_ix, med_ix, small_ix = [], [],[], []\n",
    "            for ix, label in enumerate(route_labels):\n",
    "                if label == i:\n",
    "                    time = city_infos[ix,3]\n",
    "                    event_ix = city_infos[ix,0]\n",
    "                    current_events.append(event_ix)\n",
    "                    if time > 180 :\n",
    "                        big_ix.append(ix)\n",
    "                    elif time >= 120 :\n",
    "                        med_ix.append(ix)\n",
    "                    else:\n",
    "                        small_ix.append(ix)\n",
    "            big_ = sorted_outside_events(city_infos, big_ix)\n",
    "            med_ = sorted_outside_events(city_infos, med_ix)\n",
    "            small_ = sorted_outside_events(city_infos, small_ix)\n",
    "            # need to update!!!!!!!!\n",
    "            event_ids, event_type = create_outside_event_id_list(big_, med_, small_)\n",
    "            event_ids, event_type = db_outside_event_cloest_distance(coord_lat, coord_long, event_ids = event_ids, event_type = event_type)\n",
    "            event_ids, google_ids, name_list, driving_time_list, walking_time_list =db_outside_google_driving_walking_time(city_id, coord_lat,coord_long, event_ids, event_type, origin_city = origin_city, origin_state = origin_state)\n",
    "            #why bug????\n",
    "            event_ids, driving_time_list, walking_time_list, total_time_spent = db_remove_outside_extra_events(event_ids, driving_time_list, walking_time_list)\n",
    "            outside_route_id = outside_trip_id + '-'+str(i)\n",
    "#             values = db_outside_route_trip_details(outside_route_id, event_ids, origin_city, origin_state, regular, full_day,n_days,i)\n",
    "            if check_outside_route_id(outside_route_id):\n",
    "                conn = psycopg2.connect(conn_str)\n",
    "                cur = conn.cursor()\n",
    "                cur.execute('DELETE FROM outside_route_table WHERE outside_route_id = %s;' %(outside_route_id))\n",
    "                conn.commit()\n",
    "                conn.close()\n",
    "                \n",
    "            details = db_outside_route_trip_details(event_ids,i)\n",
    "#             conn = psycopg2.connect(conn_str)\n",
    "#             cur = conn.cursor()\n",
    "#             cur.execute('select max(index) from outside_route_table;')\n",
    "#             new_index = cur.fetchone()[0] + 1\n",
    "#             cur.execute(\"insert into outside_route_table (index, outside_route_id, full_day, regular, origin_city, origin_state, target_direction, details, event_type, event_ids, route_num) \\\n",
    "#                         VALUES (%s, '%s', %s, %s, '%s', '%s', '%s', '%s', '%s', '%s', %s);\" \\\n",
    "#                         %(new_index, outside_route_id, full_day, regular, origin_city, origin_state, target_direction, str(details).replace(\"'\",\"''\"), event_type, str(event_ids) , i))\n",
    "#             conn.commit()\n",
    "#             conn.close()\n",
    "            details = db_outside_route_trip_details(event_ids,i)\n",
    "\n",
    "            route_theme = assign_theme(details)\n",
    "            info = [outside_route_id, full_day, regular, origin_city, origin_state, target_direction, str(details).replace(\"'\",\"''\"), event_type, str(event_ids) , i, route_theme[0]]\n",
    "            route_theme.extend(info)\n",
    "            \n",
    "            details_theme.append(route_theme)\n",
    "#             outside_route_ids.append(outside_route_id)\n",
    "            # outside_trip_details.extend(details)\n",
    "#             event_id_lst.extend(event_ids)\n",
    "        return details_theme\n",
    "        info_to_psql = clean_details(details_theme)\n",
    "        return info_to_psql\n",
    "#         username_id = 1\n",
    "# #         conn = psycopg2.connect(conn_str)\n",
    "# #         cur = conn.cursor()\n",
    "# #         cur.execute('SELECT MAX(index) from outside_trip_table;')\n",
    "# #         new_index = cur.fetchone()[0] +1\n",
    "# #         cur.execute(\"INSERT into outside_trip_table(index, username_id, outside_trip_id, outside_route_ids, event_id_lst, origin_city, origin_state, target_direction, n_routes, regular, full_day, details) \\\n",
    "# #                      VALUES (%s,'%s', '%s', '%s','%s', '%s', '%s', '%s', %s,%s,%s,'%s');\" \\\n",
    "# #                      %(new_index, username_id, outside_trip_id, str(outside_route_ids).replace(\"'\",\"''\"), str(event_id_lst), origin_city, origin_state, target_direction, n_routes, regular, full_day, str(outside_trip_details).replace(\"'\",\"''\")))\n",
    "# #         conn.commit()\n",
    "# #         conn.close()\n",
    "#         print \"finish update %s, %s, direction %s into database\" %(origin_state, origin_city, target_direction)\n",
    "#         return outside_trip_id, outside_trip_details\n",
    "#     else:\n",
    "#         print \"ALERT: %s, %s, direction %s already in database\" %(origin_state, origin_city, target_direction)\n",
    "#         conn = psycopg2.connect(conn_str)\n",
    "#         cur = conn.cursor()\n",
    "#         cur.execute(\"SELECT DISTINCT outside_trip_id, details FROM outside_trip_table WHERE outside_trip_id = '%s';\" %(outside_trip_id))\n",
    "#         outside_trip_id, details = cur.fetchone()\n",
    "#         details = ast.literal_eval(details)\n",
    "#         conn.close()\n",
    "#         return outside_trip_id, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "from distance import *\n",
    "from outside_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "direct = [\"E\",\"S\",\"W\",\"N\"]\n",
    "target_direction = direct[1]\n",
    "origin_city = 'San Francisco'\n",
    "origin_state = 'California'\n",
    "print origin_city, origin_state\n",
    "\n",
    "details= outside_trip_poi(origin_city,origin_state, target_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# details_array= np.array(details)\n",
    "\n",
    "details_array[:,[1,3]] = details_array[:,[1,3]].astype(np.float)\n",
    "details_array[:,2].astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "details_array= np.array(details)\n",
    "\n",
    "final = []\n",
    "used =[]\n",
    "for count, i, in enumerate(details_array):\n",
    "    if (i[0] == \"national_park\") or (i[0] == \"theme_park\"):\n",
    "        final.append(i[4])\n",
    "        used.append(count)\n",
    "details_array = np.delete(details_array, used, axis = 0)\n",
    "a= np.array(sorted(details_array, key=lambda x: (x[2].astype(np.int), -x[1].astype(np.float), x[3].astype(np.float))))\n",
    "\n",
    "theme_select_dict={}\n",
    "backup =[]\n",
    "# a[:,0:4]\n",
    "for count, i in enumerate(a):\n",
    "    if i[0] not in theme_select_dict:\n",
    "        theme_select_dict[i[0]] = 1\n",
    "        final.append(i[4:])\n",
    "    else:\n",
    "        backup.extend(i[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_details(details_theme):\n",
    "    details_array= np.array(details_theme)\n",
    "    final = []\n",
    "    used =[]\n",
    "    for count, i, in enumerate(details_array):  \n",
    "        if (i[0] == \"national_park\") or (i[0] == \"theme_park\"):  #select all national park & theme park \n",
    "            final.extend(i[4]) #save all details together\n",
    "            used.append(count) #save the count of those park\n",
    "    details_array = np.delete(details_array, used, axis = 0)  #remove them from array\n",
    "    a= np.array(sorted(details_array, key=lambda x: (x[2], -x[1], -x[3] ))) #sorted the item base on ranking, num_review, review_score\n",
    "    \n",
    "    theme_select_dict={}\n",
    "    backup =[]\n",
    "    # a[:,0:4]\n",
    "    for count, i in enumerate(a):\n",
    "        if i[0] not in theme_select_dict:\n",
    "            theme_select_dict[i[0]] = 1 #use dict to check for only one of each theme is choose\n",
    "            final.extend(i[4])\n",
    "        else:\n",
    "            backup.extend(i[4]) #backup for those didnt use \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assign_theme(details):\n",
    "    assign_dict={\"family\" : 0,\"lifestyle\": 0,\"nature\": 0,\"cultural\": 0,\"theme_park\": 0,\"national_park\": 0,\"other_list\": 0}\n",
    "    \n",
    "    assign_dict2={\"family\" : 0,\"lifestyle\": 0,\"nature\": 0,\"cultural\": 0,\"theme_park\": 0,\"national_park\": 0,\"other_list\": 0}\n",
    "    \n",
    "    assign_dict3={\"family\" : -1,\"lifestyle\": -1,\"nature\": -1,\"cultural\": -1,\"theme_park\": -1,\"national_park\": -1,\"other_list\": -1}\n",
    "\n",
    "    #create a list for each poi\n",
    "    all_type=[]\n",
    "    for i in details:\n",
    "        all_type.append([i[\"poi_type\"],i[\"adjusted_visit_length\"], i[\"num_reviews\"], i[\"ranking\"]])\n",
    "\n",
    "    for i in all_type:\n",
    "        for key, value in theme_list_dict.items():\n",
    "            if i[0] in value: #locate the theme \n",
    "                assign_dict[key] += int(i[1]) #total time of theme\n",
    "                assign_dict2[key] += int(i[2]) #total # of review of theme\n",
    "                if assign_dict3[key] <0:\n",
    "                    assign_dict3[key] = int(i[3])\n",
    "                else:\n",
    "                    assign_dict3[key] = min(assign_dict3[key], int(i[3]))\n",
    "    assign_dict = sort_dict(assign_dict) #order descending \n",
    "    \n",
    "    if assign_dict[0][0] == assign_dict[1][0]: #check if the total time is same \n",
    "        if assign_dict2[assign_dict[0][1]] > assign_dict2[assign_dict[1][1]]:  #check number of review\n",
    "            return assign_dict[0][1]\n",
    "        elif assign_dict2[assign_dict[0][1]] < assign_dict2[assign_dict[1][1]]:\n",
    "            return assign_dict[1][1]\n",
    "        elif assign_dict3[assign_dict[0][1]] < assign_dict3[assign_dict[1][1]]: #check for ranking\n",
    "            return assign_dict[0][1]\n",
    "        else:\n",
    "            return assign_dict[1][1]\n",
    "\n",
    "            \n",
    "    return assign_dict[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_dict(input_dict):\n",
    "\ttemp_dict = [(input_dict[key], key) for key in input_dict]\n",
    "\ttemp_dict.sort(reverse = True)\n",
    "\treturn temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print assign_theme(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theme_list_dict = {\n",
    "    \"family\" : [\"Park\",\"Zoo\",\"Game\"],\n",
    "    \"lifestyle\" : [\"Nightlife\",\"Shopping\",\"Theater\",\"Food\",\"Spa\",\"Casino\",\"Show\",\"ShoppingMall\",\"Show\"],\n",
    "    \"nature\" : [\"StatePark\",\"NationalWildlifeRefuge\",\"NationalHistoricalPark\",\"NationalForest\",\"NationalMonument\",\"NationalMemorial\"],\n",
    "    \"cultural\" : [\"Landmark\", \"Museum\",\"OutdoorActivities\",\"Library\",\"Stadium\"],\n",
    "    \"theme_park\" : [\"ThemePark\"],\n",
    "    \"national_park\" : [\"NationalPark\"],\n",
    "    \"other_list\" : [\"Other\",\"VisotorCenter\",\"Transportation\",\"Tour\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "museum =300\n",
    "theater =60\n",
    "landmark = 60\n",
    "visitorCenter =15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theme={}\n",
    "theme_list = [\"family\",\"lifestyle\",\"nature\",\"cultural\",\"theme_park\",\"national_park\"]\n",
    "for i in theme_list:\n",
    "    theme[i]= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi = pd.read_csv(\"poi_detail_table_final_v1.csv\", encoding=('utf-8'), index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_type_u= set(poi.poi_type.str.encode('utf8'))\n",
    "poi_type= list(poi.poi_type.str.encode('utf8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(poi_type)\n",
    "add = 0\n",
    "for i in counts.items():\n",
    "    add += i[1]\n",
    "print add\n",
    "# print counts.items()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# d = {'key': 'value'}\n",
    "# word_count_dict = {}\n",
    "# for key, values in d.items():\n",
    "#     if values[1] in temp_dict:\n",
    "#         temp_dict[values[1]] = temp_dict[values[1]] + 1\n",
    "#     else:\n",
    "#         temp_dict[values[1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# d = defaultdict(int)\n",
    "\n",
    "# for word in poi_type:\n",
    "#     d[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_type_dict={}\n",
    "for i in poi_type_u:\n",
    "    poi_type_dict[i] = poi_type.count(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sortFreqDict(freqdict):\n",
    "    aux = [(freqdict[key], key) for key in freqdict]\n",
    "    aux.sort(reverse=True)\n",
    "#     aux.reverse()\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sortFreqDict(poi_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi[poi.poi_type == \"NationalHistoricalPark\"].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conn_str = \"dbname='travel_with_friends' user='Gon' host='localhost'\"\n",
    "with open('api_key_list.config') as key_file:\n",
    "    api_key_list = json.load(key_file)\n",
    "conn_str = api_key_list[\"conn_str\"]\n",
    "engine_str = api_key_list[\"engine\"]\n",
    "engine = create_engine(engine_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "# conn = psycopg2.connect(conn_str)   \n",
    "# cur = conn.cursor()\n",
    "# poi.to_sql('poi_detail_table_final_v1',engine, index=True, if_exists = \"replace\")\n",
    "# conn.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a= [1.5,2,3,4,5.5,[\"hel\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "a= np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[[0,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ca <type 'unicode'>\n",
      "California <type 'str'>\n"
     ]
    }
   ],
   "source": [
    "import helpers\n",
    "from us_state_abbrevation import *\n",
    "\n",
    "def check_state(origin_state):\n",
    "    if not helpers.check_valid_state(origin_state):\n",
    "        origin_state = abb2state[str(origin_state).upper()]\n",
    "    return origin_state\n",
    "state = u'Ca'\n",
    "print state, type(state)\n",
    "state = check_state(state)\n",
    "print state, type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
